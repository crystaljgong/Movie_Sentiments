{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "959a7890-af52-4a93-8179-e797ad6fc700"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e7a16fae-e0f8-4ab1-89e3-457c6bcabe63"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'During the training of the deep networks, we oversample the training\\nimages by rotating them around their center by a random angle between \\n\\xe2\\x88\\x9215\\xc2\\xb0 and 15\\xc2\\xb0, and by circularly shifting the images in the horizontal and \\nvertical directions by an amount no more than 20% of the image size. \\nThis approach helps our network to be more robust against alignment errors. \\nIn Fig. 2, we show the training curves of two stages of fine-tuning of the \\nnetwork with the FER dataset, where we set the learning rate and weight \\ndecay to 0.0005, momentum to 0.9, and dropout probability to 0.8 [25].'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "For the fine-tuning of the VGG-Face network for the emotion\n",
    "recognition task, we investigated various options in our preliminary\n",
    "analysis. We found that combining weight decay and dropout for regularization\n",
    "gives the best results on the FER validation set. We carry\n",
    "out a multi-stage fine-tuning. In the first stage, we fine-tune on the\n",
    "FER public test set, and run weight updates for five epochs. In the second\n",
    "stage, we update the upper layers (higher than layer 27) using'''\n",
    "\n",
    "''' We then fine-tune the VGG-face model on FER 2013\n",
    "dataset, using both the training and the public test set; during\n",
    "training we use data augmentation by jittering the scale, flipping\n",
    "and rotating the faces. The aim is to make the network more robust\n",
    "to small misalignment of the faces. We also apply a strong dropout\n",
    "on the last layer of the VGG (keeping only 5% of the nodes) to\n",
    "prevent over-fitting. We achieve a performance of 71.2% on the\n",
    "FER private test set, which is slightly higher than the previously\n",
    "published results '''\n",
    "\n",
    "'''During the training of the deep networks, we oversample the training\n",
    "images by rotating them around their center by a random angle between \n",
    "−15° and 15°, and by circularly shifting the images in the horizontal and \n",
    "vertical directions by an amount no more than 20% of the image size. \n",
    "This approach helps our network to be more robust against alignment errors. \n",
    "In Fig. 2, we show the training curves of two stages of fine-tuning of the \n",
    "network with the FER dataset, where we set the learning rate and weight \n",
    "decay to 0.0005, momentum to 0.9, and dropout probability to 0.8 [25].'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6879088e-ce15-45e6-8f39-29fd16ab529a"
    }
   },
   "source": [
    "### VGG16-Face model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d691c9bc-5b8d-42ae-b109-0597f42f5d60"
    }
   },
   "outputs": [],
   "source": [
    "import VGG_FACE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "570025bf-5112-4fae-9432-4039578fc868"
    }
   },
   "outputs": [],
   "source": [
    "model = VGG_FACE.VGG_FACE\n",
    "\n",
    "model.load_state_dict(torch.load('VGG_FACE.pth'))\n",
    "\n",
    "#how to test whether this is pretrained?\n",
    "#model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7ef650af-4012-42c1-a5f5-69e04cdd9cf8"
    }
   },
   "source": [
    "### Dataset: FERplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5e29d967-b841-48d2-8160-e678660be2ea"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "be8542c0-7e28-4b37-93f3-0fda5361a126"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Image name</th>\n",
       "      <th>neutral</th>\n",
       "      <th>happiness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>contempt</th>\n",
       "      <th>unknown</th>\n",
       "      <th>NF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000000.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000001.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000002.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000003.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000004.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000005.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000006.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000007.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000008.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000009.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000010.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000011.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000012.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000013.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000014.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000015.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000016.png</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000018.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000019.png</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000020.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000021.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000022.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000024.png</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000025.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000026.png</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000027.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000028.png</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000029.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000030.png</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000031.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35856</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035771.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35857</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035772.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35858</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035773.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35859</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035774.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35860</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035775.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35861</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035776.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35862</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035777.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35863</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035778.png</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35864</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035779.png</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35865</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035780.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35866</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035781.png</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35867</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035782.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35868</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035783.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35869</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035784.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35870</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035785.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35871</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035786.png</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35872</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035787.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35873</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035788.png</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35874</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035789.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35875</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035790.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35876</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035791.png</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35877</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035792.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35878</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035793.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35879</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035794.png</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35880</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035795.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35881</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035796.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035797.png</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035799.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035800.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035801.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35714 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Usage      Image name  neutral  happiness  surprise  sadness  \\\n",
       "0         Training  fer0000000.png        4          0         0        1   \n",
       "1         Training  fer0000001.png        6          0         1        1   \n",
       "2         Training  fer0000002.png        5          0         0        3   \n",
       "3         Training  fer0000003.png        4          0         0        4   \n",
       "4         Training  fer0000004.png        9          0         0        1   \n",
       "5         Training  fer0000005.png        6          0         0        1   \n",
       "6         Training  fer0000006.png        2          0         0        8   \n",
       "7         Training  fer0000007.png        0         10         0        0   \n",
       "8         Training  fer0000008.png        0         10         0        0   \n",
       "9         Training  fer0000009.png        0          0         6        0   \n",
       "10        Training  fer0000010.png        2          0         0        0   \n",
       "11        Training  fer0000011.png       10          0         0        0   \n",
       "12        Training  fer0000012.png        5          0         0        3   \n",
       "13        Training  fer0000013.png        9          0         0        1   \n",
       "14        Training  fer0000014.png        0         10         0        0   \n",
       "15        Training  fer0000015.png        0          0         6        0   \n",
       "16        Training  fer0000016.png        4          6         0        0   \n",
       "18        Training  fer0000018.png        1          0         2        4   \n",
       "19        Training  fer0000019.png        6          1         0        0   \n",
       "20        Training  fer0000020.png        5          0         0        4   \n",
       "21        Training  fer0000021.png        1          0         1        2   \n",
       "22        Training  fer0000022.png        1          0         1        1   \n",
       "24        Training  fer0000024.png        2          7         0        0   \n",
       "25        Training  fer0000025.png        0         10         0        0   \n",
       "26        Training  fer0000026.png        4          2         4        0   \n",
       "27        Training  fer0000027.png        0          0         0        0   \n",
       "28        Training  fer0000028.png        1          7         0        0   \n",
       "29        Training  fer0000029.png        0          1         6        0   \n",
       "30        Training  fer0000030.png        0          9         0        0   \n",
       "31        Training  fer0000031.png       10          0         0        0   \n",
       "...            ...             ...      ...        ...       ...      ...   \n",
       "35856  PrivateTest  fer0035771.png        0         10         0        0   \n",
       "35857  PrivateTest  fer0035772.png        0          0        10        0   \n",
       "35858  PrivateTest  fer0035773.png        1          0         1        7   \n",
       "35859  PrivateTest  fer0035774.png       10          0         0        0   \n",
       "35860  PrivateTest  fer0035775.png        0         10         0        0   \n",
       "35861  PrivateTest  fer0035776.png        9          0         0        0   \n",
       "35862  PrivateTest  fer0035777.png        2          0         3        0   \n",
       "35863  PrivateTest  fer0035778.png        0          2         7        0   \n",
       "35864  PrivateTest  fer0035779.png        4          1         0        4   \n",
       "35865  PrivateTest  fer0035780.png        0         10         0        0   \n",
       "35866  PrivateTest  fer0035781.png        7          3         0        0   \n",
       "35867  PrivateTest  fer0035782.png        0         10         0        0   \n",
       "35868  PrivateTest  fer0035783.png        0          0         0        0   \n",
       "35869  PrivateTest  fer0035784.png        0         10         0        0   \n",
       "35870  PrivateTest  fer0035785.png        0          0         0        0   \n",
       "35871  PrivateTest  fer0035786.png        9          1         0        0   \n",
       "35872  PrivateTest  fer0035787.png        6          0         0        0   \n",
       "35873  PrivateTest  fer0035788.png        8          0         0        2   \n",
       "35874  PrivateTest  fer0035789.png        1          0         1        5   \n",
       "35875  PrivateTest  fer0035790.png        2          0         5        1   \n",
       "35876  PrivateTest  fer0035791.png        1          9         0        0   \n",
       "35877  PrivateTest  fer0035792.png        4          0         0        5   \n",
       "35878  PrivateTest  fer0035793.png        0         10         0        0   \n",
       "35879  PrivateTest  fer0035794.png        3          0         0        5   \n",
       "35880  PrivateTest  fer0035795.png        0          0         1        6   \n",
       "35881  PrivateTest  fer0035796.png        5          0         0        3   \n",
       "35882  PrivateTest  fer0035797.png        8          0         0        2   \n",
       "35884  PrivateTest  fer0035799.png        0          0         0        0   \n",
       "35885  PrivateTest  fer0035800.png        0         10         0        0   \n",
       "35886  PrivateTest  fer0035801.png        2          0         0        5   \n",
       "\n",
       "       anger  disgust  fear  contempt  unknown  NF  \n",
       "0          3        2     0         0        0   0  \n",
       "1          0        0     0         0        2   0  \n",
       "2          1        0     0         0        1   0  \n",
       "3          1        0     0         0        1   0  \n",
       "4          0        0     0         0        0   0  \n",
       "5          0        0     1         1        1   0  \n",
       "6          0        0     0         0        0   0  \n",
       "7          0        0     0         0        0   0  \n",
       "8          0        0     0         0        0   0  \n",
       "9          0        0     4         0        0   0  \n",
       "10         8        0     0         0        0   0  \n",
       "11         0        0     0         0        0   0  \n",
       "12         0        0     0         0        2   0  \n",
       "13         0        0     0         0        0   0  \n",
       "14         0        0     0         0        0   0  \n",
       "15         1        0     3         0        0   0  \n",
       "16         0        0     0         0        0   0  \n",
       "18         2        0     0         0        1   0  \n",
       "19         3        0     0         0        0   0  \n",
       "20         0        0     0         0        1   0  \n",
       "21         0        0     5         0        1   0  \n",
       "22         7        0     0         0        0   0  \n",
       "24         0        0     0         1        0   0  \n",
       "25         0        0     0         0        0   0  \n",
       "26         0        0     0         0        0   0  \n",
       "27         7        1     0         0        2   0  \n",
       "28         0        2     0         0        0   0  \n",
       "29         0        0     3         0        0   0  \n",
       "30         0        1     0         0        0   0  \n",
       "31         0        0     0         0        0   0  \n",
       "...      ...      ...   ...       ...      ...  ..  \n",
       "35856      0        0     0         0        0   0  \n",
       "35857      0        0     0         0        0   0  \n",
       "35858      0        0     0         0        1   0  \n",
       "35859      0        0     0         0        0   0  \n",
       "35860      0        0     0         0        0   0  \n",
       "35861      0        0     0         0        1   0  \n",
       "35862      0        0     5         0        0   0  \n",
       "35863      0        0     1         0        0   0  \n",
       "35864      0        0     0         0        1   0  \n",
       "35865      0        0     0         0        0   0  \n",
       "35866      0        0     0         0        0   0  \n",
       "35867      0        0     0         0        0   0  \n",
       "35868      7        0     2         0        1   0  \n",
       "35869      0        0     0         0        0   0  \n",
       "35870     10        0     0         0        0   0  \n",
       "35871      0        0     0         0        0   0  \n",
       "35872      1        1     1         0        1   0  \n",
       "35873      0        0     0         0        0   0  \n",
       "35874      0        0     1         0        2   0  \n",
       "35875      0        0     0         1        1   0  \n",
       "35876      0        0     0         0        0   0  \n",
       "35877      0        0     0         0        1   0  \n",
       "35878      0        0     0         0        0   0  \n",
       "35879      1        0     0         0        1   0  \n",
       "35880      0        0     3         0        0   0  \n",
       "35881      0        0     0         0        2   0  \n",
       "35882      0        0     0         0        0   0  \n",
       "35884      7        1     0         2        0   0  \n",
       "35885      0        0     0         0        0   0  \n",
       "35886      1        1     0         0        1   0  \n",
       "\n",
       "[35714 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all-data/FERPlus/fer2013new.csv')\n",
    "df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0ca1abe4-7bb7-4bbe-8faf-080cad04eaf5"
    }
   },
   "outputs": [],
   "source": [
    "class FaceEmotionsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.emotions_frame = pd.read_csv(csv_file)\n",
    "        self.emotions_frame.dropna(axis=0, how='any', inplace=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.emotions_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.emotions_frame.iloc[idx][1]\n",
    "        \n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = io.imread(img_path)\n",
    "        #this takes the most highest ranked emotion. if two emotions have the same ranking, it just takes the first one\n",
    "        emotion = np.argmax(self.emotions_frame.iloc[idx,2:].as_matrix())\n",
    "        sample = {'image': image, 'emotion': emotion}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7eb85ee3-259b-4395-a288-ee1af15c1f41"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "emotions_frame = pd.read_csv('all-data/FERPlus/fer2013new.csv')\n",
    "emotions_frame.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "emotion = np.argmax(emotions_frame.iloc[10,2:].as_matrix())\n",
    "print(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "252d81d5-707f-4133-add3-fe798d2dc52e"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30,  24,  21, ...,  37,  44,  37],\n",
       "       [ 31,  22,  21, ...,  37,  35,  41],\n",
       "       [ 27,  22,  19, ...,  33,  34,  40],\n",
       "       ..., \n",
       "       [ 29,  29,  26, ..., 118, 132, 148],\n",
       "       [ 30,  30,  27, ..., 154, 159, 166],\n",
       "       [ 32,  29,  28, ..., 172, 173, 173]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_emotions = FaceEmotionsDataset(csv_file = 'all-data/FERPlus/fer2013new_training.csv', \n",
    "                                    root_dir = 'all-data/FERPlus/data/FER2013Train')\n",
    "\n",
    "face_emotions[10]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e2264cdf-997e-446c-b3bf-f46ba169e294"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nO05K+b8gRHCVsxoNGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1375af910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#for i in range(len(face_emotions)):\n",
    "    #sample = face_emotions[i]\n",
    "\n",
    "    #print(i, sample['image'].shape, sample['emotion'])\n",
    "\"\"\"\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    show_landmarks(**sample)\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break\n",
    "\"\"\"\n",
    "plt.imshow(face_emotions[10]['image'])\n",
    "plt.show()\n",
    "print(face_emotions[10]['emotion'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0d088434-f0c7-4d61-a29f-29d2529e3ad1"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from skimage import transform\n",
    "from PIL import Image\n",
    "from skimage import io; io.use_plugin('matplotlib')\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, emotion = sample['image'], sample['emotion']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        #print(image.shape)\n",
    "        #image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'emotion': emotion}\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, emotion = sample['image'], sample['emotion']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        #emotion = emotion - [left, top]\n",
    "\n",
    "        return {'image': image, 'emotion': emotion}\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or tuple): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, emotion = sample['image'], sample['emotion']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        \n",
    "        #emotion = emotion * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'emotion': emotion}\n",
    "\n",
    "\n",
    "imgTransform = transforms.Compose([Rescale(256), #scale to 256x256\n",
    "                                   #transforms.CenterCrop(224), #crops the image at center to 224x224\n",
    "                                   RandomCrop(224),\n",
    "                                   ToTensor()\n",
    "                                   ])\n",
    "                                   #, #turn the jpg/pil/wahtever image into a tensor\n",
    "                                   #transforms.Normalize(mean = [0.485, 0.456, 0.406], #normalize with these vals\n",
    "                                                        #std=[0.229, 0.224, 0.225])])\n",
    "                                    ##HOW TO GET NORMALIZED VALUES?\n",
    "                                    #to add: jitter/rotate data augmentation, flipping, \n",
    "                                   \n",
    "#this doesn't work because the data is organized w a csv file w prob distrib of labels \n",
    "#instead of a single ground truth\n",
    "#see this paper: https://arxiv.org/pdf/1608.01041.pdf\n",
    "trainset = FaceEmotionsDataset(csv_file = 'all-data/FERPlus/fer2013new_training.csv', \n",
    "                                    root_dir = 'all-data/FERPlus/data/FER2013Train', transform = imgTransform)\n",
    "valset = FaceEmotionsDataset(csv_file = 'all-data/FERPlus/fer2013new_validation.csv', \n",
    "                                    root_dir = 'all-data/FERPlus/data/FER2013Valid', transform = imgTransform)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size = 64, \n",
    "                                          shuffle = True, num_workers = 0)\n",
    "valLoader = torch.utils.data.DataLoader(valset, batch_size = 64, \n",
    "                                       shuffle = False, num_workers = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6d2ad753-43bf-4df1-b903-4dc8b543cff0"
    }
   },
   "source": [
    "### Function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d0d19064-5fe3-4fae-b953-b62bf3aeba34"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c180c3a4-a698-4501-a48d-3b4cb152b2f8"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = False):\n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    t_loss, t_acc, v_loss, v_acc = (np.zeros(n_epochs) for i in range(4))    \n",
    "    \n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (inputs, labels)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "            \n",
    "        t_loss[epoch] = (cum_loss/len(t))\n",
    "        t_acc[epoch] = (100*correct/counter)\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (inputs, labels)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "            \n",
    "        v_loss[epoch] = (cum_loss/len(t))\n",
    "        v_acc[epoch] = (100*correct/counter)\n",
    "        \n",
    "                \n",
    "    lab_utils.generate_plots(t_loss, v_loss, t_acc, v_acc, n_epochs)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8459ae87-2706-43ee-9348-a63be5996153"
    }
   },
   "source": [
    "### set learning rate, loss, optimizer, all variable stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "faa6cc19-fa86-49d0-9374-cfc76c652add"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Variable data has to be a tensor, but got str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-7211dfbb8803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-069f7b4f7f18>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(network, criterion, optimizer, trainLoader, valLoader, n_epochs, use_gpu)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Wrap inputs, and targets into torch.autograd.Variable types.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Variable data has to be a tensor, but got str"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "#\"where we set the learning rate and weight decay to 0.0005, momentum to 0.9, and dropout probability to 0.8 [25]\"\n",
    "learningRate = 5e-4\n",
    "\n",
    "\n",
    "\n",
    "# Definition of our network.\n",
    "#how to change the last fc layer of the model to nn.linear(4096, 7) instead of (4096, 2622)?\n",
    "model.fc = nn.Linear(512, 2)\n",
    "\n",
    "#Definition of our loss. #maybe need to change this?\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definition of optimization strategy. # maybe need to change this?\n",
    "optimizer = optim.SGD(model.parameters(), lr = learningRate)\n",
    "\n",
    "train_model(model, criterion, optimizer, trainLoader, valLoader, n_epochs = 3, use_gpu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "02eedb4f-caec-4730-8c9b-fefd3ff20fbc"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "15c9d09f438441b9a7a2d8e4c7099215": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
