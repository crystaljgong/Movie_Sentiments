{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "959a7890-af52-4a93-8179-e797ad6fc700"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "e7a16fae-e0f8-4ab1-89e3-457c6bcabe63"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'During the training of the deep networks, we oversample the training\\nimages by rotating them around their center by a random angle between \\n\\xe2\\x88\\x9215\\xc2\\xb0 and 15\\xc2\\xb0, and by circularly shifting the images in the horizontal and \\nvertical directions by an amount no more than 20% of the image size. \\nThis approach helps our network to be more robust against alignment errors. \\nIn Fig. 2, we show the training curves of two stages of fine-tuning of the \\nnetwork with the FER dataset, where we set the learning rate and weight \\ndecay to 0.0005, momentum to 0.9, and dropout probability to 0.8 [25].'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "For the fine-tuning of the VGG-Face network for the emotion\n",
    "recognition task, we investigated various options in our preliminary\n",
    "analysis. We found that combining weight decay and dropout for regularization\n",
    "gives the best results on the FER validation set. We carry\n",
    "out a multi-stage fine-tuning. In the first stage, we fine-tune on the\n",
    "FER public test set, and run weight updates for five epochs. In the second\n",
    "stage, we update the upper layers (higher than layer 27) using'''\n",
    "\n",
    "''' We then fine-tune the VGG-face model on FER 2013\n",
    "dataset, using both the training and the public test set; during\n",
    "training we use data augmentation by jittering the scale, flipping\n",
    "and rotating the faces. The aim is to make the network more robust\n",
    "to small misalignment of the faces. We also apply a strong dropout\n",
    "on the last layer of the VGG (keeping only 5% of the nodes) to\n",
    "prevent over-fitting. We achieve a performance of 71.2% on the\n",
    "FER private test set, which is slightly higher than the previously\n",
    "published results '''\n",
    "\n",
    "'''During the training of the deep networks, we oversample the training\n",
    "images by rotating them around their center by a random angle between \n",
    "−15° and 15°, and by circularly shifting the images in the horizontal and \n",
    "vertical directions by an amount no more than 20% of the image size. \n",
    "This approach helps our network to be more robust against alignment errors. \n",
    "In Fig. 2, we show the training curves of two stages of fine-tuning of the \n",
    "network with the FER dataset, where we set the learning rate and weight \n",
    "decay to 0.0005, momentum to 0.9, and dropout probability to 0.8 [25].'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6879088e-ce15-45e6-8f39-29fd16ab529a"
    }
   },
   "source": [
    "### VGG16-Face model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d691c9bc-5b8d-42ae-b109-0597f42f5d60"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import VGG_FACE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "570025bf-5112-4fae-9432-4039578fc868"
    }
   },
   "outputs": [],
   "source": [
    "model = VGG_FACE.VGG_FACE\n",
    "\n",
    "model.load_state_dict(torch.load('VGG_FACE.pth'))\n",
    "\n",
    "#model.eval() #this will let you pass an input through the model and evaluate it? without training?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7ef650af-4012-42c1-a5f5-69e04cdd9cf8"
    }
   },
   "source": [
    "### Dataset: FERplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5e29d967-b841-48d2-8160-e678660be2ea"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "be8542c0-7e28-4b37-93f3-0fda5361a126"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Image name</th>\n",
       "      <th>neutral</th>\n",
       "      <th>happiness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>contempt</th>\n",
       "      <th>unknown</th>\n",
       "      <th>NF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000000.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000001.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000002.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000003.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000004.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000005.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000006.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000007.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000008.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000009.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000010.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000011.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000012.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000013.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000014.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000015.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000016.png</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000018.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000019.png</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000020.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000021.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000022.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000024.png</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000025.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000026.png</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000027.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000028.png</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000029.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000030.png</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000031.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35856</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035771.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35857</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035772.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35858</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035773.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35859</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035774.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35860</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035775.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35861</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035776.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35862</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035777.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35863</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035778.png</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35864</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035779.png</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35865</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035780.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35866</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035781.png</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35867</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035782.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35868</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035783.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35869</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035784.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35870</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035785.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35871</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035786.png</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35872</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035787.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35873</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035788.png</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35874</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035789.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35875</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035790.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35876</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035791.png</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35877</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035792.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35878</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035793.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35879</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035794.png</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35880</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035795.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35881</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035796.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035797.png</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035799.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035800.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035801.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35714 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Usage      Image name  neutral  happiness  surprise  sadness  \\\n",
       "0         Training  fer0000000.png        4          0         0        1   \n",
       "1         Training  fer0000001.png        6          0         1        1   \n",
       "2         Training  fer0000002.png        5          0         0        3   \n",
       "3         Training  fer0000003.png        4          0         0        4   \n",
       "4         Training  fer0000004.png        9          0         0        1   \n",
       "5         Training  fer0000005.png        6          0         0        1   \n",
       "6         Training  fer0000006.png        2          0         0        8   \n",
       "7         Training  fer0000007.png        0         10         0        0   \n",
       "8         Training  fer0000008.png        0         10         0        0   \n",
       "9         Training  fer0000009.png        0          0         6        0   \n",
       "10        Training  fer0000010.png        2          0         0        0   \n",
       "11        Training  fer0000011.png       10          0         0        0   \n",
       "12        Training  fer0000012.png        5          0         0        3   \n",
       "13        Training  fer0000013.png        9          0         0        1   \n",
       "14        Training  fer0000014.png        0         10         0        0   \n",
       "15        Training  fer0000015.png        0          0         6        0   \n",
       "16        Training  fer0000016.png        4          6         0        0   \n",
       "18        Training  fer0000018.png        1          0         2        4   \n",
       "19        Training  fer0000019.png        6          1         0        0   \n",
       "20        Training  fer0000020.png        5          0         0        4   \n",
       "21        Training  fer0000021.png        1          0         1        2   \n",
       "22        Training  fer0000022.png        1          0         1        1   \n",
       "24        Training  fer0000024.png        2          7         0        0   \n",
       "25        Training  fer0000025.png        0         10         0        0   \n",
       "26        Training  fer0000026.png        4          2         4        0   \n",
       "27        Training  fer0000027.png        0          0         0        0   \n",
       "28        Training  fer0000028.png        1          7         0        0   \n",
       "29        Training  fer0000029.png        0          1         6        0   \n",
       "30        Training  fer0000030.png        0          9         0        0   \n",
       "31        Training  fer0000031.png       10          0         0        0   \n",
       "...            ...             ...      ...        ...       ...      ...   \n",
       "35856  PrivateTest  fer0035771.png        0         10         0        0   \n",
       "35857  PrivateTest  fer0035772.png        0          0        10        0   \n",
       "35858  PrivateTest  fer0035773.png        1          0         1        7   \n",
       "35859  PrivateTest  fer0035774.png       10          0         0        0   \n",
       "35860  PrivateTest  fer0035775.png        0         10         0        0   \n",
       "35861  PrivateTest  fer0035776.png        9          0         0        0   \n",
       "35862  PrivateTest  fer0035777.png        2          0         3        0   \n",
       "35863  PrivateTest  fer0035778.png        0          2         7        0   \n",
       "35864  PrivateTest  fer0035779.png        4          1         0        4   \n",
       "35865  PrivateTest  fer0035780.png        0         10         0        0   \n",
       "35866  PrivateTest  fer0035781.png        7          3         0        0   \n",
       "35867  PrivateTest  fer0035782.png        0         10         0        0   \n",
       "35868  PrivateTest  fer0035783.png        0          0         0        0   \n",
       "35869  PrivateTest  fer0035784.png        0         10         0        0   \n",
       "35870  PrivateTest  fer0035785.png        0          0         0        0   \n",
       "35871  PrivateTest  fer0035786.png        9          1         0        0   \n",
       "35872  PrivateTest  fer0035787.png        6          0         0        0   \n",
       "35873  PrivateTest  fer0035788.png        8          0         0        2   \n",
       "35874  PrivateTest  fer0035789.png        1          0         1        5   \n",
       "35875  PrivateTest  fer0035790.png        2          0         5        1   \n",
       "35876  PrivateTest  fer0035791.png        1          9         0        0   \n",
       "35877  PrivateTest  fer0035792.png        4          0         0        5   \n",
       "35878  PrivateTest  fer0035793.png        0         10         0        0   \n",
       "35879  PrivateTest  fer0035794.png        3          0         0        5   \n",
       "35880  PrivateTest  fer0035795.png        0          0         1        6   \n",
       "35881  PrivateTest  fer0035796.png        5          0         0        3   \n",
       "35882  PrivateTest  fer0035797.png        8          0         0        2   \n",
       "35884  PrivateTest  fer0035799.png        0          0         0        0   \n",
       "35885  PrivateTest  fer0035800.png        0         10         0        0   \n",
       "35886  PrivateTest  fer0035801.png        2          0         0        5   \n",
       "\n",
       "       anger  disgust  fear  contempt  unknown  NF  \n",
       "0          3        2     0         0        0   0  \n",
       "1          0        0     0         0        2   0  \n",
       "2          1        0     0         0        1   0  \n",
       "3          1        0     0         0        1   0  \n",
       "4          0        0     0         0        0   0  \n",
       "5          0        0     1         1        1   0  \n",
       "6          0        0     0         0        0   0  \n",
       "7          0        0     0         0        0   0  \n",
       "8          0        0     0         0        0   0  \n",
       "9          0        0     4         0        0   0  \n",
       "10         8        0     0         0        0   0  \n",
       "11         0        0     0         0        0   0  \n",
       "12         0        0     0         0        2   0  \n",
       "13         0        0     0         0        0   0  \n",
       "14         0        0     0         0        0   0  \n",
       "15         1        0     3         0        0   0  \n",
       "16         0        0     0         0        0   0  \n",
       "18         2        0     0         0        1   0  \n",
       "19         3        0     0         0        0   0  \n",
       "20         0        0     0         0        1   0  \n",
       "21         0        0     5         0        1   0  \n",
       "22         7        0     0         0        0   0  \n",
       "24         0        0     0         1        0   0  \n",
       "25         0        0     0         0        0   0  \n",
       "26         0        0     0         0        0   0  \n",
       "27         7        1     0         0        2   0  \n",
       "28         0        2     0         0        0   0  \n",
       "29         0        0     3         0        0   0  \n",
       "30         0        1     0         0        0   0  \n",
       "31         0        0     0         0        0   0  \n",
       "...      ...      ...   ...       ...      ...  ..  \n",
       "35856      0        0     0         0        0   0  \n",
       "35857      0        0     0         0        0   0  \n",
       "35858      0        0     0         0        1   0  \n",
       "35859      0        0     0         0        0   0  \n",
       "35860      0        0     0         0        0   0  \n",
       "35861      0        0     0         0        1   0  \n",
       "35862      0        0     5         0        0   0  \n",
       "35863      0        0     1         0        0   0  \n",
       "35864      0        0     0         0        1   0  \n",
       "35865      0        0     0         0        0   0  \n",
       "35866      0        0     0         0        0   0  \n",
       "35867      0        0     0         0        0   0  \n",
       "35868      7        0     2         0        1   0  \n",
       "35869      0        0     0         0        0   0  \n",
       "35870     10        0     0         0        0   0  \n",
       "35871      0        0     0         0        0   0  \n",
       "35872      1        1     1         0        1   0  \n",
       "35873      0        0     0         0        0   0  \n",
       "35874      0        0     1         0        2   0  \n",
       "35875      0        0     0         1        1   0  \n",
       "35876      0        0     0         0        0   0  \n",
       "35877      0        0     0         0        1   0  \n",
       "35878      0        0     0         0        0   0  \n",
       "35879      1        0     0         0        1   0  \n",
       "35880      0        0     3         0        0   0  \n",
       "35881      0        0     0         0        2   0  \n",
       "35882      0        0     0         0        0   0  \n",
       "35884      7        1     0         2        0   0  \n",
       "35885      0        0     0         0        0   0  \n",
       "35886      1        1     0         0        1   0  \n",
       "\n",
       "[35714 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all-data/FERPlus/fer2013new.csv')\n",
    "df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0ca1abe4-7bb7-4bbe-8faf-080cad04eaf5"
    }
   },
   "outputs": [],
   "source": [
    "class FaceEmotionsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.emotions_frame = pd.read_csv(csv_file)\n",
    "        self.emotions_frame.dropna(axis=0, how='any', inplace=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.emotions_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.emotions_frame.iloc[idx][1]\n",
    "        \n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = io.imread(img_path)\n",
    "        #this takes the most highest ranked emotion. if two emotions have the same ranking, it just takes the first one\n",
    "        emotion = np.argmax(self.emotions_frame.iloc[idx,2:].as_matrix())\n",
    "        if (emotion == 1 or emotion == 2):\n",
    "            emotion = 1\n",
    "        elif (emotion > 2 and emotion < 8):\n",
    "            emotion = -1\n",
    "        else:\n",
    "            emotion = 0\n",
    "        \n",
    "        sample = {'image': image, 'emotion': emotion}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "7eb85ee3-259b-4395-a288-ee1af15c1f41"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "emotions_frame = pd.read_csv('all-data/FERPlus/fer2013new.csv')\n",
    "emotions_frame.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "emotion = np.argmax(emotions_frame.iloc[10,2:].as_matrix())\n",
    "print(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbpresent": {
     "id": "252d81d5-707f-4133-add3-fe798d2dc52e"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emotion': 4, 'image': array([[ 30,  24,  21, ...,  37,  44,  37],\n",
       "        [ 31,  22,  21, ...,  37,  35,  41],\n",
       "        [ 27,  22,  19, ...,  33,  34,  40],\n",
       "        ..., \n",
       "        [ 29,  29,  26, ..., 118, 132, 148],\n",
       "        [ 30,  30,  27, ..., 154, 159, 166],\n",
       "        [ 32,  29,  28, ..., 172, 173, 173]], dtype=uint8)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_emotions = FaceEmotionsDataset(csv_file = 'all-data/FERPlus/fer2013new_training.csv', \n",
    "                                    root_dir = 'all-data/FERPlus/data/FER2013Train')\n",
    "\n",
    "face_emotions[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0d088434-f0c7-4d61-a29f-29d2529e3ad1"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from skimage import transform\n",
    "from PIL import Image\n",
    "from skimage import io; io.use_plugin('matplotlib')\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, emotion = sample['image'], sample['emotion']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        #print(image.shape)\n",
    "        #image = image.transpose((2, 0, 1))\n",
    "        image = np.expand_dims(image,0)\n",
    "        y = np.copy(image)\n",
    "        z = np.copy(image)\n",
    "        z = np.concatenate((y,z), axis=0)    \n",
    "        image = np.concatenate((image,z), axis=0)\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'emotion': emotion}\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, emotion = sample['image'], sample['emotion']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        #emotion = emotion - [left, top]\n",
    "\n",
    "        return {'image': image, 'emotion': emotion}\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or tuple): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, emotion = sample['image'], sample['emotion']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        \n",
    "        #emotion = emotion * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'emotion': emotion}\n",
    "\n",
    "\n",
    "imgTransform = transforms.Compose([Rescale(256), #scale to 256x256\n",
    "                                   #transforms.CenterCrop(224), #crops the image at center to 224x224\n",
    "                                   RandomCrop(224),\n",
    "                                   ToTensor()\n",
    "                                   ])\n",
    "                                   #, #turn the jpg/pil/wahtever image into a tensor\n",
    "                                   #transforms.Normalize(mean = [0.485, 0.456, 0.406], #normalize with these vals\n",
    "                                                        #std=[0.229, 0.224, 0.225])])\n",
    "                                    ##HOW TO GET NORMALIZED VALUES?\n",
    "                                    #to add: jitter/rotate data augmentation, flipping, \n",
    "                                   \n",
    "#this doesn't work because the data is organized w a csv file w prob distrib of labels \n",
    "#instead of a single ground truth\n",
    "#see this paper: https://arxiv.org/pdf/1608.01041.pdf\n",
    "trainset = FaceEmotionsDataset(csv_file = 'all-data/FERPlus/fer2013new_training.csv', \n",
    "                                    root_dir = 'all-data/FERPlus/data/FER2013Train', transform = imgTransform)\n",
    "valset = FaceEmotionsDataset(csv_file = 'all-data/FERPlus/fer2013new_validation.csv', \n",
    "                                    root_dir = 'all-data/FERPlus/data/FER2013Valid', transform = imgTransform)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size = 32, \n",
    "                                          shuffle = True, num_workers = 0)\n",
    "valLoader = torch.utils.data.DataLoader(valset, batch_size = 32, \n",
    "                                       shuffle = False, num_workers = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( 0 , 0 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.7149  0.7532  0.7916  ...   0.5105  0.5084  0.5062\n",
      "  0.7206  0.7629  0.8053  ...   0.5141  0.5134  0.5128\n",
      "  0.7262  0.7726  0.8189  ...   0.5176  0.5185  0.5194\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.7149  0.7532  0.7916  ...   0.5105  0.5084  0.5062\n",
      "  0.7206  0.7629  0.8053  ...   0.5141  0.5134  0.5128\n",
      "  0.7262  0.7726  0.8189  ...   0.5176  0.5185  0.5194\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.7149  0.7532  0.7916  ...   0.5105  0.5084  0.5062\n",
      "  0.7206  0.7629  0.8053  ...   0.5141  0.5134  0.5128\n",
      "  0.7262  0.7726  0.8189  ...   0.5176  0.5185  0.5194\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.4482  0.4647  0.4804  ...   0.6294  0.6682  0.7070\n",
      "  0.4581  0.4759  0.4927  ...   0.6090  0.6503  0.6916\n",
      "  0.4669  0.4859  0.5036  ...   0.5857  0.6290  0.6723\n",
      "           ...             ⋱             ...          \n",
      "  0.6528  0.6639  0.6764  ...   0.8518  0.8574  0.8629\n",
      "  0.6499  0.6598  0.6710  ...   0.8437  0.8486  0.8534\n",
      "  0.6471  0.6557  0.6655  ...   0.8356  0.8398  0.8439\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.4482  0.4647  0.4804  ...   0.6294  0.6682  0.7070\n",
      "  0.4581  0.4759  0.4927  ...   0.6090  0.6503  0.6916\n",
      "  0.4669  0.4859  0.5036  ...   0.5857  0.6290  0.6723\n",
      "           ...             ⋱             ...          \n",
      "  0.6528  0.6639  0.6764  ...   0.8518  0.8574  0.8629\n",
      "  0.6499  0.6598  0.6710  ...   0.8437  0.8486  0.8534\n",
      "  0.6471  0.6557  0.6655  ...   0.8356  0.8398  0.8439\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.4482  0.4647  0.4804  ...   0.6294  0.6682  0.7070\n",
      "  0.4581  0.4759  0.4927  ...   0.6090  0.6503  0.6916\n",
      "  0.4669  0.4859  0.5036  ...   0.5857  0.6290  0.6723\n",
      "           ...             ⋱             ...          \n",
      "  0.6528  0.6639  0.6764  ...   0.8518  0.8574  0.8629\n",
      "  0.6499  0.6598  0.6710  ...   0.8437  0.8486  0.8534\n",
      "  0.6471  0.6557  0.6655  ...   0.8356  0.8398  0.8439\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.0445  0.0480  0.0515  ...   0.1168  0.1121  0.1074\n",
      "  0.0447  0.0481  0.0515  ...   0.1141  0.1100  0.1058\n",
      "  0.0450  0.0482  0.0515  ...   0.1114  0.1079  0.1043\n",
      "           ...             ⋱             ...          \n",
      "  0.0477  0.0457  0.0437  ...   0.0123  0.0133  0.0143\n",
      "  0.0463  0.0438  0.0415  ...   0.0122  0.0131  0.0140\n",
      "  0.0448  0.0420  0.0393  ...   0.0121  0.0129  0.0137\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.0445  0.0480  0.0515  ...   0.1168  0.1121  0.1074\n",
      "  0.0447  0.0481  0.0515  ...   0.1141  0.1100  0.1058\n",
      "  0.0450  0.0482  0.0515  ...   0.1114  0.1079  0.1043\n",
      "           ...             ⋱             ...          \n",
      "  0.0477  0.0457  0.0437  ...   0.0123  0.0133  0.0143\n",
      "  0.0463  0.0438  0.0415  ...   0.0122  0.0131  0.0140\n",
      "  0.0448  0.0420  0.0393  ...   0.0121  0.0129  0.0137\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.0445  0.0480  0.0515  ...   0.1168  0.1121  0.1074\n",
      "  0.0447  0.0481  0.0515  ...   0.1141  0.1100  0.1058\n",
      "  0.0450  0.0482  0.0515  ...   0.1114  0.1079  0.1043\n",
      "           ...             ⋱             ...          \n",
      "  0.0477  0.0457  0.0437  ...   0.0123  0.0133  0.0143\n",
      "  0.0463  0.0438  0.0415  ...   0.0122  0.0131  0.0140\n",
      "  0.0448  0.0420  0.0393  ...   0.0121  0.0129  0.0137\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(29 , 0 ,.,.) = \n",
      "  0.8591  0.8671  0.8751  ...   0.8074  0.8115  0.8117\n",
      "  0.8588  0.8666  0.8745  ...   0.8022  0.8065  0.8070\n",
      "  0.8585  0.8662  0.8739  ...   0.7971  0.8015  0.8023\n",
      "           ...             ⋱             ...          \n",
      "  0.7917  0.7852  0.7788  ...   0.5568  0.5400  0.5183\n",
      "  0.7907  0.7838  0.7769  ...   0.5485  0.5315  0.5089\n",
      "  0.7896  0.7823  0.7751  ...   0.5402  0.5230  0.4996\n",
      "\n",
      "(29 , 1 ,.,.) = \n",
      "  0.8591  0.8671  0.8751  ...   0.8074  0.8115  0.8117\n",
      "  0.8588  0.8666  0.8745  ...   0.8022  0.8065  0.8070\n",
      "  0.8585  0.8662  0.8739  ...   0.7971  0.8015  0.8023\n",
      "           ...             ⋱             ...          \n",
      "  0.7917  0.7852  0.7788  ...   0.5568  0.5400  0.5183\n",
      "  0.7907  0.7838  0.7769  ...   0.5485  0.5315  0.5089\n",
      "  0.7896  0.7823  0.7751  ...   0.5402  0.5230  0.4996\n",
      "\n",
      "(29 , 2 ,.,.) = \n",
      "  0.8591  0.8671  0.8751  ...   0.8074  0.8115  0.8117\n",
      "  0.8588  0.8666  0.8745  ...   0.8022  0.8065  0.8070\n",
      "  0.8585  0.8662  0.8739  ...   0.7971  0.8015  0.8023\n",
      "           ...             ⋱             ...          \n",
      "  0.7917  0.7852  0.7788  ...   0.5568  0.5400  0.5183\n",
      "  0.7907  0.7838  0.7769  ...   0.5485  0.5315  0.5089\n",
      "  0.7896  0.7823  0.7751  ...   0.5402  0.5230  0.4996\n",
      "      ⋮  \n",
      "\n",
      "(30 , 0 ,.,.) = \n",
      "  0.3865  0.3865  0.3859  ...   0.0501  0.0488  0.0475\n",
      "  0.5086  0.5086  0.5077  ...   0.0660  0.0642  0.0625\n",
      "  0.6306  0.6306  0.6296  ...   0.0818  0.0797  0.0775\n",
      "           ...             ⋱             ...          \n",
      "  0.6764  0.6779  0.6864  ...   0.6986  0.6609  0.6233\n",
      "  0.6775  0.6793  0.6879  ...   0.7009  0.6626  0.6243\n",
      "  0.6785  0.6806  0.6895  ...   0.7033  0.6643  0.6253\n",
      "\n",
      "(30 , 1 ,.,.) = \n",
      "  0.3865  0.3865  0.3859  ...   0.0501  0.0488  0.0475\n",
      "  0.5086  0.5086  0.5077  ...   0.0660  0.0642  0.0625\n",
      "  0.6306  0.6306  0.6296  ...   0.0818  0.0797  0.0775\n",
      "           ...             ⋱             ...          \n",
      "  0.6764  0.6779  0.6864  ...   0.6986  0.6609  0.6233\n",
      "  0.6775  0.6793  0.6879  ...   0.7009  0.6626  0.6243\n",
      "  0.6785  0.6806  0.6895  ...   0.7033  0.6643  0.6253\n",
      "\n",
      "(30 , 2 ,.,.) = \n",
      "  0.3865  0.3865  0.3859  ...   0.0501  0.0488  0.0475\n",
      "  0.5086  0.5086  0.5077  ...   0.0660  0.0642  0.0625\n",
      "  0.6306  0.6306  0.6296  ...   0.0818  0.0797  0.0775\n",
      "           ...             ⋱             ...          \n",
      "  0.6764  0.6779  0.6864  ...   0.6986  0.6609  0.6233\n",
      "  0.6775  0.6793  0.6879  ...   0.7009  0.6626  0.6243\n",
      "  0.6785  0.6806  0.6895  ...   0.7033  0.6643  0.6253\n",
      "      ⋮  \n",
      "\n",
      "(31 , 0 ,.,.) = \n",
      "  0.1772  0.1525  0.1279  ...   0.3481  0.3650  0.3819\n",
      "  0.1809  0.1551  0.1292  ...   0.3439  0.3598  0.3757\n",
      "  0.1842  0.1583  0.1324  ...   0.3423  0.3575  0.3728\n",
      "           ...             ⋱             ...          \n",
      "  0.9028  0.8569  0.8110  ...   0.3834  0.3575  0.3316\n",
      "  0.9000  0.8572  0.8145  ...   0.4060  0.3922  0.3785\n",
      "  0.8971  0.8576  0.8180  ...   0.4286  0.4270  0.4253\n",
      "\n",
      "(31 , 1 ,.,.) = \n",
      "  0.1772  0.1525  0.1279  ...   0.3481  0.3650  0.3819\n",
      "  0.1809  0.1551  0.1292  ...   0.3439  0.3598  0.3757\n",
      "  0.1842  0.1583  0.1324  ...   0.3423  0.3575  0.3728\n",
      "           ...             ⋱             ...          \n",
      "  0.9028  0.8569  0.8110  ...   0.3834  0.3575  0.3316\n",
      "  0.9000  0.8572  0.8145  ...   0.4060  0.3922  0.3785\n",
      "  0.8971  0.8576  0.8180  ...   0.4286  0.4270  0.4253\n",
      "\n",
      "(31 , 2 ,.,.) = \n",
      "  0.1772  0.1525  0.1279  ...   0.3481  0.3650  0.3819\n",
      "  0.1809  0.1551  0.1292  ...   0.3439  0.3598  0.3757\n",
      "  0.1842  0.1583  0.1324  ...   0.3423  0.3575  0.3728\n",
      "           ...             ⋱             ...          \n",
      "  0.9028  0.8569  0.8110  ...   0.3834  0.3575  0.3316\n",
      "  0.9000  0.8572  0.8145  ...   0.4060  0.3922  0.3785\n",
      "  0.8971  0.8576  0.8180  ...   0.4286  0.4270  0.4253\n",
      "[torch.DoubleTensor of size 32x3x224x224]\n",
      ", \n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 8\n",
      " 3\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 0\n",
      " 3\n",
      " 3\n",
      " 1\n",
      " 0\n",
      " 6\n",
      " 1\n",
      " 6\n",
      " 1\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 0\n",
      " 0\n",
      " 3\n",
      " 0\n",
      " 3\n",
      " 0\n",
      " 3\n",
      " 3\n",
      " 1\n",
      " 0\n",
      "[torch.LongTensor of size 32]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (i, sample) in enumerate(trainLoader):\n",
    "    inputs = sample['image']\n",
    "    labels = sample['emotion']\n",
    "    print(\"{}, {}\".format(inputs, labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6d2ad753-43bf-4df1-b903-4dc8b543cff0"
    }
   },
   "source": [
    "### Function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d0d19064-5fe3-4fae-b953-b62bf3aeba34"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  0.7727  0.7678  0.7621  ...   0.1983  0.2016  0.2049\n",
      "  0.7727  0.7679  0.7623  ...   0.2021  0.2044  0.2067\n",
      "  0.7727  0.7680  0.7626  ...   0.2059  0.2072  0.2086\n",
      "           ...             ⋱             ...          \n",
      "  0.4273  0.4255  0.4233  ...   0.4096  0.4164  0.4233\n",
      "  0.4295  0.4277  0.4255  ...   0.4109  0.4180  0.4251\n",
      "  0.4311  0.4294  0.4271  ...   0.4118  0.4191  0.4263\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.7727  0.7678  0.7621  ...   0.1983  0.2016  0.2049\n",
      "  0.7727  0.7679  0.7623  ...   0.2021  0.2044  0.2067\n",
      "  0.7727  0.7680  0.7626  ...   0.2059  0.2072  0.2086\n",
      "           ...             ⋱             ...          \n",
      "  0.4273  0.4255  0.4233  ...   0.4096  0.4164  0.4233\n",
      "  0.4295  0.4277  0.4255  ...   0.4109  0.4180  0.4251\n",
      "  0.4311  0.4294  0.4271  ...   0.4118  0.4191  0.4263\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.7727  0.7678  0.7621  ...   0.1983  0.2016  0.2049\n",
      "  0.7727  0.7679  0.7623  ...   0.2021  0.2044  0.2067\n",
      "  0.7727  0.7680  0.7626  ...   0.2059  0.2072  0.2086\n",
      "           ...             ⋱             ...          \n",
      "  0.4273  0.4255  0.4233  ...   0.4096  0.4164  0.4233\n",
      "  0.4295  0.4277  0.4255  ...   0.4109  0.4180  0.4251\n",
      "  0.4311  0.4294  0.4271  ...   0.4118  0.4191  0.4263\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.1669  0.1676  0.1684  ...   0.2755  0.2786  0.2700\n",
      "  0.1676  0.1684  0.1691  ...   0.2657  0.2744  0.2689\n",
      "  0.1684  0.1691  0.1699  ...   0.2560  0.2701  0.2678\n",
      "           ...             ⋱             ...          \n",
      "  0.1472  0.1478  0.1485  ...   0.5219  0.5165  0.5109\n",
      "  0.1473  0.1485  0.1496  ...   0.5223  0.5166  0.5106\n",
      "  0.1468  0.1482  0.1496  ...   0.5211  0.5147  0.5082\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.1669  0.1676  0.1684  ...   0.2755  0.2786  0.2700\n",
      "  0.1676  0.1684  0.1691  ...   0.2657  0.2744  0.2689\n",
      "  0.1684  0.1691  0.1699  ...   0.2560  0.2701  0.2678\n",
      "           ...             ⋱             ...          \n",
      "  0.1472  0.1478  0.1485  ...   0.5219  0.5165  0.5109\n",
      "  0.1473  0.1485  0.1496  ...   0.5223  0.5166  0.5106\n",
      "  0.1468  0.1482  0.1496  ...   0.5211  0.5147  0.5082\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.1669  0.1676  0.1684  ...   0.2755  0.2786  0.2700\n",
      "  0.1676  0.1684  0.1691  ...   0.2657  0.2744  0.2689\n",
      "  0.1684  0.1691  0.1699  ...   0.2560  0.2701  0.2678\n",
      "           ...             ⋱             ...          \n",
      "  0.1472  0.1478  0.1485  ...   0.5219  0.5165  0.5109\n",
      "  0.1473  0.1485  0.1496  ...   0.5223  0.5166  0.5106\n",
      "  0.1468  0.1482  0.1496  ...   0.5211  0.5147  0.5082\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.7571  0.7566  0.7559  ...   0.4237  0.4103  0.3970\n",
      "  0.7727  0.7721  0.7712  ...   0.4310  0.4166  0.4021\n",
      "  0.7919  0.7911  0.7901  ...   0.4386  0.4236  0.4087\n",
      "           ...             ⋱             ...          \n",
      "  0.3890  0.3848  0.3814  ...   0.1120  0.0979  0.0838\n",
      "  0.3940  0.3901  0.3868  ...   0.1075  0.0944  0.0812\n",
      "  0.3991  0.3953  0.3922  ...   0.1030  0.0908  0.0786\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.7571  0.7566  0.7559  ...   0.4237  0.4103  0.3970\n",
      "  0.7727  0.7721  0.7712  ...   0.4310  0.4166  0.4021\n",
      "  0.7919  0.7911  0.7901  ...   0.4386  0.4236  0.4087\n",
      "           ...             ⋱             ...          \n",
      "  0.3890  0.3848  0.3814  ...   0.1120  0.0979  0.0838\n",
      "  0.3940  0.3901  0.3868  ...   0.1075  0.0944  0.0812\n",
      "  0.3991  0.3953  0.3922  ...   0.1030  0.0908  0.0786\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.7571  0.7566  0.7559  ...   0.4237  0.4103  0.3970\n",
      "  0.7727  0.7721  0.7712  ...   0.4310  0.4166  0.4021\n",
      "  0.7919  0.7911  0.7901  ...   0.4386  0.4236  0.4087\n",
      "           ...             ⋱             ...          \n",
      "  0.3890  0.3848  0.3814  ...   0.1120  0.0979  0.0838\n",
      "  0.3940  0.3901  0.3868  ...   0.1075  0.0944  0.0812\n",
      "  0.3991  0.3953  0.3922  ...   0.1030  0.0908  0.0786\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(29 , 0 ,.,.) = \n",
      "  0.9443  0.9461  0.9478  ...   0.7790  0.8425  0.8628\n",
      "  0.9441  0.9457  0.9473  ...   0.7544  0.8270  0.8505\n",
      "  0.9440  0.9455  0.9469  ...   0.7253  0.8042  0.8317\n",
      "           ...             ⋱             ...          \n",
      "  0.6852  0.7253  0.7654  ...   0.5637  0.5630  0.5648\n",
      "  0.6786  0.7196  0.7605  ...   0.5600  0.5593  0.5612\n",
      "  0.6721  0.7138  0.7556  ...   0.5564  0.5556  0.5576\n",
      "\n",
      "(29 , 1 ,.,.) = \n",
      "  0.9443  0.9461  0.9478  ...   0.7790  0.8425  0.8628\n",
      "  0.9441  0.9457  0.9473  ...   0.7544  0.8270  0.8505\n",
      "  0.9440  0.9455  0.9469  ...   0.7253  0.8042  0.8317\n",
      "           ...             ⋱             ...          \n",
      "  0.6852  0.7253  0.7654  ...   0.5637  0.5630  0.5648\n",
      "  0.6786  0.7196  0.7605  ...   0.5600  0.5593  0.5612\n",
      "  0.6721  0.7138  0.7556  ...   0.5564  0.5556  0.5576\n",
      "\n",
      "(29 , 2 ,.,.) = \n",
      "  0.9443  0.9461  0.9478  ...   0.7790  0.8425  0.8628\n",
      "  0.9441  0.9457  0.9473  ...   0.7544  0.8270  0.8505\n",
      "  0.9440  0.9455  0.9469  ...   0.7253  0.8042  0.8317\n",
      "           ...             ⋱             ...          \n",
      "  0.6852  0.7253  0.7654  ...   0.5637  0.5630  0.5648\n",
      "  0.6786  0.7196  0.7605  ...   0.5600  0.5593  0.5612\n",
      "  0.6721  0.7138  0.7556  ...   0.5564  0.5556  0.5576\n",
      "      ⋮  \n",
      "\n",
      "(30 , 0 ,.,.) = \n",
      "  0.9961  0.9961  0.9961  ...   0.1283  0.1411  0.1539\n",
      "  0.9961  0.9961  0.9961  ...   0.1312  0.1423  0.1534\n",
      "  0.9961  0.9961  0.9961  ...   0.1340  0.1435  0.1530\n",
      "           ...             ⋱             ...          \n",
      "  0.9882  0.9880  0.9875  ...   0.6189  0.6121  0.6052\n",
      "  0.9882  0.9879  0.9873  ...   0.6162  0.6091  0.6020\n",
      "  0.9574  0.9570  0.9563  ...   0.5948  0.5877  0.5805\n",
      "\n",
      "(30 , 1 ,.,.) = \n",
      "  0.9961  0.9961  0.9961  ...   0.1283  0.1411  0.1539\n",
      "  0.9961  0.9961  0.9961  ...   0.1312  0.1423  0.1534\n",
      "  0.9961  0.9961  0.9961  ...   0.1340  0.1435  0.1530\n",
      "           ...             ⋱             ...          \n",
      "  0.9882  0.9880  0.9875  ...   0.6189  0.6121  0.6052\n",
      "  0.9882  0.9879  0.9873  ...   0.6162  0.6091  0.6020\n",
      "  0.9574  0.9570  0.9563  ...   0.5948  0.5877  0.5805\n",
      "\n",
      "(30 , 2 ,.,.) = \n",
      "  0.9961  0.9961  0.9961  ...   0.1283  0.1411  0.1539\n",
      "  0.9961  0.9961  0.9961  ...   0.1312  0.1423  0.1534\n",
      "  0.9961  0.9961  0.9961  ...   0.1340  0.1435  0.1530\n",
      "           ...             ⋱             ...          \n",
      "  0.9882  0.9880  0.9875  ...   0.6189  0.6121  0.6052\n",
      "  0.9882  0.9879  0.9873  ...   0.6162  0.6091  0.6020\n",
      "  0.9574  0.9570  0.9563  ...   0.5948  0.5877  0.5805\n",
      "      ⋮  \n",
      "\n",
      "(31 , 0 ,.,.) = \n",
      "  0.1872  0.1763  0.1654  ...   0.3829  0.3820  0.3822\n",
      "  0.2463  0.2320  0.2176  ...   0.5038  0.5026  0.5029\n",
      "  0.3055  0.2877  0.2698  ...   0.6247  0.6233  0.6236\n",
      "           ...             ⋱             ...          \n",
      "  0.0053  0.0082  0.0111  ...   0.2076  0.2076  0.2076\n",
      "  0.0048  0.0074  0.0100  ...   0.2061  0.2061  0.2063\n",
      "  0.0043  0.0066  0.0090  ...   0.2047  0.2047  0.2049\n",
      "\n",
      "(31 , 1 ,.,.) = \n",
      "  0.1872  0.1763  0.1654  ...   0.3829  0.3820  0.3822\n",
      "  0.2463  0.2320  0.2176  ...   0.5038  0.5026  0.5029\n",
      "  0.3055  0.2877  0.2698  ...   0.6247  0.6233  0.6236\n",
      "           ...             ⋱             ...          \n",
      "  0.0053  0.0082  0.0111  ...   0.2076  0.2076  0.2076\n",
      "  0.0048  0.0074  0.0100  ...   0.2061  0.2061  0.2063\n",
      "  0.0043  0.0066  0.0090  ...   0.2047  0.2047  0.2049\n",
      "\n",
      "(31 , 2 ,.,.) = \n",
      "  0.1872  0.1763  0.1654  ...   0.3829  0.3820  0.3822\n",
      "  0.2463  0.2320  0.2176  ...   0.5038  0.5026  0.5029\n",
      "  0.3055  0.2877  0.2698  ...   0.6247  0.6233  0.6236\n",
      "           ...             ⋱             ...          \n",
      "  0.0053  0.0082  0.0111  ...   0.2076  0.2076  0.2076\n",
      "  0.0048  0.0074  0.0100  ...   0.2061  0.2061  0.2063\n",
      "  0.0043  0.0066  0.0090  ...   0.2047  0.2047  0.2049\n",
      "[torch.FloatTensor of size 32x3x224x224]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 3\n",
      " 3\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 4\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 3\n",
      " 0\n",
      " 3\n",
      " 3\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 3\n",
      " 2\n",
      " 1\n",
      " 4\n",
      " 1\n",
      " 3\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 32]\n",
      "\n",
      "Variable containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  0.5408  0.5428  0.5431  ...   0.7451  0.7451  0.7451\n",
      "  0.5424  0.5433  0.5424  ...   0.7451  0.7451  0.7451\n",
      "  0.5439  0.5439  0.5416  ...   0.7451  0.7451  0.7451\n",
      "           ...             ⋱             ...          \n",
      "  0.5173  0.5139  0.5110  ...   0.4066  0.4035  0.4003\n",
      "  0.5006  0.4972  0.4943  ...   0.3881  0.3860  0.3838\n",
      "  0.4037  0.4010  0.3987  ...   0.3130  0.3113  0.3095\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.5408  0.5428  0.5431  ...   0.7451  0.7451  0.7451\n",
      "  0.5424  0.5433  0.5424  ...   0.7451  0.7451  0.7451\n",
      "  0.5439  0.5439  0.5416  ...   0.7451  0.7451  0.7451\n",
      "           ...             ⋱             ...          \n",
      "  0.5173  0.5139  0.5110  ...   0.4066  0.4035  0.4003\n",
      "  0.5006  0.4972  0.4943  ...   0.3881  0.3860  0.3838\n",
      "  0.4037  0.4010  0.3987  ...   0.3130  0.3113  0.3095\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.5408  0.5428  0.5431  ...   0.7451  0.7451  0.7451\n",
      "  0.5424  0.5433  0.5424  ...   0.7451  0.7451  0.7451\n",
      "  0.5439  0.5439  0.5416  ...   0.7451  0.7451  0.7451\n",
      "           ...             ⋱             ...          \n",
      "  0.5173  0.5139  0.5110  ...   0.4066  0.4035  0.4003\n",
      "  0.5006  0.4972  0.4943  ...   0.3881  0.3860  0.3838\n",
      "  0.4037  0.4010  0.3987  ...   0.3130  0.3113  0.3095\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.0100  0.0131  0.0163  ...   0.3502  0.3442  0.3382\n",
      "  0.0113  0.0148  0.0184  ...   0.3546  0.3483  0.3420\n",
      "  0.0126  0.0166  0.0205  ...   0.3590  0.3524  0.3458\n",
      "           ...             ⋱             ...          \n",
      "  0.4693  0.6174  0.7656  ...   0.4197  0.4233  0.4269\n",
      "  0.4697  0.6180  0.7663  ...   0.4167  0.4197  0.4227\n",
      "  0.4701  0.6186  0.7670  ...   0.4136  0.4161  0.4186\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.0100  0.0131  0.0163  ...   0.3502  0.3442  0.3382\n",
      "  0.0113  0.0148  0.0184  ...   0.3546  0.3483  0.3420\n",
      "  0.0126  0.0166  0.0205  ...   0.3590  0.3524  0.3458\n",
      "           ...             ⋱             ...          \n",
      "  0.4693  0.6174  0.7656  ...   0.4197  0.4233  0.4269\n",
      "  0.4697  0.6180  0.7663  ...   0.4167  0.4197  0.4227\n",
      "  0.4701  0.6186  0.7670  ...   0.4136  0.4161  0.4186\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.0100  0.0131  0.0163  ...   0.3502  0.3442  0.3382\n",
      "  0.0113  0.0148  0.0184  ...   0.3546  0.3483  0.3420\n",
      "  0.0126  0.0166  0.0205  ...   0.3590  0.3524  0.3458\n",
      "           ...             ⋱             ...          \n",
      "  0.4693  0.6174  0.7656  ...   0.4197  0.4233  0.4269\n",
      "  0.4697  0.6180  0.7663  ...   0.4167  0.4197  0.4227\n",
      "  0.4701  0.6186  0.7670  ...   0.4136  0.4161  0.4186\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.0982  0.1292  0.1602  ...   0.8169  0.8168  0.8167\n",
      "  0.0986  0.1297  0.1609  ...   0.8183  0.8181  0.8178\n",
      "  0.0990  0.1303  0.1616  ...   0.8198  0.8194  0.8190\n",
      "           ...             ⋱             ...          \n",
      "  0.1419  0.1867  0.2315  ...   0.8979  0.8972  0.8964\n",
      "  0.1463  0.1924  0.2386  ...   0.8979  0.8972  0.8964\n",
      "  0.1506  0.1982  0.2457  ...   0.8979  0.8972  0.8964\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.0982  0.1292  0.1602  ...   0.8169  0.8168  0.8167\n",
      "  0.0986  0.1297  0.1609  ...   0.8183  0.8181  0.8178\n",
      "  0.0990  0.1303  0.1616  ...   0.8198  0.8194  0.8190\n",
      "           ...             ⋱             ...          \n",
      "  0.1419  0.1867  0.2315  ...   0.8979  0.8972  0.8964\n",
      "  0.1463  0.1924  0.2386  ...   0.8979  0.8972  0.8964\n",
      "  0.1506  0.1982  0.2457  ...   0.8979  0.8972  0.8964\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.0982  0.1292  0.1602  ...   0.8169  0.8168  0.8167\n",
      "  0.0986  0.1297  0.1609  ...   0.8183  0.8181  0.8178\n",
      "  0.0990  0.1303  0.1616  ...   0.8198  0.8194  0.8190\n",
      "           ...             ⋱             ...          \n",
      "  0.1419  0.1867  0.2315  ...   0.8979  0.8972  0.8964\n",
      "  0.1463  0.1924  0.2386  ...   0.8979  0.8972  0.8964\n",
      "  0.1506  0.1982  0.2457  ...   0.8979  0.8972  0.8964\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(29 , 0 ,.,.) = \n",
      "  0.0213  0.0197  0.0182  ...   0.7597  0.7624  0.7653\n",
      "  0.0214  0.0204  0.0194  ...   0.7581  0.7616  0.7646\n",
      "  0.0215  0.0210  0.0206  ...   0.7566  0.7609  0.7638\n",
      "           ...             ⋱             ...          \n",
      "  0.2163  0.2238  0.2314  ...   0.6019  0.6049  0.6079\n",
      "  0.2168  0.2250  0.2333  ...   0.6048  0.6075  0.6101\n",
      "  0.2104  0.2189  0.2275  ...   0.5881  0.5906  0.5928\n",
      "\n",
      "(29 , 1 ,.,.) = \n",
      "  0.0213  0.0197  0.0182  ...   0.7597  0.7624  0.7653\n",
      "  0.0214  0.0204  0.0194  ...   0.7581  0.7616  0.7646\n",
      "  0.0215  0.0210  0.0206  ...   0.7566  0.7609  0.7638\n",
      "           ...             ⋱             ...          \n",
      "  0.2163  0.2238  0.2314  ...   0.6019  0.6049  0.6079\n",
      "  0.2168  0.2250  0.2333  ...   0.6048  0.6075  0.6101\n",
      "  0.2104  0.2189  0.2275  ...   0.5881  0.5906  0.5928\n",
      "\n",
      "(29 , 2 ,.,.) = \n",
      "  0.0213  0.0197  0.0182  ...   0.7597  0.7624  0.7653\n",
      "  0.0214  0.0204  0.0194  ...   0.7581  0.7616  0.7646\n",
      "  0.0215  0.0210  0.0206  ...   0.7566  0.7609  0.7638\n",
      "           ...             ⋱             ...          \n",
      "  0.2163  0.2238  0.2314  ...   0.6019  0.6049  0.6079\n",
      "  0.2168  0.2250  0.2333  ...   0.6048  0.6075  0.6101\n",
      "  0.2104  0.2189  0.2275  ...   0.5881  0.5906  0.5928\n",
      "      ⋮  \n",
      "\n",
      "(30 , 0 ,.,.) = \n",
      "  0.4878  0.4753  0.4671  ...   1.0000  1.0000  1.0000\n",
      "  0.4808  0.4703  0.4639  ...   1.0000  1.0000  1.0000\n",
      "  0.4739  0.4653  0.4607  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.4192  0.4328  0.4699  ...   0.2912  0.2848  0.2784\n",
      "  0.3997  0.4113  0.4466  ...   0.2902  0.2801  0.2700\n",
      "  0.3825  0.3920  0.4251  ...   0.2885  0.2755  0.2626\n",
      "\n",
      "(30 , 1 ,.,.) = \n",
      "  0.4878  0.4753  0.4671  ...   1.0000  1.0000  1.0000\n",
      "  0.4808  0.4703  0.4639  ...   1.0000  1.0000  1.0000\n",
      "  0.4739  0.4653  0.4607  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.4192  0.4328  0.4699  ...   0.2912  0.2848  0.2784\n",
      "  0.3997  0.4113  0.4466  ...   0.2902  0.2801  0.2700\n",
      "  0.3825  0.3920  0.4251  ...   0.2885  0.2755  0.2626\n",
      "\n",
      "(30 , 2 ,.,.) = \n",
      "  0.4878  0.4753  0.4671  ...   1.0000  1.0000  1.0000\n",
      "  0.4808  0.4703  0.4639  ...   1.0000  1.0000  1.0000\n",
      "  0.4739  0.4653  0.4607  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.4192  0.4328  0.4699  ...   0.2912  0.2848  0.2784\n",
      "  0.3997  0.4113  0.4466  ...   0.2902  0.2801  0.2700\n",
      "  0.3825  0.3920  0.4251  ...   0.2885  0.2755  0.2626\n",
      "      ⋮  \n",
      "\n",
      "(31 , 0 ,.,.) = \n",
      "  0.3140  0.4131  0.5123  ...   0.1075  0.1089  0.1103\n",
      "  0.3214  0.4229  0.5244  ...   0.1081  0.1087  0.1093\n",
      "  0.3288  0.4327  0.5365  ...   0.1087  0.1084  0.1082\n",
      "           ...             ⋱             ...          \n",
      "  0.0549  0.0549  0.0608  ...   0.5505  0.5566  0.5626\n",
      "  0.0549  0.0549  0.0608  ...   0.5534  0.5593  0.5652\n",
      "  0.0549  0.0549  0.0643  ...   0.5617  0.5662  0.5707\n",
      "\n",
      "(31 , 1 ,.,.) = \n",
      "  0.3140  0.4131  0.5123  ...   0.1075  0.1089  0.1103\n",
      "  0.3214  0.4229  0.5244  ...   0.1081  0.1087  0.1093\n",
      "  0.3288  0.4327  0.5365  ...   0.1087  0.1084  0.1082\n",
      "           ...             ⋱             ...          \n",
      "  0.0549  0.0549  0.0608  ...   0.5505  0.5566  0.5626\n",
      "  0.0549  0.0549  0.0608  ...   0.5534  0.5593  0.5652\n",
      "  0.0549  0.0549  0.0643  ...   0.5617  0.5662  0.5707\n",
      "\n",
      "(31 , 2 ,.,.) = \n",
      "  0.3140  0.4131  0.5123  ...   0.1075  0.1089  0.1103\n",
      "  0.3214  0.4229  0.5244  ...   0.1081  0.1087  0.1093\n",
      "  0.3288  0.4327  0.5365  ...   0.1087  0.1084  0.1082\n",
      "           ...             ⋱             ...          \n",
      "  0.0549  0.0549  0.0608  ...   0.5505  0.5566  0.5626\n",
      "  0.0549  0.0549  0.0608  ...   0.5534  0.5593  0.5652\n",
      "  0.0549  0.0549  0.0643  ...   0.5617  0.5662  0.5707\n",
      "[torch.FloatTensor of size 32x3x224x224]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 6\n",
      " 1\n",
      " 0\n",
      " 3\n",
      " 4\n",
      " 2\n",
      " 0\n",
      " 1\n",
      " 4\n",
      " 0\n",
      " 2\n",
      " 2\n",
      " 4\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 4\n",
      " 2\n",
      " 0\n",
      " 3\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 32]\n",
      "\n",
      "Variable containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  0.6634  0.6694  0.6754  ...   0.0970  0.0979  0.1110\n",
      "  0.6613  0.6682  0.6750  ...   0.1010  0.1012  0.1139\n",
      "  0.6592  0.6669  0.6746  ...   0.1049  0.1045  0.1169\n",
      "           ...             ⋱             ...          \n",
      "  0.1476  0.1549  0.1621  ...   0.0887  0.0935  0.0973\n",
      "  0.1507  0.1544  0.1580  ...   0.0875  0.0918  0.0953\n",
      "  0.1538  0.1539  0.1539  ...   0.0863  0.0901  0.0933\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.6634  0.6694  0.6754  ...   0.0970  0.0979  0.1110\n",
      "  0.6613  0.6682  0.6750  ...   0.1010  0.1012  0.1139\n",
      "  0.6592  0.6669  0.6746  ...   0.1049  0.1045  0.1169\n",
      "           ...             ⋱             ...          \n",
      "  0.1476  0.1549  0.1621  ...   0.0887  0.0935  0.0973\n",
      "  0.1507  0.1544  0.1580  ...   0.0875  0.0918  0.0953\n",
      "  0.1538  0.1539  0.1539  ...   0.0863  0.0901  0.0933\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.6634  0.6694  0.6754  ...   0.0970  0.0979  0.1110\n",
      "  0.6613  0.6682  0.6750  ...   0.1010  0.1012  0.1139\n",
      "  0.6592  0.6669  0.6746  ...   0.1049  0.1045  0.1169\n",
      "           ...             ⋱             ...          \n",
      "  0.1476  0.1549  0.1621  ...   0.0887  0.0935  0.0973\n",
      "  0.1507  0.1544  0.1580  ...   0.0875  0.0918  0.0953\n",
      "  0.1538  0.1539  0.1539  ...   0.0863  0.0901  0.0933\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.0575  0.0562  0.0577  ...   0.6328  0.6306  0.6284\n",
      "  0.0581  0.0569  0.0583  ...   0.6321  0.6299  0.6277\n",
      "  0.0586  0.0575  0.0590  ...   0.6314  0.6292  0.6270\n",
      "           ...             ⋱             ...          \n",
      "  0.3845  0.3786  0.3759  ...   0.4542  0.4533  0.4524\n",
      "  0.3856  0.3804  0.3776  ...   0.4539  0.4528  0.4516\n",
      "  0.3868  0.3823  0.3794  ...   0.4537  0.4523  0.4509\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.0575  0.0562  0.0577  ...   0.6328  0.6306  0.6284\n",
      "  0.0581  0.0569  0.0583  ...   0.6321  0.6299  0.6277\n",
      "  0.0586  0.0575  0.0590  ...   0.6314  0.6292  0.6270\n",
      "           ...             ⋱             ...          \n",
      "  0.3845  0.3786  0.3759  ...   0.4542  0.4533  0.4524\n",
      "  0.3856  0.3804  0.3776  ...   0.4539  0.4528  0.4516\n",
      "  0.3868  0.3823  0.3794  ...   0.4537  0.4523  0.4509\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.0575  0.0562  0.0577  ...   0.6328  0.6306  0.6284\n",
      "  0.0581  0.0569  0.0583  ...   0.6321  0.6299  0.6277\n",
      "  0.0586  0.0575  0.0590  ...   0.6314  0.6292  0.6270\n",
      "           ...             ⋱             ...          \n",
      "  0.3845  0.3786  0.3759  ...   0.4542  0.4533  0.4524\n",
      "  0.3856  0.3804  0.3776  ...   0.4539  0.4528  0.4516\n",
      "  0.3868  0.3823  0.3794  ...   0.4537  0.4523  0.4509\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.1968  0.2008  0.2050  ...   0.3319  0.3294  0.3270\n",
      "  0.1970  0.2009  0.2041  ...   0.3241  0.3217  0.3194\n",
      "  0.1979  0.2021  0.2043  ...   0.3162  0.3143  0.3123\n",
      "           ...             ⋱             ...          \n",
      "  0.3752  0.3883  0.3885  ...   0.3234  0.3346  0.3457\n",
      "  0.3672  0.3804  0.3813  ...   0.3423  0.3670  0.3917\n",
      "  0.3591  0.3726  0.3740  ...   0.3612  0.3994  0.4376\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.1968  0.2008  0.2050  ...   0.3319  0.3294  0.3270\n",
      "  0.1970  0.2009  0.2041  ...   0.3241  0.3217  0.3194\n",
      "  0.1979  0.2021  0.2043  ...   0.3162  0.3143  0.3123\n",
      "           ...             ⋱             ...          \n",
      "  0.3752  0.3883  0.3885  ...   0.3234  0.3346  0.3457\n",
      "  0.3672  0.3804  0.3813  ...   0.3423  0.3670  0.3917\n",
      "  0.3591  0.3726  0.3740  ...   0.3612  0.3994  0.4376\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.1968  0.2008  0.2050  ...   0.3319  0.3294  0.3270\n",
      "  0.1970  0.2009  0.2041  ...   0.3241  0.3217  0.3194\n",
      "  0.1979  0.2021  0.2043  ...   0.3162  0.3143  0.3123\n",
      "           ...             ⋱             ...          \n",
      "  0.3752  0.3883  0.3885  ...   0.3234  0.3346  0.3457\n",
      "  0.3672  0.3804  0.3813  ...   0.3423  0.3670  0.3917\n",
      "  0.3591  0.3726  0.3740  ...   0.3612  0.3994  0.4376\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(29 , 0 ,.,.) = \n",
      "  0.0046  0.0040  0.0039  ...   0.1803  0.2676  0.3549\n",
      "  0.0048  0.0040  0.0039  ...   0.1795  0.2655  0.3514\n",
      "  0.0048  0.0040  0.0039  ...   0.1836  0.2693  0.3550\n",
      "           ...             ⋱             ...          \n",
      "  0.2158  0.2173  0.2191  ...   0.4216  0.4208  0.4201\n",
      "  0.2092  0.2107  0.2127  ...   0.4208  0.4201  0.4194\n",
      "  0.2026  0.2040  0.2063  ...   0.4201  0.4194  0.4186\n",
      "\n",
      "(29 , 1 ,.,.) = \n",
      "  0.0046  0.0040  0.0039  ...   0.1803  0.2676  0.3549\n",
      "  0.0048  0.0040  0.0039  ...   0.1795  0.2655  0.3514\n",
      "  0.0048  0.0040  0.0039  ...   0.1836  0.2693  0.3550\n",
      "           ...             ⋱             ...          \n",
      "  0.2158  0.2173  0.2191  ...   0.4216  0.4208  0.4201\n",
      "  0.2092  0.2107  0.2127  ...   0.4208  0.4201  0.4194\n",
      "  0.2026  0.2040  0.2063  ...   0.4201  0.4194  0.4186\n",
      "\n",
      "(29 , 2 ,.,.) = \n",
      "  0.0046  0.0040  0.0039  ...   0.1803  0.2676  0.3549\n",
      "  0.0048  0.0040  0.0039  ...   0.1795  0.2655  0.3514\n",
      "  0.0048  0.0040  0.0039  ...   0.1836  0.2693  0.3550\n",
      "           ...             ⋱             ...          \n",
      "  0.2158  0.2173  0.2191  ...   0.4216  0.4208  0.4201\n",
      "  0.2092  0.2107  0.2127  ...   0.4208  0.4201  0.4194\n",
      "  0.2026  0.2040  0.2063  ...   0.4201  0.4194  0.4186\n",
      "      ⋮  \n",
      "\n",
      "(30 , 0 ,.,.) = \n",
      "  0.3769  0.3695  0.3622  ...   0.4400  0.4388  0.4377\n",
      "  0.3762  0.3665  0.3568  ...   0.4394  0.4373  0.4364\n",
      "  0.3756  0.3635  0.3515  ...   0.4387  0.4359  0.4351\n",
      "           ...             ⋱             ...          \n",
      "  0.1945  0.2097  0.2249  ...   0.1561  0.1603  0.1596\n",
      "  0.1804  0.1932  0.2060  ...   0.1570  0.1607  0.1599\n",
      "  0.1658  0.1762  0.1866  ...   0.1575  0.1607  0.1599\n",
      "\n",
      "(30 , 1 ,.,.) = \n",
      "  0.3769  0.3695  0.3622  ...   0.4400  0.4388  0.4377\n",
      "  0.3762  0.3665  0.3568  ...   0.4394  0.4373  0.4364\n",
      "  0.3756  0.3635  0.3515  ...   0.4387  0.4359  0.4351\n",
      "           ...             ⋱             ...          \n",
      "  0.1945  0.2097  0.2249  ...   0.1561  0.1603  0.1596\n",
      "  0.1804  0.1932  0.2060  ...   0.1570  0.1607  0.1599\n",
      "  0.1658  0.1762  0.1866  ...   0.1575  0.1607  0.1599\n",
      "\n",
      "(30 , 2 ,.,.) = \n",
      "  0.3769  0.3695  0.3622  ...   0.4400  0.4388  0.4377\n",
      "  0.3762  0.3665  0.3568  ...   0.4394  0.4373  0.4364\n",
      "  0.3756  0.3635  0.3515  ...   0.4387  0.4359  0.4351\n",
      "           ...             ⋱             ...          \n",
      "  0.1945  0.2097  0.2249  ...   0.1561  0.1603  0.1596\n",
      "  0.1804  0.1932  0.2060  ...   0.1570  0.1607  0.1599\n",
      "  0.1658  0.1762  0.1866  ...   0.1575  0.1607  0.1599\n",
      "      ⋮  \n",
      "\n",
      "(31 , 0 ,.,.) = \n",
      "  0.9595  0.9454  0.9313  ...   0.9697  0.9759  0.9811\n",
      "  0.9543  0.9393  0.9244  ...   0.9637  0.9704  0.9760\n",
      "  0.9490  0.9332  0.9174  ...   0.9578  0.9648  0.9709\n",
      "           ...             ⋱             ...          \n",
      "  0.3275  0.3261  0.3248  ...   0.1805  0.1797  0.1791\n",
      "  0.3259  0.3237  0.3215  ...   0.1819  0.1802  0.1786\n",
      "  0.3243  0.3213  0.3183  ...   0.1832  0.1808  0.1780\n",
      "\n",
      "(31 , 1 ,.,.) = \n",
      "  0.9595  0.9454  0.9313  ...   0.9697  0.9759  0.9811\n",
      "  0.9543  0.9393  0.9244  ...   0.9637  0.9704  0.9760\n",
      "  0.9490  0.9332  0.9174  ...   0.9578  0.9648  0.9709\n",
      "           ...             ⋱             ...          \n",
      "  0.3275  0.3261  0.3248  ...   0.1805  0.1797  0.1791\n",
      "  0.3259  0.3237  0.3215  ...   0.1819  0.1802  0.1786\n",
      "  0.3243  0.3213  0.3183  ...   0.1832  0.1808  0.1780\n",
      "\n",
      "(31 , 2 ,.,.) = \n",
      "  0.9595  0.9454  0.9313  ...   0.9697  0.9759  0.9811\n",
      "  0.9543  0.9393  0.9244  ...   0.9637  0.9704  0.9760\n",
      "  0.9490  0.9332  0.9174  ...   0.9578  0.9648  0.9709\n",
      "           ...             ⋱             ...          \n",
      "  0.3275  0.3261  0.3248  ...   0.1805  0.1797  0.1791\n",
      "  0.3259  0.3237  0.3215  ...   0.1819  0.1802  0.1786\n",
      "  0.3243  0.3213  0.3183  ...   0.1832  0.1808  0.1780\n",
      "[torch.FloatTensor of size 32x3x224x224]\n",
      "\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 4\n",
      " 3\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 3\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 2\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 4\n",
      " 4\n",
      " 0\n",
      " 3\n",
      " 3\n",
      " 0\n",
      " 4\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 4\n",
      "[torch.LongTensor of size 32]\n",
      "\n",
      "Variable containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  0.2280  0.2179  0.2085  ...   0.1522  0.1679  0.1837\n",
      "  0.3000  0.2867  0.2744  ...   0.2003  0.2210  0.2417\n",
      "  0.3719  0.3556  0.3402  ...   0.2484  0.2740  0.2996\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.2280  0.2179  0.2085  ...   0.1522  0.1679  0.1837\n",
      "  0.3000  0.2867  0.2744  ...   0.2003  0.2210  0.2417\n",
      "  0.3719  0.3556  0.3402  ...   0.2484  0.2740  0.2996\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.2280  0.2179  0.2085  ...   0.1522  0.1679  0.1837\n",
      "  0.3000  0.2867  0.2744  ...   0.2003  0.2210  0.2417\n",
      "  0.3719  0.3556  0.3402  ...   0.2484  0.2740  0.2996\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.9432  0.9769  0.9808  ...   0.3971  0.3901  0.3831\n",
      "  0.9439  0.9777  0.9818  ...   0.3953  0.3861  0.3769\n",
      "  0.9446  0.9786  0.9827  ...   0.3934  0.3820  0.3706\n",
      "           ...             ⋱             ...          \n",
      "  0.9650  0.9967  0.9974  ...   0.6480  0.6487  0.6495\n",
      "  0.9650  0.9967  0.9974  ...   0.6427  0.6444  0.6462\n",
      "  0.9653  0.9968  0.9972  ...   0.6396  0.6416  0.6436\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.9432  0.9769  0.9808  ...   0.3971  0.3901  0.3831\n",
      "  0.9439  0.9777  0.9818  ...   0.3953  0.3861  0.3769\n",
      "  0.9446  0.9786  0.9827  ...   0.3934  0.3820  0.3706\n",
      "           ...             ⋱             ...          \n",
      "  0.9650  0.9967  0.9974  ...   0.6480  0.6487  0.6495\n",
      "  0.9650  0.9967  0.9974  ...   0.6427  0.6444  0.6462\n",
      "  0.9653  0.9968  0.9972  ...   0.6396  0.6416  0.6436\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.9432  0.9769  0.9808  ...   0.3971  0.3901  0.3831\n",
      "  0.9439  0.9777  0.9818  ...   0.3953  0.3861  0.3769\n",
      "  0.9446  0.9786  0.9827  ...   0.3934  0.3820  0.3706\n",
      "           ...             ⋱             ...          \n",
      "  0.9650  0.9967  0.9974  ...   0.6480  0.6487  0.6495\n",
      "  0.9650  0.9967  0.9974  ...   0.6427  0.6444  0.6462\n",
      "  0.9653  0.9968  0.9972  ...   0.6396  0.6416  0.6436\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.9736  0.9743  0.9751  ...   0.4054  0.3942  0.3806\n",
      "  0.9745  0.9753  0.9762  ...   0.4106  0.3986  0.3840\n",
      "  0.9753  0.9764  0.9774  ...   0.4158  0.4030  0.3874\n",
      "           ...             ⋱             ...          \n",
      "  0.1058  0.1125  0.1191  ...   0.0926  0.0915  0.0896\n",
      "  0.1055  0.1119  0.1183  ...   0.0904  0.0890  0.0867\n",
      "  0.1052  0.1113  0.1174  ...   0.0882  0.0864  0.0839\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.9736  0.9743  0.9751  ...   0.4054  0.3942  0.3806\n",
      "  0.9745  0.9753  0.9762  ...   0.4106  0.3986  0.3840\n",
      "  0.9753  0.9764  0.9774  ...   0.4158  0.4030  0.3874\n",
      "           ...             ⋱             ...          \n",
      "  0.1058  0.1125  0.1191  ...   0.0926  0.0915  0.0896\n",
      "  0.1055  0.1119  0.1183  ...   0.0904  0.0890  0.0867\n",
      "  0.1052  0.1113  0.1174  ...   0.0882  0.0864  0.0839\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.9736  0.9743  0.9751  ...   0.4054  0.3942  0.3806\n",
      "  0.9745  0.9753  0.9762  ...   0.4106  0.3986  0.3840\n",
      "  0.9753  0.9764  0.9774  ...   0.4158  0.4030  0.3874\n",
      "           ...             ⋱             ...          \n",
      "  0.1058  0.1125  0.1191  ...   0.0926  0.0915  0.0896\n",
      "  0.1055  0.1119  0.1183  ...   0.0904  0.0890  0.0867\n",
      "  0.1052  0.1113  0.1174  ...   0.0882  0.0864  0.0839\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(29 , 0 ,.,.) = \n",
      "  0.0553  0.0410  0.0268  ...   0.1819  0.1811  0.1833\n",
      "  0.0489  0.0373  0.0256  ...   0.1841  0.1833  0.1854\n",
      "  0.0426  0.0336  0.0245  ...   0.1863  0.1855  0.1874\n",
      "           ...             ⋱             ...          \n",
      "  0.0981  0.1072  0.1164  ...   0.1043  0.1065  0.1104\n",
      "  0.0980  0.1075  0.1171  ...   0.0975  0.0974  0.1010\n",
      "  0.0979  0.1078  0.1178  ...   0.0907  0.0882  0.0917\n",
      "\n",
      "(29 , 1 ,.,.) = \n",
      "  0.0553  0.0410  0.0268  ...   0.1819  0.1811  0.1833\n",
      "  0.0489  0.0373  0.0256  ...   0.1841  0.1833  0.1854\n",
      "  0.0426  0.0336  0.0245  ...   0.1863  0.1855  0.1874\n",
      "           ...             ⋱             ...          \n",
      "  0.0981  0.1072  0.1164  ...   0.1043  0.1065  0.1104\n",
      "  0.0980  0.1075  0.1171  ...   0.0975  0.0974  0.1010\n",
      "  0.0979  0.1078  0.1178  ...   0.0907  0.0882  0.0917\n",
      "\n",
      "(29 , 2 ,.,.) = \n",
      "  0.0553  0.0410  0.0268  ...   0.1819  0.1811  0.1833\n",
      "  0.0489  0.0373  0.0256  ...   0.1841  0.1833  0.1854\n",
      "  0.0426  0.0336  0.0245  ...   0.1863  0.1855  0.1874\n",
      "           ...             ⋱             ...          \n",
      "  0.0981  0.1072  0.1164  ...   0.1043  0.1065  0.1104\n",
      "  0.0980  0.1075  0.1171  ...   0.0975  0.0974  0.1010\n",
      "  0.0979  0.1078  0.1178  ...   0.0907  0.0882  0.0917\n",
      "      ⋮  \n",
      "\n",
      "(30 , 0 ,.,.) = \n",
      "  0.1565  0.1698  0.1830  ...   0.9742  0.9791  0.9840\n",
      "  0.1566  0.1686  0.1807  ...   0.9779  0.9807  0.9836\n",
      "  0.1567  0.1675  0.1783  ...   0.9816  0.9824  0.9832\n",
      "           ...             ⋱             ...          \n",
      "  0.3745  0.3806  0.3868  ...   1.0000  1.0000  1.0000\n",
      "  0.3708  0.3768  0.3828  ...   1.0000  1.0000  1.0000\n",
      "  0.3667  0.3727  0.3787  ...   1.0000  1.0000  1.0000\n",
      "\n",
      "(30 , 1 ,.,.) = \n",
      "  0.1565  0.1698  0.1830  ...   0.9742  0.9791  0.9840\n",
      "  0.1566  0.1686  0.1807  ...   0.9779  0.9807  0.9836\n",
      "  0.1567  0.1675  0.1783  ...   0.9816  0.9824  0.9832\n",
      "           ...             ⋱             ...          \n",
      "  0.3745  0.3806  0.3868  ...   1.0000  1.0000  1.0000\n",
      "  0.3708  0.3768  0.3828  ...   1.0000  1.0000  1.0000\n",
      "  0.3667  0.3727  0.3787  ...   1.0000  1.0000  1.0000\n",
      "\n",
      "(30 , 2 ,.,.) = \n",
      "  0.1565  0.1698  0.1830  ...   0.9742  0.9791  0.9840\n",
      "  0.1566  0.1686  0.1807  ...   0.9779  0.9807  0.9836\n",
      "  0.1567  0.1675  0.1783  ...   0.9816  0.9824  0.9832\n",
      "           ...             ⋱             ...          \n",
      "  0.3745  0.3806  0.3868  ...   1.0000  1.0000  1.0000\n",
      "  0.3708  0.3768  0.3828  ...   1.0000  1.0000  1.0000\n",
      "  0.3667  0.3727  0.3787  ...   1.0000  1.0000  1.0000\n",
      "      ⋮  \n",
      "\n",
      "(31 , 0 ,.,.) = \n",
      "  0.0111  0.0113  0.0115  ...   0.0268  0.0205  0.0176\n",
      "  0.0117  0.0117  0.0117  ...   0.0258  0.0192  0.0163\n",
      "  0.0118  0.0118  0.0118  ...   0.0267  0.0198  0.0166\n",
      "           ...             ⋱             ...          \n",
      "  0.5591  0.4927  0.4264  ...   0.6626  0.6466  0.6143\n",
      "  0.5421  0.4912  0.4404  ...   0.6889  0.6774  0.6486\n",
      "  0.5250  0.4898  0.4545  ...   0.7152  0.7082  0.6830\n",
      "\n",
      "(31 , 1 ,.,.) = \n",
      "  0.0111  0.0113  0.0115  ...   0.0268  0.0205  0.0176\n",
      "  0.0117  0.0117  0.0117  ...   0.0258  0.0192  0.0163\n",
      "  0.0118  0.0118  0.0118  ...   0.0267  0.0198  0.0166\n",
      "           ...             ⋱             ...          \n",
      "  0.5591  0.4927  0.4264  ...   0.6626  0.6466  0.6143\n",
      "  0.5421  0.4912  0.4404  ...   0.6889  0.6774  0.6486\n",
      "  0.5250  0.4898  0.4545  ...   0.7152  0.7082  0.6830\n",
      "\n",
      "(31 , 2 ,.,.) = \n",
      "  0.0111  0.0113  0.0115  ...   0.0268  0.0205  0.0176\n",
      "  0.0117  0.0117  0.0117  ...   0.0258  0.0192  0.0163\n",
      "  0.0118  0.0118  0.0118  ...   0.0267  0.0198  0.0166\n",
      "           ...             ⋱             ...          \n",
      "  0.5591  0.4927  0.4264  ...   0.6626  0.6466  0.6143\n",
      "  0.5421  0.4912  0.4404  ...   0.6889  0.6774  0.6486\n",
      "  0.5250  0.4898  0.4545  ...   0.7152  0.7082  0.6830\n",
      "[torch.FloatTensor of size 32x3x224x224]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 0\n",
      " 3\n",
      " 4\n",
      " 1\n",
      " 2\n",
      " 0\n",
      " 5\n",
      " 0\n",
      " 6\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 0\n",
      " 3\n",
      " 1\n",
      " 0\n",
      " 3\n",
      " 4\n",
      " 6\n",
      " 4\n",
      " 0\n",
      " 3\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 32]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = tqdm(trainLoader)\n",
    "for (i, (sample)) in enumerate(t):\n",
    "    \n",
    "    inputs = Variable(sample['image'] ).float()\n",
    "    labels = Variable(sample['emotion'])\n",
    "    print(inputs)\n",
    "    print(labels)\n",
    "    if i == 3:\n",
    "        break\n",
    "    #outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c180c3a4-a698-4501-a48d-3b4cb152b2f8"
    }
   },
   "outputs": [],
   "source": [
    "import lab_utils\n",
    "def train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = False):\n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    t_loss, t_acc, v_loss, v_acc = (np.zeros(n_epochs) for i in range(4))    \n",
    "    \n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (sample)) in enumerate(t):\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(sample['image'] ).float()\n",
    "            labels = Variable(sample['emotion'])\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "            \n",
    "        t_loss[epoch] = (cum_loss/len(t))\n",
    "        t_acc[epoch] = (100*correct/counter)\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (sample)) in enumerate(t):\n",
    "            #print(\"on iter {}\".format(i))\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(sample['image'] ).float()\n",
    "            labels = Variable(sample['emotion'])\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "            \n",
    "        v_loss[epoch] = (cum_loss/len(t))\n",
    "        v_acc[epoch] = (100*correct/counter)\n",
    "        \n",
    "                \n",
    "    lab_utils.generate_plots(t_loss, v_loss, t_acc, v_acc, n_epochs)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8459ae87-2706-43ee-9348-a63be5996153"
    }
   },
   "source": [
    "### set learning rate, loss, optimizer, all variable stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential (\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU ()\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU ()\n",
      "  (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU ()\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU ()\n",
      "  (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU ()\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU ()\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU ()\n",
      "  (16): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU ()\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU ()\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU ()\n",
      "  (23): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU ()\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU ()\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU ()\n",
      "  (30): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (31): Lambda (\n",
      "  )\n",
      "  (32): Sequential (\n",
      "    (0): Lambda (\n",
      "    )\n",
      "    (1): Linear (25088 -> 4096)\n",
      "  )\n",
      "  (33): ReLU ()\n",
      "  (34): Dropout (p = 0.5)\n",
      "  (35): Sequential (\n",
      "    (0): Lambda (\n",
      "    )\n",
      "    (1): Linear (4096 -> 4096)\n",
      "  )\n",
      "  (36): ReLU ()\n",
      "  (37): Dropout (p = 0.5)\n",
      "  (38): Sequential (\n",
      "    (0): Lambda (\n",
      "    )\n",
      "    (1): Linear (4096 -> 10)\n",
      "  )\n",
      "  (39): Softmax ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = model\n",
    "#print(pretrained_model)\n",
    "#print(list(pretrained_model.children())[:-2]) #gets rid of the last linear layer and softmax\n",
    "modified_pretrained = nn.Sequential(*list(pretrained_model.children())[:-2]) \n",
    "\n",
    "#print(modified_pretrained)\n",
    "\n",
    "modified_pretrained.add_module('38', nn.Sequential(VGG_FACE.Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(4096,3)))\n",
    "modified_pretrained.add_module('39', nn.Softmax())\n",
    "\n",
    "print(modified_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbpresent": {
     "id": "faa6cc19-fa86-49d0-9374-cfc76c652add"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'generate_plots'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-51198b36fb2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodified_pretrained\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodified_pretrained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-b68e52d6f3ce>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(network, criterion, optimizer, trainLoader, valLoader, n_epochs, use_gpu)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mlab_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_plots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'generate_plots'"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "#\"where we set the learning rate and weight decay to 0.0005, momentum to 0.9, and dropout probability to 0.8 [25]\"\n",
    "learningRate = 5e-4\n",
    "\n",
    "\n",
    "\n",
    "# Definition of our network.\n",
    "#how to change the last fc layer of the model to nn.linear(4096, 7) instead of (4096, 2622)?\n",
    "#model.fc = nn.Linear(512, 2)\n",
    "\n",
    "\n",
    "#Definition of our loss. #maybe need to change this?\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definition of optimization strategy. # maybe need to change this?\n",
    "optimizer = optim.SGD(modified_pretrained.parameters(), lr = learningRate)\n",
    "\n",
    "train_model(modified_pretrained, criterion, optimizer, trainLoader, valLoader, n_epochs = 1, use_gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <type 'function'>: attribute lookup __builtin__.function failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-770a4b6a8613>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodified_pretrained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'trained_model.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/torch/serialization.pyc\u001b[0m in \u001b[0;36m_save\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m     \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <type 'function'>: attribute lookup __builtin__.function failed"
     ]
    }
   ],
   "source": [
    "torch.save(modified_pretrained, 'trained_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CompVision]",
   "language": "python",
   "name": "conda-env-CompVision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
