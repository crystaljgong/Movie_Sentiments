{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "959a7890-af52-4a93-8179-e797ad6fc700"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e7a16fae-e0f8-4ab1-89e3-457c6bcabe63"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'During the training of the deep networks, we oversample the training\\nimages by rotating them around their center by a random angle between \\n\\xe2\\x88\\x9215\\xc2\\xb0 and 15\\xc2\\xb0, and by circularly shifting the images in the horizontal and \\nvertical directions by an amount no more than 20% of the image size. \\nThis approach helps our network to be more robust against alignment errors. \\nIn Fig. 2, we show the training curves of two stages of fine-tuning of the \\nnetwork with the FER dataset, where we set the learning rate and weight \\ndecay to 0.0005, momentum to 0.9, and dropout probability to 0.8 [25].'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "For the fine-tuning of the VGG-Face network for the emotion\n",
    "recognition task, we investigated various options in our preliminary\n",
    "analysis. We found that combining weight decay and dropout for regularization\n",
    "gives the best results on the FER validation set. We carry\n",
    "out a multi-stage fine-tuning. In the first stage, we fine-tune on the\n",
    "FER public test set, and run weight updates for five epochs. In the second\n",
    "stage, we update the upper layers (higher than layer 27) using'''\n",
    "\n",
    "''' We then fine-tune the VGG-face model on FER 2013\n",
    "dataset, using both the training and the public test set; during\n",
    "training we use data augmentation by jittering the scale, flipping\n",
    "and rotating the faces. The aim is to make the network more robust\n",
    "to small misalignment of the faces. We also apply a strong dropout\n",
    "on the last layer of the VGG (keeping only 5% of the nodes) to\n",
    "prevent over-fitting. We achieve a performance of 71.2% on the\n",
    "FER private test set, which is slightly higher than the previously\n",
    "published results '''\n",
    "\n",
    "'''During the training of the deep networks, we oversample the training\n",
    "images by rotating them around their center by a random angle between \n",
    "−15° and 15°, and by circularly shifting the images in the horizontal and \n",
    "vertical directions by an amount no more than 20% of the image size. \n",
    "This approach helps our network to be more robust against alignment errors. \n",
    "In Fig. 2, we show the training curves of two stages of fine-tuning of the \n",
    "network with the FER dataset, where we set the learning rate and weight \n",
    "decay to 0.0005, momentum to 0.9, and dropout probability to 0.8 [25].'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6879088e-ce15-45e6-8f39-29fd16ab529a"
    }
   },
   "source": [
    "### VGG16-Face model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d691c9bc-5b8d-42ae-b109-0597f42f5d60"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import VGG_FACE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "570025bf-5112-4fae-9432-4039578fc868"
    }
   },
   "outputs": [],
   "source": [
    "model = VGG_FACE.VGG_FACE\n",
    "\n",
    "model.load_state_dict(torch.load('VGG_FACE.pth'))\n",
    "\n",
    "#model.eval() #this will let you pass an input through the model and evaluate it? without training?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7ef650af-4012-42c1-a5f5-69e04cdd9cf8"
    }
   },
   "source": [
    "### Dataset: FERplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5e29d967-b841-48d2-8160-e678660be2ea"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "be8542c0-7e28-4b37-93f3-0fda5361a126"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Image name</th>\n",
       "      <th>neutral</th>\n",
       "      <th>happiness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>contempt</th>\n",
       "      <th>unknown</th>\n",
       "      <th>NF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000000.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000001.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000002.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000003.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000004.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000005.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000006.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000007.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000008.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000009.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000010.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000011.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000012.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000013.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000014.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000015.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000016.png</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000018.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000019.png</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000020.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000021.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000022.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000024.png</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000025.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000026.png</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000027.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000028.png</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000029.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000030.png</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000031.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35856</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035771.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35857</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035772.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35858</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035773.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35859</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035774.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35860</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035775.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35861</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035776.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35862</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035777.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35863</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035778.png</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35864</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035779.png</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35865</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035780.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35866</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035781.png</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35867</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035782.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35868</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035783.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35869</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035784.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35870</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035785.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35871</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035786.png</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35872</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035787.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35873</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035788.png</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35874</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035789.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35875</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035790.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35876</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035791.png</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35877</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035792.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35878</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035793.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35879</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035794.png</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35880</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035795.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35881</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035796.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035797.png</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035799.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035800.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035801.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35714 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Usage      Image name  neutral  happiness  surprise  sadness  \\\n",
       "0         Training  fer0000000.png        4          0         0        1   \n",
       "1         Training  fer0000001.png        6          0         1        1   \n",
       "2         Training  fer0000002.png        5          0         0        3   \n",
       "3         Training  fer0000003.png        4          0         0        4   \n",
       "4         Training  fer0000004.png        9          0         0        1   \n",
       "5         Training  fer0000005.png        6          0         0        1   \n",
       "6         Training  fer0000006.png        2          0         0        8   \n",
       "7         Training  fer0000007.png        0         10         0        0   \n",
       "8         Training  fer0000008.png        0         10         0        0   \n",
       "9         Training  fer0000009.png        0          0         6        0   \n",
       "10        Training  fer0000010.png        2          0         0        0   \n",
       "11        Training  fer0000011.png       10          0         0        0   \n",
       "12        Training  fer0000012.png        5          0         0        3   \n",
       "13        Training  fer0000013.png        9          0         0        1   \n",
       "14        Training  fer0000014.png        0         10         0        0   \n",
       "15        Training  fer0000015.png        0          0         6        0   \n",
       "16        Training  fer0000016.png        4          6         0        0   \n",
       "18        Training  fer0000018.png        1          0         2        4   \n",
       "19        Training  fer0000019.png        6          1         0        0   \n",
       "20        Training  fer0000020.png        5          0         0        4   \n",
       "21        Training  fer0000021.png        1          0         1        2   \n",
       "22        Training  fer0000022.png        1          0         1        1   \n",
       "24        Training  fer0000024.png        2          7         0        0   \n",
       "25        Training  fer0000025.png        0         10         0        0   \n",
       "26        Training  fer0000026.png        4          2         4        0   \n",
       "27        Training  fer0000027.png        0          0         0        0   \n",
       "28        Training  fer0000028.png        1          7         0        0   \n",
       "29        Training  fer0000029.png        0          1         6        0   \n",
       "30        Training  fer0000030.png        0          9         0        0   \n",
       "31        Training  fer0000031.png       10          0         0        0   \n",
       "...            ...             ...      ...        ...       ...      ...   \n",
       "35856  PrivateTest  fer0035771.png        0         10         0        0   \n",
       "35857  PrivateTest  fer0035772.png        0          0        10        0   \n",
       "35858  PrivateTest  fer0035773.png        1          0         1        7   \n",
       "35859  PrivateTest  fer0035774.png       10          0         0        0   \n",
       "35860  PrivateTest  fer0035775.png        0         10         0        0   \n",
       "35861  PrivateTest  fer0035776.png        9          0         0        0   \n",
       "35862  PrivateTest  fer0035777.png        2          0         3        0   \n",
       "35863  PrivateTest  fer0035778.png        0          2         7        0   \n",
       "35864  PrivateTest  fer0035779.png        4          1         0        4   \n",
       "35865  PrivateTest  fer0035780.png        0         10         0        0   \n",
       "35866  PrivateTest  fer0035781.png        7          3         0        0   \n",
       "35867  PrivateTest  fer0035782.png        0         10         0        0   \n",
       "35868  PrivateTest  fer0035783.png        0          0         0        0   \n",
       "35869  PrivateTest  fer0035784.png        0         10         0        0   \n",
       "35870  PrivateTest  fer0035785.png        0          0         0        0   \n",
       "35871  PrivateTest  fer0035786.png        9          1         0        0   \n",
       "35872  PrivateTest  fer0035787.png        6          0         0        0   \n",
       "35873  PrivateTest  fer0035788.png        8          0         0        2   \n",
       "35874  PrivateTest  fer0035789.png        1          0         1        5   \n",
       "35875  PrivateTest  fer0035790.png        2          0         5        1   \n",
       "35876  PrivateTest  fer0035791.png        1          9         0        0   \n",
       "35877  PrivateTest  fer0035792.png        4          0         0        5   \n",
       "35878  PrivateTest  fer0035793.png        0         10         0        0   \n",
       "35879  PrivateTest  fer0035794.png        3          0         0        5   \n",
       "35880  PrivateTest  fer0035795.png        0          0         1        6   \n",
       "35881  PrivateTest  fer0035796.png        5          0         0        3   \n",
       "35882  PrivateTest  fer0035797.png        8          0         0        2   \n",
       "35884  PrivateTest  fer0035799.png        0          0         0        0   \n",
       "35885  PrivateTest  fer0035800.png        0         10         0        0   \n",
       "35886  PrivateTest  fer0035801.png        2          0         0        5   \n",
       "\n",
       "       anger  disgust  fear  contempt  unknown  NF  \n",
       "0          3        2     0         0        0   0  \n",
       "1          0        0     0         0        2   0  \n",
       "2          1        0     0         0        1   0  \n",
       "3          1        0     0         0        1   0  \n",
       "4          0        0     0         0        0   0  \n",
       "5          0        0     1         1        1   0  \n",
       "6          0        0     0         0        0   0  \n",
       "7          0        0     0         0        0   0  \n",
       "8          0        0     0         0        0   0  \n",
       "9          0        0     4         0        0   0  \n",
       "10         8        0     0         0        0   0  \n",
       "11         0        0     0         0        0   0  \n",
       "12         0        0     0         0        2   0  \n",
       "13         0        0     0         0        0   0  \n",
       "14         0        0     0         0        0   0  \n",
       "15         1        0     3         0        0   0  \n",
       "16         0        0     0         0        0   0  \n",
       "18         2        0     0         0        1   0  \n",
       "19         3        0     0         0        0   0  \n",
       "20         0        0     0         0        1   0  \n",
       "21         0        0     5         0        1   0  \n",
       "22         7        0     0         0        0   0  \n",
       "24         0        0     0         1        0   0  \n",
       "25         0        0     0         0        0   0  \n",
       "26         0        0     0         0        0   0  \n",
       "27         7        1     0         0        2   0  \n",
       "28         0        2     0         0        0   0  \n",
       "29         0        0     3         0        0   0  \n",
       "30         0        1     0         0        0   0  \n",
       "31         0        0     0         0        0   0  \n",
       "...      ...      ...   ...       ...      ...  ..  \n",
       "35856      0        0     0         0        0   0  \n",
       "35857      0        0     0         0        0   0  \n",
       "35858      0        0     0         0        1   0  \n",
       "35859      0        0     0         0        0   0  \n",
       "35860      0        0     0         0        0   0  \n",
       "35861      0        0     0         0        1   0  \n",
       "35862      0        0     5         0        0   0  \n",
       "35863      0        0     1         0        0   0  \n",
       "35864      0        0     0         0        1   0  \n",
       "35865      0        0     0         0        0   0  \n",
       "35866      0        0     0         0        0   0  \n",
       "35867      0        0     0         0        0   0  \n",
       "35868      7        0     2         0        1   0  \n",
       "35869      0        0     0         0        0   0  \n",
       "35870     10        0     0         0        0   0  \n",
       "35871      0        0     0         0        0   0  \n",
       "35872      1        1     1         0        1   0  \n",
       "35873      0        0     0         0        0   0  \n",
       "35874      0        0     1         0        2   0  \n",
       "35875      0        0     0         1        1   0  \n",
       "35876      0        0     0         0        0   0  \n",
       "35877      0        0     0         0        1   0  \n",
       "35878      0        0     0         0        0   0  \n",
       "35879      1        0     0         0        1   0  \n",
       "35880      0        0     3         0        0   0  \n",
       "35881      0        0     0         0        2   0  \n",
       "35882      0        0     0         0        0   0  \n",
       "35884      7        1     0         2        0   0  \n",
       "35885      0        0     0         0        0   0  \n",
       "35886      1        1     0         0        1   0  \n",
       "\n",
       "[35714 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all-data/FERPlus/fer2013new.csv')\n",
    "df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0ca1abe4-7bb7-4bbe-8faf-080cad04eaf5"
    }
   },
   "outputs": [],
   "source": [
    "class FaceEmotionsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.emotions_frame = pd.read_csv(csv_file)\n",
    "        self.emotions_frame.dropna(axis=0, how='any', inplace=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.emotions_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.emotions_frame.iloc[idx][1]\n",
    "        \n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = io.imread(img_path)\n",
    "        #this takes the most highest ranked emotion. if two emotions have the same ranking, it just takes the first one\n",
    "        emotion = np.argmax(self.emotions_frame.iloc[idx,2:].as_matrix())\n",
    "        sample = {'image': image, 'emotion': emotion}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7eb85ee3-259b-4395-a288-ee1af15c1f41"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "emotions_frame = pd.read_csv('all-data/FERPlus/fer2013new.csv')\n",
    "emotions_frame.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "emotion = np.argmax(emotions_frame.iloc[10,2:].as_matrix())\n",
    "print(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "252d81d5-707f-4133-add3-fe798d2dc52e"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emotion': 4, 'image': array([[ 30,  24,  21, ...,  37,  44,  37],\n",
       "        [ 31,  22,  21, ...,  37,  35,  41],\n",
       "        [ 27,  22,  19, ...,  33,  34,  40],\n",
       "        ..., \n",
       "        [ 29,  29,  26, ..., 118, 132, 148],\n",
       "        [ 30,  30,  27, ..., 154, 159, 166],\n",
       "        [ 32,  29,  28, ..., 172, 173, 173]], dtype=uint8)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_emotions = FaceEmotionsDataset(csv_file = 'all-data/FERPlus/fer2013new_training.csv', \n",
    "                                    root_dir = 'all-data/FERPlus/data/FER2013Train')\n",
    "\n",
    "face_emotions[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0d088434-f0c7-4d61-a29f-29d2529e3ad1"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from skimage import transform\n",
    "from PIL import Image\n",
    "from skimage import io; io.use_plugin('matplotlib')\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, emotion = sample['image'], sample['emotion']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        #print(image.shape)\n",
    "        #image = image.transpose((2, 0, 1))\n",
    "        image = np.expand_dims(image,0)\n",
    "        y = np.copy(image)\n",
    "        z = np.copy(image)\n",
    "        z = np.concatenate((y,z), axis=0)    \n",
    "        image = np.concatenate((image,z), axis=0)\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'emotion': emotion}\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, emotion = sample['image'], sample['emotion']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        #emotion = emotion - [left, top]\n",
    "\n",
    "        return {'image': image, 'emotion': emotion}\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or tuple): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, emotion = sample['image'], sample['emotion']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        \n",
    "        #emotion = emotion * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'emotion': emotion}\n",
    "\n",
    "\n",
    "imgTransform = transforms.Compose([Rescale(256), #scale to 256x256\n",
    "                                   #transforms.CenterCrop(224), #crops the image at center to 224x224\n",
    "                                   RandomCrop(224),\n",
    "                                   ToTensor()\n",
    "                                   ])\n",
    "                                   #, #turn the jpg/pil/wahtever image into a tensor\n",
    "                                   #transforms.Normalize(mean = [0.485, 0.456, 0.406], #normalize with these vals\n",
    "                                                        #std=[0.229, 0.224, 0.225])])\n",
    "                                    ##HOW TO GET NORMALIZED VALUES?\n",
    "                                    #to add: jitter/rotate data augmentation, flipping, \n",
    "                                   \n",
    "#this doesn't work because the data is organized w a csv file w prob distrib of labels \n",
    "#instead of a single ground truth\n",
    "#see this paper: https://arxiv.org/pdf/1608.01041.pdf\n",
    "trainset = FaceEmotionsDataset(csv_file = 'all-data/FERPlus/fer2013new_training.csv', \n",
    "                                    root_dir = 'all-data/FERPlus/data/FER2013Train', transform = imgTransform)\n",
    "valset = FaceEmotionsDataset(csv_file = 'all-data/FERPlus/fer2013new_validation.csv', \n",
    "                                    root_dir = 'all-data/FERPlus/data/FER2013Valid', transform = imgTransform)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size = 64, \n",
    "                                          shuffle = True, num_workers = 0)\n",
    "valLoader = torch.utils.data.DataLoader(valset, batch_size = 64, \n",
    "                                       shuffle = False, num_workers = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( 0 , 0 ,.,.) = \n",
      "  0.6519  0.6891  0.7262  ...   0.8415  0.8464  0.8495\n",
      "  0.6571  0.6933  0.7295  ...   0.8454  0.8512  0.8541\n",
      "  0.6588  0.6954  0.7320  ...   0.8468  0.8518  0.8540\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   0.7946  0.7939  0.7928\n",
      "  1.0000  1.0000  1.0000  ...   0.7924  0.7917  0.7906\n",
      "  1.0000  1.0000  1.0000  ...   0.7902  0.7895  0.7884\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.6519  0.6891  0.7262  ...   0.8415  0.8464  0.8495\n",
      "  0.6571  0.6933  0.7295  ...   0.8454  0.8512  0.8541\n",
      "  0.6588  0.6954  0.7320  ...   0.8468  0.8518  0.8540\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   0.7946  0.7939  0.7928\n",
      "  1.0000  1.0000  1.0000  ...   0.7924  0.7917  0.7906\n",
      "  1.0000  1.0000  1.0000  ...   0.7902  0.7895  0.7884\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.6519  0.6891  0.7262  ...   0.8415  0.8464  0.8495\n",
      "  0.6571  0.6933  0.7295  ...   0.8454  0.8512  0.8541\n",
      "  0.6588  0.6954  0.7320  ...   0.8468  0.8518  0.8540\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   0.7946  0.7939  0.7928\n",
      "  1.0000  1.0000  1.0000  ...   0.7924  0.7917  0.7906\n",
      "  1.0000  1.0000  1.0000  ...   0.7902  0.7895  0.7884\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.4735  0.4674  0.4628  ...   0.1920  0.1909  0.1899\n",
      "  0.4909  0.4861  0.4849  ...   0.1925  0.1913  0.1901\n",
      "  0.5083  0.5047  0.5070  ...   0.1930  0.1916  0.1903\n",
      "           ...             ⋱             ...          \n",
      "  0.2017  0.1970  0.1967  ...   0.0275  0.0275  0.0275\n",
      "  0.1995  0.1949  0.1955  ...   0.0283  0.0282  0.0280\n",
      "  0.1969  0.1926  0.1945  ...   0.0300  0.0296  0.0292\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.4735  0.4674  0.4628  ...   0.1920  0.1909  0.1899\n",
      "  0.4909  0.4861  0.4849  ...   0.1925  0.1913  0.1901\n",
      "  0.5083  0.5047  0.5070  ...   0.1930  0.1916  0.1903\n",
      "           ...             ⋱             ...          \n",
      "  0.2017  0.1970  0.1967  ...   0.0275  0.0275  0.0275\n",
      "  0.1995  0.1949  0.1955  ...   0.0283  0.0282  0.0280\n",
      "  0.1969  0.1926  0.1945  ...   0.0300  0.0296  0.0292\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.4735  0.4674  0.4628  ...   0.1920  0.1909  0.1899\n",
      "  0.4909  0.4861  0.4849  ...   0.1925  0.1913  0.1901\n",
      "  0.5083  0.5047  0.5070  ...   0.1930  0.1916  0.1903\n",
      "           ...             ⋱             ...          \n",
      "  0.2017  0.1970  0.1967  ...   0.0275  0.0275  0.0275\n",
      "  0.1995  0.1949  0.1955  ...   0.0283  0.0282  0.0280\n",
      "  0.1969  0.1926  0.1945  ...   0.0300  0.0296  0.0292\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.8319  0.8232  0.8146  ...   0.9461  0.9501  0.9480\n",
      "  0.8215  0.8143  0.8072  ...   0.9399  0.9429  0.9461\n",
      "  0.8126  0.8073  0.8020  ...   0.9339  0.9370  0.9446\n",
      "           ...             ⋱             ...          \n",
      "  0.0165  0.0160  0.0156  ...   0.1058  0.1081  0.0957\n",
      "  0.0232  0.0204  0.0177  ...   0.1090  0.1129  0.1011\n",
      "  0.0299  0.0248  0.0197  ...   0.1122  0.1178  0.1065\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.8319  0.8232  0.8146  ...   0.9461  0.9501  0.9480\n",
      "  0.8215  0.8143  0.8072  ...   0.9399  0.9429  0.9461\n",
      "  0.8126  0.8073  0.8020  ...   0.9339  0.9370  0.9446\n",
      "           ...             ⋱             ...          \n",
      "  0.0165  0.0160  0.0156  ...   0.1058  0.1081  0.0957\n",
      "  0.0232  0.0204  0.0177  ...   0.1090  0.1129  0.1011\n",
      "  0.0299  0.0248  0.0197  ...   0.1122  0.1178  0.1065\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.8319  0.8232  0.8146  ...   0.9461  0.9501  0.9480\n",
      "  0.8215  0.8143  0.8072  ...   0.9399  0.9429  0.9461\n",
      "  0.8126  0.8073  0.8020  ...   0.9339  0.9370  0.9446\n",
      "           ...             ⋱             ...          \n",
      "  0.0165  0.0160  0.0156  ...   0.1058  0.1081  0.0957\n",
      "  0.0232  0.0204  0.0177  ...   0.1090  0.1129  0.1011\n",
      "  0.0299  0.0248  0.0197  ...   0.1122  0.1178  0.1065\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(61 , 0 ,.,.) = \n",
      "  0.2756  0.2781  0.2799  ...   0.2888  0.2866  0.2844\n",
      "  0.2772  0.2792  0.2806  ...   0.2945  0.2924  0.2902\n",
      "  0.2766  0.2784  0.2796  ...   0.2970  0.2950  0.2930\n",
      "           ...             ⋱             ...          \n",
      "  0.1905  0.1891  0.1870  ...   0.3020  0.2639  0.2258\n",
      "  0.1920  0.1913  0.1900  ...   0.3542  0.3044  0.2547\n",
      "  0.1934  0.1935  0.1929  ...   0.4063  0.3450  0.2837\n",
      "\n",
      "(61 , 1 ,.,.) = \n",
      "  0.2756  0.2781  0.2799  ...   0.2888  0.2866  0.2844\n",
      "  0.2772  0.2792  0.2806  ...   0.2945  0.2924  0.2902\n",
      "  0.2766  0.2784  0.2796  ...   0.2970  0.2950  0.2930\n",
      "           ...             ⋱             ...          \n",
      "  0.1905  0.1891  0.1870  ...   0.3020  0.2639  0.2258\n",
      "  0.1920  0.1913  0.1900  ...   0.3542  0.3044  0.2547\n",
      "  0.1934  0.1935  0.1929  ...   0.4063  0.3450  0.2837\n",
      "\n",
      "(61 , 2 ,.,.) = \n",
      "  0.2756  0.2781  0.2799  ...   0.2888  0.2866  0.2844\n",
      "  0.2772  0.2792  0.2806  ...   0.2945  0.2924  0.2902\n",
      "  0.2766  0.2784  0.2796  ...   0.2970  0.2950  0.2930\n",
      "           ...             ⋱             ...          \n",
      "  0.1905  0.1891  0.1870  ...   0.3020  0.2639  0.2258\n",
      "  0.1920  0.1913  0.1900  ...   0.3542  0.3044  0.2547\n",
      "  0.1934  0.1935  0.1929  ...   0.4063  0.3450  0.2837\n",
      "      ⋮  \n",
      "\n",
      "(62 , 0 ,.,.) = \n",
      "  0.0973  0.0974  0.0976  ...   0.1066  0.1042  0.1018\n",
      "  0.0966  0.0969  0.0972  ...   0.1060  0.1047  0.1035\n",
      "  0.0959  0.0964  0.0968  ...   0.1055  0.1053  0.1051\n",
      "           ...             ⋱             ...          \n",
      "  0.3327  0.3309  0.3291  ...   0.0934  0.0946  0.0958\n",
      "  0.3525  0.3521  0.3517  ...   0.0982  0.0996  0.1009\n",
      "  0.3575  0.3582  0.3589  ...   0.0990  0.1004  0.1019\n",
      "\n",
      "(62 , 1 ,.,.) = \n",
      "  0.0973  0.0974  0.0976  ...   0.1066  0.1042  0.1018\n",
      "  0.0966  0.0969  0.0972  ...   0.1060  0.1047  0.1035\n",
      "  0.0959  0.0964  0.0968  ...   0.1055  0.1053  0.1051\n",
      "           ...             ⋱             ...          \n",
      "  0.3327  0.3309  0.3291  ...   0.0934  0.0946  0.0958\n",
      "  0.3525  0.3521  0.3517  ...   0.0982  0.0996  0.1009\n",
      "  0.3575  0.3582  0.3589  ...   0.0990  0.1004  0.1019\n",
      "\n",
      "(62 , 2 ,.,.) = \n",
      "  0.0973  0.0974  0.0976  ...   0.1066  0.1042  0.1018\n",
      "  0.0966  0.0969  0.0972  ...   0.1060  0.1047  0.1035\n",
      "  0.0959  0.0964  0.0968  ...   0.1055  0.1053  0.1051\n",
      "           ...             ⋱             ...          \n",
      "  0.3327  0.3309  0.3291  ...   0.0934  0.0946  0.0958\n",
      "  0.3525  0.3521  0.3517  ...   0.0982  0.0996  0.1009\n",
      "  0.3575  0.3582  0.3589  ...   0.0990  0.1004  0.1019\n",
      "      ⋮  \n",
      "\n",
      "(63 , 0 ,.,.) = \n",
      "  0.0449  0.0488  0.0537  ...   0.4115  0.4108  0.4100\n",
      "  0.0436  0.0471  0.0516  ...   0.4137  0.4130  0.4123\n",
      "  0.0423  0.0454  0.0496  ...   0.4159  0.4152  0.4145\n",
      "           ...             ⋱             ...          \n",
      "  0.5238  0.5232  0.5228  ...   0.0138  0.0138  0.0138\n",
      "  0.5230  0.5224  0.5219  ...   0.0146  0.0146  0.0146\n",
      "  0.5223  0.5216  0.5209  ...   0.0153  0.0153  0.0153\n",
      "\n",
      "(63 , 1 ,.,.) = \n",
      "  0.0449  0.0488  0.0537  ...   0.4115  0.4108  0.4100\n",
      "  0.0436  0.0471  0.0516  ...   0.4137  0.4130  0.4123\n",
      "  0.0423  0.0454  0.0496  ...   0.4159  0.4152  0.4145\n",
      "           ...             ⋱             ...          \n",
      "  0.5238  0.5232  0.5228  ...   0.0138  0.0138  0.0138\n",
      "  0.5230  0.5224  0.5219  ...   0.0146  0.0146  0.0146\n",
      "  0.5223  0.5216  0.5209  ...   0.0153  0.0153  0.0153\n",
      "\n",
      "(63 , 2 ,.,.) = \n",
      "  0.0449  0.0488  0.0537  ...   0.4115  0.4108  0.4100\n",
      "  0.0436  0.0471  0.0516  ...   0.4137  0.4130  0.4123\n",
      "  0.0423  0.0454  0.0496  ...   0.4159  0.4152  0.4145\n",
      "           ...             ⋱             ...          \n",
      "  0.5238  0.5232  0.5228  ...   0.0138  0.0138  0.0138\n",
      "  0.5230  0.5224  0.5219  ...   0.0146  0.0146  0.0146\n",
      "  0.5223  0.5216  0.5209  ...   0.0153  0.0153  0.0153\n",
      "[torch.DoubleTensor of size 64x3x224x224]\n",
      ", \n",
      " 2\n",
      " 1\n",
      " 3\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 2\n",
      " 1\n",
      " 3\n",
      " 3\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 3\n",
      " 2\n",
      " 3\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 4\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 0\n",
      " 0\n",
      " 3\n",
      " 2\n",
      " 4\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 0\n",
      " 4\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 0\n",
      " 2\n",
      " 2\n",
      " 3\n",
      " 0\n",
      " 4\n",
      " 3\n",
      " 4\n",
      " 7\n",
      " 0\n",
      " 0\n",
      " 5\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 64]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (i, sample) in enumerate(trainLoader):\n",
    "    inputs = sample['image']\n",
    "    labels = sample['emotion']\n",
    "    print(\"{}, {}\".format(inputs, labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6d2ad753-43bf-4df1-b903-4dc8b543cff0"
    }
   },
   "source": [
    "### Function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d0d19064-5fe3-4fae-b953-b62bf3aeba34"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065068435d75482b89768fe8bc000508"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = tqdm(trainLoader)\n",
    "for (i, (sample)) in enumerate(t):\n",
    "    break\n",
    "    inputs = Variable(sample['image'] ).float()\n",
    "    labels = Variable(sample['emotion'])\n",
    "    #outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c180c3a4-a698-4501-a48d-3b4cb152b2f8"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = False):\n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    t_loss, t_acc, v_loss, v_acc = (np.zeros(n_epochs) for i in range(4))    \n",
    "    \n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (sample)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(sample['image'] ).float()\n",
    "            labels = Variable(sample['emotion'])\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "            \n",
    "        t_loss[epoch] = (cum_loss/len(t))\n",
    "        t_acc[epoch] = (100*correct/counter)\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (inputs, labels)) in enumerate(t):\n",
    "            print(\"on iter {}\".format(i))\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs).unsqueeze(0)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "            \n",
    "        v_loss[epoch] = (cum_loss/len(t))\n",
    "        v_acc[epoch] = (100*correct/counter)\n",
    "        \n",
    "                \n",
    "    lab_utils.generate_plots(t_loss, v_loss, t_acc, v_acc, n_epochs)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8459ae87-2706-43ee-9348-a63be5996153"
    }
   },
   "source": [
    "### set learning rate, loss, optimizer, all variable stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)), Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (), MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)), Lambda (\n",
      "), Sequential (\n",
      "  (0): Lambda (\n",
      "  )\n",
      "  (1): Linear (25088 -> 4096)\n",
      "), ReLU (), Dropout (p = 0.5), Sequential (\n",
      "  (0): Lambda (\n",
      "  )\n",
      "  (1): Linear (4096 -> 4096)\n",
      "), ReLU (), Dropout (p = 0.5)]\n",
      "Sequential (\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU ()\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU ()\n",
      "  (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU ()\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU ()\n",
      "  (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU ()\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU ()\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU ()\n",
      "  (16): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU ()\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU ()\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU ()\n",
      "  (23): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU ()\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU ()\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU ()\n",
      "  (30): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (31): Lambda (\n",
      "  )\n",
      "  (32): Sequential (\n",
      "    (0): Lambda (\n",
      "    )\n",
      "    (1): Linear (25088 -> 4096)\n",
      "  )\n",
      "  (33): ReLU ()\n",
      "  (34): Dropout (p = 0.5)\n",
      "  (35): Sequential (\n",
      "    (0): Lambda (\n",
      "    )\n",
      "    (1): Linear (4096 -> 4096)\n",
      "  )\n",
      "  (36): ReLU ()\n",
      "  (37): Dropout (p = 0.5)\n",
      ")\n",
      "Sequential (\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU ()\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU ()\n",
      "  (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU ()\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU ()\n",
      "  (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU ()\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU ()\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU ()\n",
      "  (16): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU ()\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU ()\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU ()\n",
      "  (23): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU ()\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU ()\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU ()\n",
      "  (30): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (31): Lambda (\n",
      "  )\n",
      "  (32): Sequential (\n",
      "    (0): Lambda (\n",
      "    )\n",
      "    (1): Linear (25088 -> 4096)\n",
      "  )\n",
      "  (33): ReLU ()\n",
      "  (34): Dropout (p = 0.5)\n",
      "  (35): Sequential (\n",
      "    (0): Lambda (\n",
      "    )\n",
      "    (1): Linear (4096 -> 4096)\n",
      "  )\n",
      "  (36): ReLU ()\n",
      "  (37): Dropout (p = 0.5)\n",
      "  (38): Sequential (\n",
      "    (0): Lambda (\n",
      "    )\n",
      "    (1): Linear (4096 -> 7)\n",
      "  )\n",
      "  (39): Softmax ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = model\n",
    "\n",
    "print(list(pretrained_model.children())[:-2]) #gets rid of the last linear layer and softmax\n",
    "modified_pretrained = nn.Sequential(*list(pretrained_model.children())[:-2]) \n",
    "\n",
    "print(modified_pretrained)\n",
    "\n",
    "modified_pretrained.add_module('38', nn.Sequential(VGG_FACE.Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(4096,7)))\n",
    "modified_pretrained.add_module('39', nn.Softmax())\n",
    "\n",
    "print(modified_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "faa6cc19-fa86-49d0-9374-cfc76c652add"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate 'str' and 'int' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-eb6249b566fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Definition of optimization strategy. # maybe need to change this?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/crystalgong/anaconda/envs/CompVision/lib/python2.7/site-packages/torch/optim/sgd.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/crystalgong/anaconda/envs/CompVision/lib/python2.7/site-packages/torch/optim/optimizer.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer got an empty parameter list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/crystalgong/anaconda/envs/CompVision/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36mparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'torch.FloatTensor'\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20L\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1L\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5L\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5L\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \"\"\"\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/crystalgong/anaconda/envs/CompVision/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36mnamed_parameters\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate 'str' and 'int' objects"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "#\"where we set the learning rate and weight decay to 0.0005, momentum to 0.9, and dropout probability to 0.8 [25]\"\n",
    "learningRate = 5e-4\n",
    "\n",
    "\n",
    "\n",
    "# Definition of our network.\n",
    "#how to change the last fc layer of the model to nn.linear(4096, 7) instead of (4096, 2622)?\n",
    "#model.fc = nn.Linear(512, 2)\n",
    "\n",
    "\n",
    "#Definition of our loss. #maybe need to change this?\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definition of optimization strategy. # maybe need to change this?\n",
    "optimizer = optim.SGD(model.parameters(), lr = learningRate)\n",
    "\n",
    "train_model(modified_pretrained, criterion, optimizer, trainLoader, valLoader, n_epochs = 1, use_gpu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
