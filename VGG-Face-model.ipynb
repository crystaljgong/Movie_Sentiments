{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "959a7890-af52-4a93-8179-e797ad6fc700"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e7a16fae-e0f8-4ab1-89e3-457c6bcabe63"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'During the training of the deep networks, we oversample the training\\nimages by rotating them around their center by a random angle between \\n\\xe2\\x88\\x9215\\xc2\\xb0 and 15\\xc2\\xb0, and by circularly shifting the images in the horizontal and \\nvertical directions by an amount no more than 20% of the image size. \\nThis approach helps our network to be more robust against alignment errors. \\nIn Fig. 2, we show the training curves of two stages of fine-tuning of the \\nnetwork with the FER dataset, where we set the learning rate and weight \\ndecay to 0.0005, momentum to 0.9, and dropout probability to 0.8 [25].'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "For the fine-tuning of the VGG-Face network for the emotion\n",
    "recognition task, we investigated various options in our preliminary\n",
    "analysis. We found that combining weight decay and dropout for regularization\n",
    "gives the best results on the FER validation set. We carry\n",
    "out a multi-stage fine-tuning. In the first stage, we fine-tune on the\n",
    "FER public test set, and run weight updates for five epochs. In the second\n",
    "stage, we update the upper layers (higher than layer 27) using'''\n",
    "\n",
    "''' We then fine-tune the VGG-face model on FER 2013\n",
    "dataset, using both the training and the public test set; during\n",
    "training we use data augmentation by jittering the scale, flipping\n",
    "and rotating the faces. The aim is to make the network more robust\n",
    "to small misalignment of the faces. We also apply a strong dropout\n",
    "on the last layer of the VGG (keeping only 5% of the nodes) to\n",
    "prevent over-fitting. We achieve a performance of 71.2% on the\n",
    "FER private test set, which is slightly higher than the previously\n",
    "published results '''\n",
    "\n",
    "'''During the training of the deep networks, we oversample the training\n",
    "images by rotating them around their center by a random angle between \n",
    "−15° and 15°, and by circularly shifting the images in the horizontal and \n",
    "vertical directions by an amount no more than 20% of the image size. \n",
    "This approach helps our network to be more robust against alignment errors. \n",
    "In Fig. 2, we show the training curves of two stages of fine-tuning of the \n",
    "network with the FER dataset, where we set the learning rate and weight \n",
    "decay to 0.0005, momentum to 0.9, and dropout probability to 0.8 [25].'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6879088e-ce15-45e6-8f39-29fd16ab529a"
    }
   },
   "source": [
    "### VGG16-Face model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d691c9bc-5b8d-42ae-b109-0597f42f5d60"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import VGG_FACE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "570025bf-5112-4fae-9432-4039578fc868"
    }
   },
   "outputs": [],
   "source": [
    "model = VGG_FACE.VGG_FACE\n",
    "\n",
    "model.load_state_dict(torch.load('VGG_FACE.pth'))\n",
    "\n",
    "#model.eval() #this will let you pass an input through the model and evaluate it? without training?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7ef650af-4012-42c1-a5f5-69e04cdd9cf8"
    }
   },
   "source": [
    "### Dataset: FERplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5e29d967-b841-48d2-8160-e678660be2ea"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "be8542c0-7e28-4b37-93f3-0fda5361a126"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Image name</th>\n",
       "      <th>neutral</th>\n",
       "      <th>happiness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>contempt</th>\n",
       "      <th>unknown</th>\n",
       "      <th>NF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000000.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000001.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000002.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000003.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000004.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000005.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000006.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000007.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000008.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000009.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000010.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000011.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000012.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000013.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000014.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000015.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000016.png</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000018.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000019.png</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000020.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000021.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000022.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000024.png</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000025.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000026.png</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000027.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000028.png</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000029.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000030.png</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000031.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35856</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035771.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35857</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035772.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35858</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035773.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35859</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035774.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35860</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035775.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35861</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035776.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35862</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035777.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35863</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035778.png</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35864</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035779.png</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35865</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035780.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35866</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035781.png</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35867</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035782.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35868</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035783.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35869</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035784.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35870</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035785.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35871</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035786.png</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35872</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035787.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35873</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035788.png</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35874</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035789.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35875</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035790.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35876</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035791.png</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35877</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035792.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35878</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035793.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35879</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035794.png</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35880</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035795.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35881</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035796.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035797.png</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035799.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035800.png</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>fer0035801.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35714 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Usage      Image name  neutral  happiness  surprise  sadness  \\\n",
       "0         Training  fer0000000.png        4          0         0        1   \n",
       "1         Training  fer0000001.png        6          0         1        1   \n",
       "2         Training  fer0000002.png        5          0         0        3   \n",
       "3         Training  fer0000003.png        4          0         0        4   \n",
       "4         Training  fer0000004.png        9          0         0        1   \n",
       "5         Training  fer0000005.png        6          0         0        1   \n",
       "6         Training  fer0000006.png        2          0         0        8   \n",
       "7         Training  fer0000007.png        0         10         0        0   \n",
       "8         Training  fer0000008.png        0         10         0        0   \n",
       "9         Training  fer0000009.png        0          0         6        0   \n",
       "10        Training  fer0000010.png        2          0         0        0   \n",
       "11        Training  fer0000011.png       10          0         0        0   \n",
       "12        Training  fer0000012.png        5          0         0        3   \n",
       "13        Training  fer0000013.png        9          0         0        1   \n",
       "14        Training  fer0000014.png        0         10         0        0   \n",
       "15        Training  fer0000015.png        0          0         6        0   \n",
       "16        Training  fer0000016.png        4          6         0        0   \n",
       "18        Training  fer0000018.png        1          0         2        4   \n",
       "19        Training  fer0000019.png        6          1         0        0   \n",
       "20        Training  fer0000020.png        5          0         0        4   \n",
       "21        Training  fer0000021.png        1          0         1        2   \n",
       "22        Training  fer0000022.png        1          0         1        1   \n",
       "24        Training  fer0000024.png        2          7         0        0   \n",
       "25        Training  fer0000025.png        0         10         0        0   \n",
       "26        Training  fer0000026.png        4          2         4        0   \n",
       "27        Training  fer0000027.png        0          0         0        0   \n",
       "28        Training  fer0000028.png        1          7         0        0   \n",
       "29        Training  fer0000029.png        0          1         6        0   \n",
       "30        Training  fer0000030.png        0          9         0        0   \n",
       "31        Training  fer0000031.png       10          0         0        0   \n",
       "...            ...             ...      ...        ...       ...      ...   \n",
       "35856  PrivateTest  fer0035771.png        0         10         0        0   \n",
       "35857  PrivateTest  fer0035772.png        0          0        10        0   \n",
       "35858  PrivateTest  fer0035773.png        1          0         1        7   \n",
       "35859  PrivateTest  fer0035774.png       10          0         0        0   \n",
       "35860  PrivateTest  fer0035775.png        0         10         0        0   \n",
       "35861  PrivateTest  fer0035776.png        9          0         0        0   \n",
       "35862  PrivateTest  fer0035777.png        2          0         3        0   \n",
       "35863  PrivateTest  fer0035778.png        0          2         7        0   \n",
       "35864  PrivateTest  fer0035779.png        4          1         0        4   \n",
       "35865  PrivateTest  fer0035780.png        0         10         0        0   \n",
       "35866  PrivateTest  fer0035781.png        7          3         0        0   \n",
       "35867  PrivateTest  fer0035782.png        0         10         0        0   \n",
       "35868  PrivateTest  fer0035783.png        0          0         0        0   \n",
       "35869  PrivateTest  fer0035784.png        0         10         0        0   \n",
       "35870  PrivateTest  fer0035785.png        0          0         0        0   \n",
       "35871  PrivateTest  fer0035786.png        9          1         0        0   \n",
       "35872  PrivateTest  fer0035787.png        6          0         0        0   \n",
       "35873  PrivateTest  fer0035788.png        8          0         0        2   \n",
       "35874  PrivateTest  fer0035789.png        1          0         1        5   \n",
       "35875  PrivateTest  fer0035790.png        2          0         5        1   \n",
       "35876  PrivateTest  fer0035791.png        1          9         0        0   \n",
       "35877  PrivateTest  fer0035792.png        4          0         0        5   \n",
       "35878  PrivateTest  fer0035793.png        0         10         0        0   \n",
       "35879  PrivateTest  fer0035794.png        3          0         0        5   \n",
       "35880  PrivateTest  fer0035795.png        0          0         1        6   \n",
       "35881  PrivateTest  fer0035796.png        5          0         0        3   \n",
       "35882  PrivateTest  fer0035797.png        8          0         0        2   \n",
       "35884  PrivateTest  fer0035799.png        0          0         0        0   \n",
       "35885  PrivateTest  fer0035800.png        0         10         0        0   \n",
       "35886  PrivateTest  fer0035801.png        2          0         0        5   \n",
       "\n",
       "       anger  disgust  fear  contempt  unknown  NF  \n",
       "0          3        2     0         0        0   0  \n",
       "1          0        0     0         0        2   0  \n",
       "2          1        0     0         0        1   0  \n",
       "3          1        0     0         0        1   0  \n",
       "4          0        0     0         0        0   0  \n",
       "5          0        0     1         1        1   0  \n",
       "6          0        0     0         0        0   0  \n",
       "7          0        0     0         0        0   0  \n",
       "8          0        0     0         0        0   0  \n",
       "9          0        0     4         0        0   0  \n",
       "10         8        0     0         0        0   0  \n",
       "11         0        0     0         0        0   0  \n",
       "12         0        0     0         0        2   0  \n",
       "13         0        0     0         0        0   0  \n",
       "14         0        0     0         0        0   0  \n",
       "15         1        0     3         0        0   0  \n",
       "16         0        0     0         0        0   0  \n",
       "18         2        0     0         0        1   0  \n",
       "19         3        0     0         0        0   0  \n",
       "20         0        0     0         0        1   0  \n",
       "21         0        0     5         0        1   0  \n",
       "22         7        0     0         0        0   0  \n",
       "24         0        0     0         1        0   0  \n",
       "25         0        0     0         0        0   0  \n",
       "26         0        0     0         0        0   0  \n",
       "27         7        1     0         0        2   0  \n",
       "28         0        2     0         0        0   0  \n",
       "29         0        0     3         0        0   0  \n",
       "30         0        1     0         0        0   0  \n",
       "31         0        0     0         0        0   0  \n",
       "...      ...      ...   ...       ...      ...  ..  \n",
       "35856      0        0     0         0        0   0  \n",
       "35857      0        0     0         0        0   0  \n",
       "35858      0        0     0         0        1   0  \n",
       "35859      0        0     0         0        0   0  \n",
       "35860      0        0     0         0        0   0  \n",
       "35861      0        0     0         0        1   0  \n",
       "35862      0        0     5         0        0   0  \n",
       "35863      0        0     1         0        0   0  \n",
       "35864      0        0     0         0        1   0  \n",
       "35865      0        0     0         0        0   0  \n",
       "35866      0        0     0         0        0   0  \n",
       "35867      0        0     0         0        0   0  \n",
       "35868      7        0     2         0        1   0  \n",
       "35869      0        0     0         0        0   0  \n",
       "35870     10        0     0         0        0   0  \n",
       "35871      0        0     0         0        0   0  \n",
       "35872      1        1     1         0        1   0  \n",
       "35873      0        0     0         0        0   0  \n",
       "35874      0        0     1         0        2   0  \n",
       "35875      0        0     0         1        1   0  \n",
       "35876      0        0     0         0        0   0  \n",
       "35877      0        0     0         0        1   0  \n",
       "35878      0        0     0         0        0   0  \n",
       "35879      1        0     0         0        1   0  \n",
       "35880      0        0     3         0        0   0  \n",
       "35881      0        0     0         0        2   0  \n",
       "35882      0        0     0         0        0   0  \n",
       "35884      7        1     0         2        0   0  \n",
       "35885      0        0     0         0        0   0  \n",
       "35886      1        1     0         0        1   0  \n",
       "\n",
       "[35714 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all-data/FERPlus/fer2013new.csv')\n",
    "df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0ca1abe4-7bb7-4bbe-8faf-080cad04eaf5"
    }
   },
   "outputs": [],
   "source": [
    "class FaceEmotionsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.emotions_frame = pd.read_csv(csv_file)\n",
    "        self.emotions_frame.dropna(axis=0, how='any', inplace=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.emotions_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.emotions_frame.iloc[idx][1]\n",
    "        \n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = io.imread(img_path)\n",
    "        #this takes the most highest ranked emotion. if two emotions have the same ranking, it just takes the first one\n",
    "        emotion = np.argmax(self.emotions_frame.iloc[idx,2:].as_matrix())\n",
    "        \n",
    "        if (emotion == 1 or emotion == 2):\n",
    "            emotion = 2\n",
    "        elif (emotion > 2 and emotion < 8):\n",
    "            emotion = 0\n",
    "        else:\n",
    "            emotion = 1\n",
    "        \n",
    "        sample = {'image': image, 'emotion': emotion}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7eb85ee3-259b-4395-a288-ee1af15c1f41"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "emotions_frame = pd.read_csv('all-data/FERPlus/fer2013new.csv')\n",
    "emotions_frame.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "emotion = np.argmax(emotions_frame.iloc[10,2:].as_matrix())\n",
    "print(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "252d81d5-707f-4133-add3-fe798d2dc52e"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emotion': 0, 'image': array([[ 30,  24,  21, ...,  37,  44,  37],\n",
       "        [ 31,  22,  21, ...,  37,  35,  41],\n",
       "        [ 27,  22,  19, ...,  33,  34,  40],\n",
       "        ..., \n",
       "        [ 29,  29,  26, ..., 118, 132, 148],\n",
       "        [ 30,  30,  27, ..., 154, 159, 166],\n",
       "        [ 32,  29,  28, ..., 172, 173, 173]], dtype=uint8)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_emotions = FaceEmotionsDataset(csv_file = 'all-data/FERPlus/fer2013new_training.csv', \n",
    "                                    root_dir = 'all-data/FERPlus/data/FER2013Train')\n",
    "\n",
    "face_emotions[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0d088434-f0c7-4d61-a29f-29d2529e3ad1"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from skimage import transform\n",
    "from PIL import Image\n",
    "from skimage import io; io.use_plugin('matplotlib')\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, emotion = sample['image'], sample['emotion']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        #print(image.shape)\n",
    "        #image = image.transpose((2, 0, 1))\n",
    "        image = np.expand_dims(image,0)\n",
    "        y = np.copy(image)\n",
    "        z = np.copy(image)\n",
    "        z = np.concatenate((y,z), axis=0)    \n",
    "        image = np.concatenate((image,z), axis=0)\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'emotion': emotion}\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, emotion = sample['image'], sample['emotion']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        #emotion = emotion - [left, top]\n",
    "\n",
    "        return {'image': image, 'emotion': emotion}\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or tuple): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, emotion = sample['image'], sample['emotion']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        \n",
    "        #emotion = emotion * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'emotion': emotion}\n",
    "\n",
    "\n",
    "imgTransform = transforms.Compose([Rescale(256), #scale to 256x256\n",
    "                                   #transforms.CenterCrop(224), #crops the image at center to 224x224\n",
    "                                   RandomCrop(224),\n",
    "                                   ToTensor()\n",
    "                                   ])\n",
    "                                   #, #turn the jpg/pil/wahtever image into a tensor\n",
    "                                   #transforms.Normalize(mean = [0.485, 0.456, 0.406], #normalize with these vals\n",
    "                                                        #std=[0.229, 0.224, 0.225])])\n",
    "                                    ##HOW TO GET NORMALIZED VALUES?\n",
    "                                    #to add: jitter/rotate data augmentation, flipping, \n",
    "                                   \n",
    "#this doesn't work because the data is organized w a csv file w prob distrib of labels \n",
    "#instead of a single ground truth\n",
    "#see this paper: https://arxiv.org/pdf/1608.01041.pdf\n",
    "trainset = FaceEmotionsDataset(csv_file = 'all-data/FERPlus/fer2013new_training.csv', \n",
    "                                    root_dir = 'all-data/FERPlus/data/FER2013Train', transform = imgTransform)\n",
    "valset = FaceEmotionsDataset(csv_file = 'all-data/FERPlus/fer2013new_validation.csv', \n",
    "                                    root_dir = 'all-data/FERPlus/data/FER2013Valid', transform = imgTransform)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size = 32, \n",
    "                                          shuffle = True, num_workers = 0)\n",
    "valLoader = torch.utils.data.DataLoader(valset, batch_size = 32, \n",
    "                                       shuffle = False, num_workers = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( 0 , 0 ,.,.) = \n",
      "  0.4059  0.4210  0.4234  ...   0.4108  0.4809  0.5509\n",
      "  0.4038  0.4179  0.4191  ...   0.4283  0.5016  0.5750\n",
      "  0.4023  0.4154  0.4155  ...   0.4479  0.5232  0.5985\n",
      "           ...             ⋱             ...          \n",
      "  0.2122  0.3069  0.4124  ...   0.0219  0.0212  0.0205\n",
      "  0.2114  0.3050  0.4091  ...   0.0219  0.0212  0.0205\n",
      "  0.2107  0.3031  0.4058  ...   0.0219  0.0212  0.0205\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.4059  0.4210  0.4234  ...   0.4108  0.4809  0.5509\n",
      "  0.4038  0.4179  0.4191  ...   0.4283  0.5016  0.5750\n",
      "  0.4023  0.4154  0.4155  ...   0.4479  0.5232  0.5985\n",
      "           ...             ⋱             ...          \n",
      "  0.2122  0.3069  0.4124  ...   0.0219  0.0212  0.0205\n",
      "  0.2114  0.3050  0.4091  ...   0.0219  0.0212  0.0205\n",
      "  0.2107  0.3031  0.4058  ...   0.0219  0.0212  0.0205\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.4059  0.4210  0.4234  ...   0.4108  0.4809  0.5509\n",
      "  0.4038  0.4179  0.4191  ...   0.4283  0.5016  0.5750\n",
      "  0.4023  0.4154  0.4155  ...   0.4479  0.5232  0.5985\n",
      "           ...             ⋱             ...          \n",
      "  0.2122  0.3069  0.4124  ...   0.0219  0.0212  0.0205\n",
      "  0.2114  0.3050  0.4091  ...   0.0219  0.0212  0.0205\n",
      "  0.2107  0.3031  0.4058  ...   0.0219  0.0212  0.0205\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.5635  0.5181  0.4727  ...   0.4259  0.4485  0.4696\n",
      "  0.5586  0.5081  0.4576  ...   0.4189  0.4411  0.4612\n",
      "  0.5537  0.4981  0.4425  ...   0.4119  0.4337  0.4528\n",
      "           ...             ⋱             ...          \n",
      "  0.8643  0.8576  0.8509  ...   0.7407  0.7503  0.7616\n",
      "  0.8655  0.8595  0.8535  ...   0.7439  0.7537  0.7648\n",
      "  0.8658  0.8606  0.8554  ...   0.7588  0.7696  0.7813\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.5635  0.5181  0.4727  ...   0.4259  0.4485  0.4696\n",
      "  0.5586  0.5081  0.4576  ...   0.4189  0.4411  0.4612\n",
      "  0.5537  0.4981  0.4425  ...   0.4119  0.4337  0.4528\n",
      "           ...             ⋱             ...          \n",
      "  0.8643  0.8576  0.8509  ...   0.7407  0.7503  0.7616\n",
      "  0.8655  0.8595  0.8535  ...   0.7439  0.7537  0.7648\n",
      "  0.8658  0.8606  0.8554  ...   0.7588  0.7696  0.7813\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.5635  0.5181  0.4727  ...   0.4259  0.4485  0.4696\n",
      "  0.5586  0.5081  0.4576  ...   0.4189  0.4411  0.4612\n",
      "  0.5537  0.4981  0.4425  ...   0.4119  0.4337  0.4528\n",
      "           ...             ⋱             ...          \n",
      "  0.8643  0.8576  0.8509  ...   0.7407  0.7503  0.7616\n",
      "  0.8655  0.8595  0.8535  ...   0.7439  0.7537  0.7648\n",
      "  0.8658  0.8606  0.8554  ...   0.7588  0.7696  0.7813\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.0072  0.0095  0.0118  ...   0.0001  0.0010  0.0023\n",
      "  0.0083  0.0108  0.0132  ...   0.0002  0.0008  0.0018\n",
      "  0.0094  0.0120  0.0146  ...   0.0002  0.0006  0.0013\n",
      "           ...             ⋱             ...          \n",
      "  0.7962  0.7977  0.7991  ...   0.6837  0.6876  0.6850\n",
      "  0.7999  0.8013  0.8028  ...   0.6985  0.7041  0.7037\n",
      "  0.8036  0.8050  0.8065  ...   0.7132  0.7206  0.7225\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.0072  0.0095  0.0118  ...   0.0001  0.0010  0.0023\n",
      "  0.0083  0.0108  0.0132  ...   0.0002  0.0008  0.0018\n",
      "  0.0094  0.0120  0.0146  ...   0.0002  0.0006  0.0013\n",
      "           ...             ⋱             ...          \n",
      "  0.7962  0.7977  0.7991  ...   0.6837  0.6876  0.6850\n",
      "  0.7999  0.8013  0.8028  ...   0.6985  0.7041  0.7037\n",
      "  0.8036  0.8050  0.8065  ...   0.7132  0.7206  0.7225\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.0072  0.0095  0.0118  ...   0.0001  0.0010  0.0023\n",
      "  0.0083  0.0108  0.0132  ...   0.0002  0.0008  0.0018\n",
      "  0.0094  0.0120  0.0146  ...   0.0002  0.0006  0.0013\n",
      "           ...             ⋱             ...          \n",
      "  0.7962  0.7977  0.7991  ...   0.6837  0.6876  0.6850\n",
      "  0.7999  0.8013  0.8028  ...   0.6985  0.7041  0.7037\n",
      "  0.8036  0.8050  0.8065  ...   0.7132  0.7206  0.7225\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(29 , 0 ,.,.) = \n",
      "  0.0955  0.0916  0.0887  ...   0.1252  0.1441  0.1629\n",
      "  0.0970  0.0934  0.0905  ...   0.1095  0.1272  0.1448\n",
      "  0.0975  0.0944  0.0917  ...   0.1234  0.1365  0.1496\n",
      "           ...             ⋱             ...          \n",
      "  0.2259  0.2488  0.2679  ...   0.1602  0.1445  0.1289\n",
      "  0.2222  0.2447  0.2638  ...   0.1623  0.1465  0.1308\n",
      "  0.2186  0.2407  0.2597  ...   0.1645  0.1485  0.1326\n",
      "\n",
      "(29 , 1 ,.,.) = \n",
      "  0.0955  0.0916  0.0887  ...   0.1252  0.1441  0.1629\n",
      "  0.0970  0.0934  0.0905  ...   0.1095  0.1272  0.1448\n",
      "  0.0975  0.0944  0.0917  ...   0.1234  0.1365  0.1496\n",
      "           ...             ⋱             ...          \n",
      "  0.2259  0.2488  0.2679  ...   0.1602  0.1445  0.1289\n",
      "  0.2222  0.2447  0.2638  ...   0.1623  0.1465  0.1308\n",
      "  0.2186  0.2407  0.2597  ...   0.1645  0.1485  0.1326\n",
      "\n",
      "(29 , 2 ,.,.) = \n",
      "  0.0955  0.0916  0.0887  ...   0.1252  0.1441  0.1629\n",
      "  0.0970  0.0934  0.0905  ...   0.1095  0.1272  0.1448\n",
      "  0.0975  0.0944  0.0917  ...   0.1234  0.1365  0.1496\n",
      "           ...             ⋱             ...          \n",
      "  0.2259  0.2488  0.2679  ...   0.1602  0.1445  0.1289\n",
      "  0.2222  0.2447  0.2638  ...   0.1623  0.1465  0.1308\n",
      "  0.2186  0.2407  0.2597  ...   0.1645  0.1485  0.1326\n",
      "      ⋮  \n",
      "\n",
      "(30 , 0 ,.,.) = \n",
      "  0.3349  0.3348  0.3348  ...   0.7313  0.7981  0.8432\n",
      "  0.3335  0.3321  0.3307  ...   0.7034  0.7756  0.8246\n",
      "  0.3322  0.3294  0.3266  ...   0.6755  0.7530  0.8061\n",
      "           ...             ⋱             ...          \n",
      "  0.1485  0.1506  0.1527  ...   0.0727  0.0717  0.0730\n",
      "  0.1476  0.1497  0.1518  ...   0.0705  0.0691  0.0702\n",
      "  0.1190  0.1207  0.1225  ...   0.0569  0.0557  0.0566\n",
      "\n",
      "(30 , 1 ,.,.) = \n",
      "  0.3349  0.3348  0.3348  ...   0.7313  0.7981  0.8432\n",
      "  0.3335  0.3321  0.3307  ...   0.7034  0.7756  0.8246\n",
      "  0.3322  0.3294  0.3266  ...   0.6755  0.7530  0.8061\n",
      "           ...             ⋱             ...          \n",
      "  0.1485  0.1506  0.1527  ...   0.0727  0.0717  0.0730\n",
      "  0.1476  0.1497  0.1518  ...   0.0705  0.0691  0.0702\n",
      "  0.1190  0.1207  0.1225  ...   0.0569  0.0557  0.0566\n",
      "\n",
      "(30 , 2 ,.,.) = \n",
      "  0.3349  0.3348  0.3348  ...   0.7313  0.7981  0.8432\n",
      "  0.3335  0.3321  0.3307  ...   0.7034  0.7756  0.8246\n",
      "  0.3322  0.3294  0.3266  ...   0.6755  0.7530  0.8061\n",
      "           ...             ⋱             ...          \n",
      "  0.1485  0.1506  0.1527  ...   0.0727  0.0717  0.0730\n",
      "  0.1476  0.1497  0.1518  ...   0.0705  0.0691  0.0702\n",
      "  0.1190  0.1207  0.1225  ...   0.0569  0.0557  0.0566\n",
      "      ⋮  \n",
      "\n",
      "(31 , 0 ,.,.) = \n",
      "  0.0632  0.0651  0.0907  ...   0.2993  0.3114  0.3235\n",
      "  0.0687  0.0716  0.0987  ...   0.2996  0.3104  0.3212\n",
      "  0.0729  0.0768  0.1048  ...   0.2884  0.2971  0.3058\n",
      "           ...             ⋱             ...          \n",
      "  0.0575  0.0575  0.0595  ...   0.6512  0.6642  0.6773\n",
      "  0.0569  0.0568  0.0586  ...   0.6503  0.6578  0.6653\n",
      "  0.0562  0.0560  0.0577  ...   0.6494  0.6514  0.6534\n",
      "\n",
      "(31 , 1 ,.,.) = \n",
      "  0.0632  0.0651  0.0907  ...   0.2993  0.3114  0.3235\n",
      "  0.0687  0.0716  0.0987  ...   0.2996  0.3104  0.3212\n",
      "  0.0729  0.0768  0.1048  ...   0.2884  0.2971  0.3058\n",
      "           ...             ⋱             ...          \n",
      "  0.0575  0.0575  0.0595  ...   0.6512  0.6642  0.6773\n",
      "  0.0569  0.0568  0.0586  ...   0.6503  0.6578  0.6653\n",
      "  0.0562  0.0560  0.0577  ...   0.6494  0.6514  0.6534\n",
      "\n",
      "(31 , 2 ,.,.) = \n",
      "  0.0632  0.0651  0.0907  ...   0.2993  0.3114  0.3235\n",
      "  0.0687  0.0716  0.0987  ...   0.2996  0.3104  0.3212\n",
      "  0.0729  0.0768  0.1048  ...   0.2884  0.2971  0.3058\n",
      "           ...             ⋱             ...          \n",
      "  0.0575  0.0575  0.0595  ...   0.6512  0.6642  0.6773\n",
      "  0.0569  0.0568  0.0586  ...   0.6503  0.6578  0.6653\n",
      "  0.0562  0.0560  0.0577  ...   0.6494  0.6514  0.6534\n",
      "[torch.DoubleTensor of size 32x3x224x224]\n",
      ", \n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 0\n",
      " 2\n",
      " 0\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 0\n",
      " 2\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 0\n",
      "[torch.LongTensor of size 32]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (i, sample) in enumerate(trainLoader):\n",
    "    inputs = sample['image']\n",
    "    labels = sample['emotion']\n",
    "    print(\"{}, {}\".format(inputs, labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6d2ad753-43bf-4df1-b903-4dc8b543cff0"
    }
   },
   "source": [
    "### Function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d0d19064-5fe3-4fae-b953-b62bf3aeba34"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  0.7711  0.7544  0.7045  ...   0.1226  0.1322  0.1418\n",
      "  0.7547  0.7313  0.6740  ...   0.1265  0.1349  0.1432\n",
      "  0.7383  0.7082  0.6434  ...   0.1305  0.1376  0.1447\n",
      "           ...             ⋱             ...          \n",
      "  0.8811  0.9084  0.9069  ...   0.4649  0.5302  0.5954\n",
      "  0.8626  0.8886  0.8863  ...   0.4739  0.5388  0.6038\n",
      "  0.8503  0.8753  0.8723  ...   0.4844  0.5500  0.6156\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.7711  0.7544  0.7045  ...   0.1226  0.1322  0.1418\n",
      "  0.7547  0.7313  0.6740  ...   0.1265  0.1349  0.1432\n",
      "  0.7383  0.7082  0.6434  ...   0.1305  0.1376  0.1447\n",
      "           ...             ⋱             ...          \n",
      "  0.8811  0.9084  0.9069  ...   0.4649  0.5302  0.5954\n",
      "  0.8626  0.8886  0.8863  ...   0.4739  0.5388  0.6038\n",
      "  0.8503  0.8753  0.8723  ...   0.4844  0.5500  0.6156\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.7711  0.7544  0.7045  ...   0.1226  0.1322  0.1418\n",
      "  0.7547  0.7313  0.6740  ...   0.1265  0.1349  0.1432\n",
      "  0.7383  0.7082  0.6434  ...   0.1305  0.1376  0.1447\n",
      "           ...             ⋱             ...          \n",
      "  0.8811  0.9084  0.9069  ...   0.4649  0.5302  0.5954\n",
      "  0.8626  0.8886  0.8863  ...   0.4739  0.5388  0.6038\n",
      "  0.8503  0.8753  0.8723  ...   0.4844  0.5500  0.6156\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.1164  0.1164  0.1164  ...   0.2137  0.2091  0.2045\n",
      "  0.1444  0.1444  0.1444  ...   0.2650  0.2593  0.2536\n",
      "  0.1520  0.1521  0.1521  ...   0.2765  0.2725  0.2686\n",
      "           ...             ⋱             ...          \n",
      "  0.1225  0.1007  0.0938  ...   0.3720  0.3871  0.4021\n",
      "  0.1284  0.1072  0.0995  ...   0.3724  0.3852  0.3981\n",
      "  0.1343  0.1137  0.1052  ...   0.3727  0.3834  0.3941\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.1164  0.1164  0.1164  ...   0.2137  0.2091  0.2045\n",
      "  0.1444  0.1444  0.1444  ...   0.2650  0.2593  0.2536\n",
      "  0.1520  0.1521  0.1521  ...   0.2765  0.2725  0.2686\n",
      "           ...             ⋱             ...          \n",
      "  0.1225  0.1007  0.0938  ...   0.3720  0.3871  0.4021\n",
      "  0.1284  0.1072  0.0995  ...   0.3724  0.3852  0.3981\n",
      "  0.1343  0.1137  0.1052  ...   0.3727  0.3834  0.3941\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.1164  0.1164  0.1164  ...   0.2137  0.2091  0.2045\n",
      "  0.1444  0.1444  0.1444  ...   0.2650  0.2593  0.2536\n",
      "  0.1520  0.1521  0.1521  ...   0.2765  0.2725  0.2686\n",
      "           ...             ⋱             ...          \n",
      "  0.1225  0.1007  0.0938  ...   0.3720  0.3871  0.4021\n",
      "  0.1284  0.1072  0.0995  ...   0.3724  0.3852  0.3981\n",
      "  0.1343  0.1137  0.1052  ...   0.3727  0.3834  0.3941\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.1028  0.1051  0.1060  ...   0.0907  0.0946  0.0985\n",
      "  0.1034  0.1058  0.1069  ...   0.1014  0.1057  0.1100\n",
      "  0.1039  0.1064  0.1079  ...   0.1120  0.1167  0.1214\n",
      "           ...             ⋱             ...          \n",
      "  0.3679  0.3811  0.3840  ...   0.2267  0.2255  0.2244\n",
      "  0.3650  0.3782  0.3817  ...   0.2278  0.2263  0.2247\n",
      "  0.3620  0.3752  0.3793  ...   0.2290  0.2270  0.2250\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.1028  0.1051  0.1060  ...   0.0907  0.0946  0.0985\n",
      "  0.1034  0.1058  0.1069  ...   0.1014  0.1057  0.1100\n",
      "  0.1039  0.1064  0.1079  ...   0.1120  0.1167  0.1214\n",
      "           ...             ⋱             ...          \n",
      "  0.3679  0.3811  0.3840  ...   0.2267  0.2255  0.2244\n",
      "  0.3650  0.3782  0.3817  ...   0.2278  0.2263  0.2247\n",
      "  0.3620  0.3752  0.3793  ...   0.2290  0.2270  0.2250\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.1028  0.1051  0.1060  ...   0.0907  0.0946  0.0985\n",
      "  0.1034  0.1058  0.1069  ...   0.1014  0.1057  0.1100\n",
      "  0.1039  0.1064  0.1079  ...   0.1120  0.1167  0.1214\n",
      "           ...             ⋱             ...          \n",
      "  0.3679  0.3811  0.3840  ...   0.2267  0.2255  0.2244\n",
      "  0.3650  0.3782  0.3817  ...   0.2278  0.2263  0.2247\n",
      "  0.3620  0.3752  0.3793  ...   0.2290  0.2270  0.2250\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(29 , 0 ,.,.) = \n",
      "  0.3174  0.3043  0.2905  ...   0.0305  0.0302  0.0298\n",
      "  0.3200  0.3073  0.2921  ...   0.0317  0.0312  0.0307\n",
      "  0.3227  0.3103  0.2938  ...   0.0329  0.0323  0.0317\n",
      "           ...             ⋱             ...          \n",
      "  0.3009  0.3018  0.3028  ...   0.4399  0.4390  0.4381\n",
      "  0.2936  0.2944  0.2968  ...   0.4365  0.4329  0.4292\n",
      "  0.2854  0.2850  0.2876  ...   0.4340  0.4289  0.4239\n",
      "\n",
      "(29 , 1 ,.,.) = \n",
      "  0.3174  0.3043  0.2905  ...   0.0305  0.0302  0.0298\n",
      "  0.3200  0.3073  0.2921  ...   0.0317  0.0312  0.0307\n",
      "  0.3227  0.3103  0.2938  ...   0.0329  0.0323  0.0317\n",
      "           ...             ⋱             ...          \n",
      "  0.3009  0.3018  0.3028  ...   0.4399  0.4390  0.4381\n",
      "  0.2936  0.2944  0.2968  ...   0.4365  0.4329  0.4292\n",
      "  0.2854  0.2850  0.2876  ...   0.4340  0.4289  0.4239\n",
      "\n",
      "(29 , 2 ,.,.) = \n",
      "  0.3174  0.3043  0.2905  ...   0.0305  0.0302  0.0298\n",
      "  0.3200  0.3073  0.2921  ...   0.0317  0.0312  0.0307\n",
      "  0.3227  0.3103  0.2938  ...   0.0329  0.0323  0.0317\n",
      "           ...             ⋱             ...          \n",
      "  0.3009  0.3018  0.3028  ...   0.4399  0.4390  0.4381\n",
      "  0.2936  0.2944  0.2968  ...   0.4365  0.4329  0.4292\n",
      "  0.2854  0.2850  0.2876  ...   0.4340  0.4289  0.4239\n",
      "      ⋮  \n",
      "\n",
      "(30 , 0 ,.,.) = \n",
      "  0.1367  0.0819  0.0796  ...   0.8902  0.8902  0.8902\n",
      "  0.1297  0.0771  0.0763  ...   0.8902  0.8902  0.8902\n",
      "  0.1227  0.0724  0.0730  ...   0.8902  0.8902  0.8902\n",
      "           ...             ⋱             ...          \n",
      "  0.7197  0.7118  0.6921  ...   0.7041  0.7004  0.6967\n",
      "  0.7073  0.7002  0.6812  ...   0.6902  0.6860  0.6817\n",
      "  0.5704  0.5647  0.5494  ...   0.5566  0.5532  0.5497\n",
      "\n",
      "(30 , 1 ,.,.) = \n",
      "  0.1367  0.0819  0.0796  ...   0.8902  0.8902  0.8902\n",
      "  0.1297  0.0771  0.0763  ...   0.8902  0.8902  0.8902\n",
      "  0.1227  0.0724  0.0730  ...   0.8902  0.8902  0.8902\n",
      "           ...             ⋱             ...          \n",
      "  0.7197  0.7118  0.6921  ...   0.7041  0.7004  0.6967\n",
      "  0.7073  0.7002  0.6812  ...   0.6902  0.6860  0.6817\n",
      "  0.5704  0.5647  0.5494  ...   0.5566  0.5532  0.5497\n",
      "\n",
      "(30 , 2 ,.,.) = \n",
      "  0.1367  0.0819  0.0796  ...   0.8902  0.8902  0.8902\n",
      "  0.1297  0.0771  0.0763  ...   0.8902  0.8902  0.8902\n",
      "  0.1227  0.0724  0.0730  ...   0.8902  0.8902  0.8902\n",
      "           ...             ⋱             ...          \n",
      "  0.7197  0.7118  0.6921  ...   0.7041  0.7004  0.6967\n",
      "  0.7073  0.7002  0.6812  ...   0.6902  0.6860  0.6817\n",
      "  0.5704  0.5647  0.5494  ...   0.5566  0.5532  0.5497\n",
      "      ⋮  \n",
      "\n",
      "(31 , 0 ,.,.) = \n",
      "  0.9983  0.9978  0.9955  ...   0.6153  0.5967  0.5780\n",
      "  0.9988  0.9984  0.9963  ...   0.6351  0.6163  0.5976\n",
      "  0.9993  0.9991  0.9971  ...   0.6549  0.6360  0.6171\n",
      "           ...             ⋱             ...          \n",
      "  0.1747  0.1558  0.1379  ...   0.1411  0.1408  0.1405\n",
      "  0.1582  0.1378  0.1189  ...   0.1408  0.1402  0.1395\n",
      "  0.1406  0.1211  0.1031  ...   0.1409  0.1402  0.1396\n",
      "\n",
      "(31 , 1 ,.,.) = \n",
      "  0.9983  0.9978  0.9955  ...   0.6153  0.5967  0.5780\n",
      "  0.9988  0.9984  0.9963  ...   0.6351  0.6163  0.5976\n",
      "  0.9993  0.9991  0.9971  ...   0.6549  0.6360  0.6171\n",
      "           ...             ⋱             ...          \n",
      "  0.1747  0.1558  0.1379  ...   0.1411  0.1408  0.1405\n",
      "  0.1582  0.1378  0.1189  ...   0.1408  0.1402  0.1395\n",
      "  0.1406  0.1211  0.1031  ...   0.1409  0.1402  0.1396\n",
      "\n",
      "(31 , 2 ,.,.) = \n",
      "  0.9983  0.9978  0.9955  ...   0.6153  0.5967  0.5780\n",
      "  0.9988  0.9984  0.9963  ...   0.6351  0.6163  0.5976\n",
      "  0.9993  0.9991  0.9971  ...   0.6549  0.6360  0.6171\n",
      "           ...             ⋱             ...          \n",
      "  0.1747  0.1558  0.1379  ...   0.1411  0.1408  0.1405\n",
      "  0.1582  0.1378  0.1189  ...   0.1408  0.1402  0.1395\n",
      "  0.1406  0.1211  0.1031  ...   0.1409  0.1402  0.1396\n",
      "[torch.FloatTensor of size 32x3x224x224]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 0\n",
      " 2\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 1\n",
      "[torch.LongTensor of size 32]\n",
      "\n",
      "Variable containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  0.2290  0.2293  0.2296  ...   0.2002  0.1988  0.1973\n",
      "  0.2313  0.2306  0.2300  ...   0.2001  0.1986  0.1971\n",
      "  0.2314  0.2313  0.2312  ...   0.1990  0.1974  0.1957\n",
      "           ...             ⋱             ...          \n",
      "  0.4523  0.4547  0.4570  ...   0.7751  0.7696  0.7641\n",
      "  0.4582  0.4601  0.4620  ...   0.7522  0.7498  0.7474\n",
      "  0.4640  0.4655  0.4670  ...   0.7292  0.7300  0.7308\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.2290  0.2293  0.2296  ...   0.2002  0.1988  0.1973\n",
      "  0.2313  0.2306  0.2300  ...   0.2001  0.1986  0.1971\n",
      "  0.2314  0.2313  0.2312  ...   0.1990  0.1974  0.1957\n",
      "           ...             ⋱             ...          \n",
      "  0.4523  0.4547  0.4570  ...   0.7751  0.7696  0.7641\n",
      "  0.4582  0.4601  0.4620  ...   0.7522  0.7498  0.7474\n",
      "  0.4640  0.4655  0.4670  ...   0.7292  0.7300  0.7308\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.2290  0.2293  0.2296  ...   0.2002  0.1988  0.1973\n",
      "  0.2313  0.2306  0.2300  ...   0.2001  0.1986  0.1971\n",
      "  0.2314  0.2313  0.2312  ...   0.1990  0.1974  0.1957\n",
      "           ...             ⋱             ...          \n",
      "  0.4523  0.4547  0.4570  ...   0.7751  0.7696  0.7641\n",
      "  0.4582  0.4601  0.4620  ...   0.7522  0.7498  0.7474\n",
      "  0.4640  0.4655  0.4670  ...   0.7292  0.7300  0.7308\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.4754  0.4970  0.5123  ...   0.2346  0.2393  0.2439\n",
      "  0.4834  0.5062  0.5225  ...   0.2326  0.2379  0.2431\n",
      "  0.4914  0.5155  0.5326  ...   0.2307  0.2365  0.2423\n",
      "           ...             ⋱             ...          \n",
      "  0.3144  0.3181  0.3218  ...   0.1373  0.1527  0.1681\n",
      "  0.3120  0.3158  0.3195  ...   0.1380  0.1534  0.1689\n",
      "  0.3095  0.3135  0.3172  ...   0.1387  0.1542  0.1696\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.4754  0.4970  0.5123  ...   0.2346  0.2393  0.2439\n",
      "  0.4834  0.5062  0.5225  ...   0.2326  0.2379  0.2431\n",
      "  0.4914  0.5155  0.5326  ...   0.2307  0.2365  0.2423\n",
      "           ...             ⋱             ...          \n",
      "  0.3144  0.3181  0.3218  ...   0.1373  0.1527  0.1681\n",
      "  0.3120  0.3158  0.3195  ...   0.1380  0.1534  0.1689\n",
      "  0.3095  0.3135  0.3172  ...   0.1387  0.1542  0.1696\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.4754  0.4970  0.5123  ...   0.2346  0.2393  0.2439\n",
      "  0.4834  0.5062  0.5225  ...   0.2326  0.2379  0.2431\n",
      "  0.4914  0.5155  0.5326  ...   0.2307  0.2365  0.2423\n",
      "           ...             ⋱             ...          \n",
      "  0.3144  0.3181  0.3218  ...   0.1373  0.1527  0.1681\n",
      "  0.3120  0.3158  0.3195  ...   0.1380  0.1534  0.1689\n",
      "  0.3095  0.3135  0.3172  ...   0.1387  0.1542  0.1696\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.5874  0.5964  0.6097  ...   0.0078  0.0078  0.0078\n",
      "  0.5723  0.5819  0.5956  ...   0.0078  0.0078  0.0078\n",
      "  0.5572  0.5674  0.5815  ...   0.0078  0.0078  0.0078\n",
      "           ...             ⋱             ...          \n",
      "  0.3522  0.3521  0.3527  ...   0.5629  0.5563  0.5496\n",
      "  0.3473  0.3474  0.3488  ...   0.5952  0.5886  0.5820\n",
      "  0.3424  0.3427  0.3449  ...   0.6276  0.6210  0.6143\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.5874  0.5964  0.6097  ...   0.0078  0.0078  0.0078\n",
      "  0.5723  0.5819  0.5956  ...   0.0078  0.0078  0.0078\n",
      "  0.5572  0.5674  0.5815  ...   0.0078  0.0078  0.0078\n",
      "           ...             ⋱             ...          \n",
      "  0.3522  0.3521  0.3527  ...   0.5629  0.5563  0.5496\n",
      "  0.3473  0.3474  0.3488  ...   0.5952  0.5886  0.5820\n",
      "  0.3424  0.3427  0.3449  ...   0.6276  0.6210  0.6143\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.5874  0.5964  0.6097  ...   0.0078  0.0078  0.0078\n",
      "  0.5723  0.5819  0.5956  ...   0.0078  0.0078  0.0078\n",
      "  0.5572  0.5674  0.5815  ...   0.0078  0.0078  0.0078\n",
      "           ...             ⋱             ...          \n",
      "  0.3522  0.3521  0.3527  ...   0.5629  0.5563  0.5496\n",
      "  0.3473  0.3474  0.3488  ...   0.5952  0.5886  0.5820\n",
      "  0.3424  0.3427  0.3449  ...   0.6276  0.6210  0.6143\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(29 , 0 ,.,.) = \n",
      "  0.2015  0.2188  0.2360  ...   0.7770  0.7748  0.7725\n",
      "  0.2052  0.2223  0.2394  ...   0.7777  0.7755  0.7733\n",
      "  0.2088  0.2258  0.2428  ...   0.7784  0.7762  0.7740\n",
      "           ...             ⋱             ...          \n",
      "  0.2839  0.2465  0.2090  ...   0.7567  0.7553  0.7539\n",
      "  0.2845  0.2468  0.2091  ...   0.7414  0.7420  0.7426\n",
      "  0.2852  0.2472  0.2092  ...   0.7226  0.7257  0.7288\n",
      "\n",
      "(29 , 1 ,.,.) = \n",
      "  0.2015  0.2188  0.2360  ...   0.7770  0.7748  0.7725\n",
      "  0.2052  0.2223  0.2394  ...   0.7777  0.7755  0.7733\n",
      "  0.2088  0.2258  0.2428  ...   0.7784  0.7762  0.7740\n",
      "           ...             ⋱             ...          \n",
      "  0.2839  0.2465  0.2090  ...   0.7567  0.7553  0.7539\n",
      "  0.2845  0.2468  0.2091  ...   0.7414  0.7420  0.7426\n",
      "  0.2852  0.2472  0.2092  ...   0.7226  0.7257  0.7288\n",
      "\n",
      "(29 , 2 ,.,.) = \n",
      "  0.2015  0.2188  0.2360  ...   0.7770  0.7748  0.7725\n",
      "  0.2052  0.2223  0.2394  ...   0.7777  0.7755  0.7733\n",
      "  0.2088  0.2258  0.2428  ...   0.7784  0.7762  0.7740\n",
      "           ...             ⋱             ...          \n",
      "  0.2839  0.2465  0.2090  ...   0.7567  0.7553  0.7539\n",
      "  0.2845  0.2468  0.2091  ...   0.7414  0.7420  0.7426\n",
      "  0.2852  0.2472  0.2092  ...   0.7226  0.7257  0.7288\n",
      "      ⋮  \n",
      "\n",
      "(30 , 0 ,.,.) = \n",
      "  0.0197  0.0200  0.0227  ...   0.0059  0.0066  0.0074\n",
      "  0.0196  0.0201  0.0230  ...   0.0051  0.0059  0.0066\n",
      "  0.0194  0.0201  0.0229  ...   0.0049  0.0055  0.0061\n",
      "           ...             ⋱             ...          \n",
      "  0.0228  0.0240  0.0269  ...   0.0129  0.0116  0.0102\n",
      "  0.0227  0.0241  0.0275  ...   0.0123  0.0112  0.0100\n",
      "  0.0226  0.0242  0.0281  ...   0.0118  0.0108  0.0097\n",
      "\n",
      "(30 , 1 ,.,.) = \n",
      "  0.0197  0.0200  0.0227  ...   0.0059  0.0066  0.0074\n",
      "  0.0196  0.0201  0.0230  ...   0.0051  0.0059  0.0066\n",
      "  0.0194  0.0201  0.0229  ...   0.0049  0.0055  0.0061\n",
      "           ...             ⋱             ...          \n",
      "  0.0228  0.0240  0.0269  ...   0.0129  0.0116  0.0102\n",
      "  0.0227  0.0241  0.0275  ...   0.0123  0.0112  0.0100\n",
      "  0.0226  0.0242  0.0281  ...   0.0118  0.0108  0.0097\n",
      "\n",
      "(30 , 2 ,.,.) = \n",
      "  0.0197  0.0200  0.0227  ...   0.0059  0.0066  0.0074\n",
      "  0.0196  0.0201  0.0230  ...   0.0051  0.0059  0.0066\n",
      "  0.0194  0.0201  0.0229  ...   0.0049  0.0055  0.0061\n",
      "           ...             ⋱             ...          \n",
      "  0.0228  0.0240  0.0269  ...   0.0129  0.0116  0.0102\n",
      "  0.0227  0.0241  0.0275  ...   0.0123  0.0112  0.0100\n",
      "  0.0226  0.0242  0.0281  ...   0.0118  0.0108  0.0097\n",
      "      ⋮  \n",
      "\n",
      "(31 , 0 ,.,.) = \n",
      "  0.6641  0.6643  0.6648  ...   0.2275  0.2152  0.2030\n",
      "  0.6634  0.6637  0.6643  ...   0.2376  0.2212  0.2048\n",
      "  0.6629  0.6632  0.6639  ...   0.2476  0.2278  0.2081\n",
      "           ...             ⋱             ...          \n",
      "  0.0849  0.0741  0.0647  ...   0.3096  0.2664  0.2231\n",
      "  0.0854  0.0750  0.0658  ...   0.3169  0.2768  0.2367\n",
      "  0.0858  0.0758  0.0670  ...   0.3242  0.2873  0.2504\n",
      "\n",
      "(31 , 1 ,.,.) = \n",
      "  0.6641  0.6643  0.6648  ...   0.2275  0.2152  0.2030\n",
      "  0.6634  0.6637  0.6643  ...   0.2376  0.2212  0.2048\n",
      "  0.6629  0.6632  0.6639  ...   0.2476  0.2278  0.2081\n",
      "           ...             ⋱             ...          \n",
      "  0.0849  0.0741  0.0647  ...   0.3096  0.2664  0.2231\n",
      "  0.0854  0.0750  0.0658  ...   0.3169  0.2768  0.2367\n",
      "  0.0858  0.0758  0.0670  ...   0.3242  0.2873  0.2504\n",
      "\n",
      "(31 , 2 ,.,.) = \n",
      "  0.6641  0.6643  0.6648  ...   0.2275  0.2152  0.2030\n",
      "  0.6634  0.6637  0.6643  ...   0.2376  0.2212  0.2048\n",
      "  0.6629  0.6632  0.6639  ...   0.2476  0.2278  0.2081\n",
      "           ...             ⋱             ...          \n",
      "  0.0849  0.0741  0.0647  ...   0.3096  0.2664  0.2231\n",
      "  0.0854  0.0750  0.0658  ...   0.3169  0.2768  0.2367\n",
      "  0.0858  0.0758  0.0670  ...   0.3242  0.2873  0.2504\n",
      "[torch.FloatTensor of size 32x3x224x224]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 32]\n",
      "\n",
      "Variable containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  0.1545  0.2033  0.2520  ...   0.2551  0.2671  0.2791\n",
      "  0.1593  0.2096  0.2599  ...   0.2671  0.2760  0.2850\n",
      "  0.1641  0.2159  0.2677  ...   0.2791  0.2850  0.2909\n",
      "           ...             ⋱             ...          \n",
      "  0.1043  0.1373  0.1702  ...   0.4002  0.3864  0.3727\n",
      "  0.1070  0.1407  0.1745  ...   0.3863  0.3777  0.3691\n",
      "  0.1096  0.1442  0.1788  ...   0.3725  0.3689  0.3654\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.1545  0.2033  0.2520  ...   0.2551  0.2671  0.2791\n",
      "  0.1593  0.2096  0.2599  ...   0.2671  0.2760  0.2850\n",
      "  0.1641  0.2159  0.2677  ...   0.2791  0.2850  0.2909\n",
      "           ...             ⋱             ...          \n",
      "  0.1043  0.1373  0.1702  ...   0.4002  0.3864  0.3727\n",
      "  0.1070  0.1407  0.1745  ...   0.3863  0.3777  0.3691\n",
      "  0.1096  0.1442  0.1788  ...   0.3725  0.3689  0.3654\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.1545  0.2033  0.2520  ...   0.2551  0.2671  0.2791\n",
      "  0.1593  0.2096  0.2599  ...   0.2671  0.2760  0.2850\n",
      "  0.1641  0.2159  0.2677  ...   0.2791  0.2850  0.2909\n",
      "           ...             ⋱             ...          \n",
      "  0.1043  0.1373  0.1702  ...   0.4002  0.3864  0.3727\n",
      "  0.1070  0.1407  0.1745  ...   0.3863  0.3777  0.3691\n",
      "  0.1096  0.1442  0.1788  ...   0.3725  0.3689  0.3654\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.7996  0.7994  0.8007  ...   0.1896  0.1931  0.1966\n",
      "  0.7988  0.7986  0.7998  ...   0.1894  0.1928  0.1961\n",
      "  0.7979  0.7978  0.7989  ...   0.1892  0.1924  0.1957\n",
      "           ...             ⋱             ...          \n",
      "  0.5497  0.5528  0.5448  ...   0.9666  0.9661  0.9656\n",
      "  0.5506  0.5542  0.5453  ...   0.9671  0.9665  0.9658\n",
      "  0.5534  0.5570  0.5469  ...   0.9676  0.9668  0.9661\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.7996  0.7994  0.8007  ...   0.1896  0.1931  0.1966\n",
      "  0.7988  0.7986  0.7998  ...   0.1894  0.1928  0.1961\n",
      "  0.7979  0.7978  0.7989  ...   0.1892  0.1924  0.1957\n",
      "           ...             ⋱             ...          \n",
      "  0.5497  0.5528  0.5448  ...   0.9666  0.9661  0.9656\n",
      "  0.5506  0.5542  0.5453  ...   0.9671  0.9665  0.9658\n",
      "  0.5534  0.5570  0.5469  ...   0.9676  0.9668  0.9661\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.7996  0.7994  0.8007  ...   0.1896  0.1931  0.1966\n",
      "  0.7988  0.7986  0.7998  ...   0.1894  0.1928  0.1961\n",
      "  0.7979  0.7978  0.7989  ...   0.1892  0.1924  0.1957\n",
      "           ...             ⋱             ...          \n",
      "  0.5497  0.5528  0.5448  ...   0.9666  0.9661  0.9656\n",
      "  0.5506  0.5542  0.5453  ...   0.9671  0.9665  0.9658\n",
      "  0.5534  0.5570  0.5469  ...   0.9676  0.9668  0.9661\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.8409  0.8120  0.7830  ...   0.4656  0.4624  0.4591\n",
      "  0.8281  0.8034  0.7786  ...   0.4727  0.4682  0.4637\n",
      "  0.8154  0.7948  0.7741  ...   0.4798  0.4741  0.4684\n",
      "           ...             ⋱             ...          \n",
      "  0.8248  0.8198  0.8148  ...   0.4274  0.4250  0.4225\n",
      "  0.8274  0.8220  0.8166  ...   0.4257  0.4227  0.4196\n",
      "  0.8300  0.8241  0.8183  ...   0.4239  0.4204  0.4168\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.8409  0.8120  0.7830  ...   0.4656  0.4624  0.4591\n",
      "  0.8281  0.8034  0.7786  ...   0.4727  0.4682  0.4637\n",
      "  0.8154  0.7948  0.7741  ...   0.4798  0.4741  0.4684\n",
      "           ...             ⋱             ...          \n",
      "  0.8248  0.8198  0.8148  ...   0.4274  0.4250  0.4225\n",
      "  0.8274  0.8220  0.8166  ...   0.4257  0.4227  0.4196\n",
      "  0.8300  0.8241  0.8183  ...   0.4239  0.4204  0.4168\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.8409  0.8120  0.7830  ...   0.4656  0.4624  0.4591\n",
      "  0.8281  0.8034  0.7786  ...   0.4727  0.4682  0.4637\n",
      "  0.8154  0.7948  0.7741  ...   0.4798  0.4741  0.4684\n",
      "           ...             ⋱             ...          \n",
      "  0.8248  0.8198  0.8148  ...   0.4274  0.4250  0.4225\n",
      "  0.8274  0.8220  0.8166  ...   0.4257  0.4227  0.4196\n",
      "  0.8300  0.8241  0.8183  ...   0.4239  0.4204  0.4168\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(29 , 0 ,.,.) = \n",
      "  0.1643  0.2162  0.2681  ...   0.4202  0.4172  0.4141\n",
      "  0.1652  0.2173  0.2695  ...   0.4208  0.4173  0.4137\n",
      "  0.1660  0.2185  0.2709  ...   0.4215  0.4174  0.4132\n",
      "           ...             ⋱             ...          \n",
      "  0.5518  0.7261  0.9004  ...   0.7616  0.7627  0.7639\n",
      "  0.5518  0.7261  0.9004  ...   0.7637  0.7646  0.7655\n",
      "  0.5523  0.7267  0.9011  ...   0.7648  0.7656  0.7664\n",
      "\n",
      "(29 , 1 ,.,.) = \n",
      "  0.1643  0.2162  0.2681  ...   0.4202  0.4172  0.4141\n",
      "  0.1652  0.2173  0.2695  ...   0.4208  0.4173  0.4137\n",
      "  0.1660  0.2185  0.2709  ...   0.4215  0.4174  0.4132\n",
      "           ...             ⋱             ...          \n",
      "  0.5518  0.7261  0.9004  ...   0.7616  0.7627  0.7639\n",
      "  0.5518  0.7261  0.9004  ...   0.7637  0.7646  0.7655\n",
      "  0.5523  0.7267  0.9011  ...   0.7648  0.7656  0.7664\n",
      "\n",
      "(29 , 2 ,.,.) = \n",
      "  0.1643  0.2162  0.2681  ...   0.4202  0.4172  0.4141\n",
      "  0.1652  0.2173  0.2695  ...   0.4208  0.4173  0.4137\n",
      "  0.1660  0.2185  0.2709  ...   0.4215  0.4174  0.4132\n",
      "           ...             ⋱             ...          \n",
      "  0.5518  0.7261  0.9004  ...   0.7616  0.7627  0.7639\n",
      "  0.5518  0.7261  0.9004  ...   0.7637  0.7646  0.7655\n",
      "  0.5523  0.7267  0.9011  ...   0.7648  0.7656  0.7664\n",
      "      ⋮  \n",
      "\n",
      "(30 , 0 ,.,.) = \n",
      "  0.0038  0.0052  0.0066  ...   0.1332  0.1093  0.0855\n",
      "  0.0033  0.0061  0.0089  ...   0.1440  0.1238  0.1037\n",
      "  0.0028  0.0070  0.0111  ...   0.1548  0.1383  0.1219\n",
      "           ...             ⋱             ...          \n",
      "  0.2366  0.2066  0.1767  ...   0.0000  0.0000  0.0000\n",
      "  0.2155  0.1869  0.1584  ...   0.0000  0.0000  0.0000\n",
      "  0.1944  0.1672  0.1401  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "(30 , 1 ,.,.) = \n",
      "  0.0038  0.0052  0.0066  ...   0.1332  0.1093  0.0855\n",
      "  0.0033  0.0061  0.0089  ...   0.1440  0.1238  0.1037\n",
      "  0.0028  0.0070  0.0111  ...   0.1548  0.1383  0.1219\n",
      "           ...             ⋱             ...          \n",
      "  0.2366  0.2066  0.1767  ...   0.0000  0.0000  0.0000\n",
      "  0.2155  0.1869  0.1584  ...   0.0000  0.0000  0.0000\n",
      "  0.1944  0.1672  0.1401  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "(30 , 2 ,.,.) = \n",
      "  0.0038  0.0052  0.0066  ...   0.1332  0.1093  0.0855\n",
      "  0.0033  0.0061  0.0089  ...   0.1440  0.1238  0.1037\n",
      "  0.0028  0.0070  0.0111  ...   0.1548  0.1383  0.1219\n",
      "           ...             ⋱             ...          \n",
      "  0.2366  0.2066  0.1767  ...   0.0000  0.0000  0.0000\n",
      "  0.2155  0.1869  0.1584  ...   0.0000  0.0000  0.0000\n",
      "  0.1944  0.1672  0.1401  ...   0.0000  0.0000  0.0000\n",
      "      ⋮  \n",
      "\n",
      "(31 , 0 ,.,.) = \n",
      "  0.1929  0.1948  0.1967  ...   0.2046  0.2030  0.2013\n",
      "  0.2064  0.2090  0.2116  ...   0.2225  0.2219  0.2214\n",
      "  0.2245  0.2272  0.2298  ...   0.2428  0.2431  0.2434\n",
      "           ...             ⋱             ...          \n",
      "  0.4825  0.4839  0.4854  ...   0.1770  0.1869  0.1969\n",
      "  0.4817  0.4832  0.4847  ...   0.1802  0.1897  0.1993\n",
      "  0.4810  0.4825  0.4839  ...   0.1834  0.1926  0.2017\n",
      "\n",
      "(31 , 1 ,.,.) = \n",
      "  0.1929  0.1948  0.1967  ...   0.2046  0.2030  0.2013\n",
      "  0.2064  0.2090  0.2116  ...   0.2225  0.2219  0.2214\n",
      "  0.2245  0.2272  0.2298  ...   0.2428  0.2431  0.2434\n",
      "           ...             ⋱             ...          \n",
      "  0.4825  0.4839  0.4854  ...   0.1770  0.1869  0.1969\n",
      "  0.4817  0.4832  0.4847  ...   0.1802  0.1897  0.1993\n",
      "  0.4810  0.4825  0.4839  ...   0.1834  0.1926  0.2017\n",
      "\n",
      "(31 , 2 ,.,.) = \n",
      "  0.1929  0.1948  0.1967  ...   0.2046  0.2030  0.2013\n",
      "  0.2064  0.2090  0.2116  ...   0.2225  0.2219  0.2214\n",
      "  0.2245  0.2272  0.2298  ...   0.2428  0.2431  0.2434\n",
      "           ...             ⋱             ...          \n",
      "  0.4825  0.4839  0.4854  ...   0.1770  0.1869  0.1969\n",
      "  0.4817  0.4832  0.4847  ...   0.1802  0.1897  0.1993\n",
      "  0.4810  0.4825  0.4839  ...   0.1834  0.1926  0.2017\n",
      "[torch.FloatTensor of size 32x3x224x224]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      "[torch.LongTensor of size 32]\n",
      "\n",
      "Variable containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  0.5926  0.5548  0.5268  ...   0.7570  0.7741  0.7911\n",
      "  0.5863  0.5516  0.5264  ...   0.7533  0.7689  0.7844\n",
      "  0.5800  0.5483  0.5261  ...   0.7496  0.7636  0.7776\n",
      "           ...             ⋱             ...          \n",
      "  0.5370  0.5214  0.5035  ...   0.2470  0.2865  0.3260\n",
      "  0.5414  0.5255  0.5074  ...   0.2538  0.2929  0.3320\n",
      "  0.5454  0.5289  0.5105  ...   0.2615  0.2999  0.3384\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  0.5926  0.5548  0.5268  ...   0.7570  0.7741  0.7911\n",
      "  0.5863  0.5516  0.5264  ...   0.7533  0.7689  0.7844\n",
      "  0.5800  0.5483  0.5261  ...   0.7496  0.7636  0.7776\n",
      "           ...             ⋱             ...          \n",
      "  0.5370  0.5214  0.5035  ...   0.2470  0.2865  0.3260\n",
      "  0.5414  0.5255  0.5074  ...   0.2538  0.2929  0.3320\n",
      "  0.5454  0.5289  0.5105  ...   0.2615  0.2999  0.3384\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  0.5926  0.5548  0.5268  ...   0.7570  0.7741  0.7911\n",
      "  0.5863  0.5516  0.5264  ...   0.7533  0.7689  0.7844\n",
      "  0.5800  0.5483  0.5261  ...   0.7496  0.7636  0.7776\n",
      "           ...             ⋱             ...          \n",
      "  0.5370  0.5214  0.5035  ...   0.2470  0.2865  0.3260\n",
      "  0.5414  0.5255  0.5074  ...   0.2538  0.2929  0.3320\n",
      "  0.5454  0.5289  0.5105  ...   0.2615  0.2999  0.3384\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  0.6536  0.6528  0.6521  ...   0.5850  0.5843  0.5848\n",
      "  0.6536  0.6528  0.6521  ...   0.5843  0.5836  0.5841\n",
      "  0.6536  0.6528  0.6521  ...   0.5836  0.5828  0.5833\n",
      "           ...             ⋱             ...          \n",
      "  0.6229  0.6203  0.6177  ...   0.4515  0.4544  0.4565\n",
      "  0.6217  0.6193  0.6168  ...   0.4515  0.4544  0.4563\n",
      "  0.6205  0.6182  0.6159  ...   0.4515  0.4544  0.4562\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  0.6536  0.6528  0.6521  ...   0.5850  0.5843  0.5848\n",
      "  0.6536  0.6528  0.6521  ...   0.5843  0.5836  0.5841\n",
      "  0.6536  0.6528  0.6521  ...   0.5836  0.5828  0.5833\n",
      "           ...             ⋱             ...          \n",
      "  0.6229  0.6203  0.6177  ...   0.4515  0.4544  0.4565\n",
      "  0.6217  0.6193  0.6168  ...   0.4515  0.4544  0.4563\n",
      "  0.6205  0.6182  0.6159  ...   0.4515  0.4544  0.4562\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  0.6536  0.6528  0.6521  ...   0.5850  0.5843  0.5848\n",
      "  0.6536  0.6528  0.6521  ...   0.5843  0.5836  0.5841\n",
      "  0.6536  0.6528  0.6521  ...   0.5836  0.5828  0.5833\n",
      "           ...             ⋱             ...          \n",
      "  0.6229  0.6203  0.6177  ...   0.4515  0.4544  0.4565\n",
      "  0.6217  0.6193  0.6168  ...   0.4515  0.4544  0.4563\n",
      "  0.6205  0.6182  0.6159  ...   0.4515  0.4544  0.4562\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  0.1766  0.1770  0.1775  ...   0.0400  0.0387  0.0373\n",
      "  0.2026  0.2036  0.2046  ...   0.0334  0.0344  0.0354\n",
      "  0.2224  0.2244  0.2263  ...   0.0279  0.0308  0.0337\n",
      "           ...             ⋱             ...          \n",
      "  0.2939  0.2907  0.2876  ...   0.2367  0.2326  0.2284\n",
      "  0.2885  0.2850  0.2814  ...   0.2331  0.2295  0.2259\n",
      "  0.2832  0.2792  0.2752  ...   0.2295  0.2265  0.2235\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  0.1766  0.1770  0.1775  ...   0.0400  0.0387  0.0373\n",
      "  0.2026  0.2036  0.2046  ...   0.0334  0.0344  0.0354\n",
      "  0.2224  0.2244  0.2263  ...   0.0279  0.0308  0.0337\n",
      "           ...             ⋱             ...          \n",
      "  0.2939  0.2907  0.2876  ...   0.2367  0.2326  0.2284\n",
      "  0.2885  0.2850  0.2814  ...   0.2331  0.2295  0.2259\n",
      "  0.2832  0.2792  0.2752  ...   0.2295  0.2265  0.2235\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  0.1766  0.1770  0.1775  ...   0.0400  0.0387  0.0373\n",
      "  0.2026  0.2036  0.2046  ...   0.0334  0.0344  0.0354\n",
      "  0.2224  0.2244  0.2263  ...   0.0279  0.0308  0.0337\n",
      "           ...             ⋱             ...          \n",
      "  0.2939  0.2907  0.2876  ...   0.2367  0.2326  0.2284\n",
      "  0.2885  0.2850  0.2814  ...   0.2331  0.2295  0.2259\n",
      "  0.2832  0.2792  0.2752  ...   0.2295  0.2265  0.2235\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(29 , 0 ,.,.) = \n",
      "  0.1037  0.1104  0.1171  ...   0.8749  0.8745  0.8752\n",
      "  0.1058  0.1123  0.1187  ...   0.8752  0.8749  0.8756\n",
      "  0.1117  0.1179  0.1241  ...   0.8752  0.8749  0.8756\n",
      "           ...             ⋱             ...          \n",
      "  0.2714  0.2597  0.2480  ...   0.8907  0.8918  0.8926\n",
      "  0.2737  0.2633  0.2528  ...   0.8894  0.8905  0.8917\n",
      "  0.2761  0.2669  0.2577  ...   0.8882  0.8893  0.8909\n",
      "\n",
      "(29 , 1 ,.,.) = \n",
      "  0.1037  0.1104  0.1171  ...   0.8749  0.8745  0.8752\n",
      "  0.1058  0.1123  0.1187  ...   0.8752  0.8749  0.8756\n",
      "  0.1117  0.1179  0.1241  ...   0.8752  0.8749  0.8756\n",
      "           ...             ⋱             ...          \n",
      "  0.2714  0.2597  0.2480  ...   0.8907  0.8918  0.8926\n",
      "  0.2737  0.2633  0.2528  ...   0.8894  0.8905  0.8917\n",
      "  0.2761  0.2669  0.2577  ...   0.8882  0.8893  0.8909\n",
      "\n",
      "(29 , 2 ,.,.) = \n",
      "  0.1037  0.1104  0.1171  ...   0.8749  0.8745  0.8752\n",
      "  0.1058  0.1123  0.1187  ...   0.8752  0.8749  0.8756\n",
      "  0.1117  0.1179  0.1241  ...   0.8752  0.8749  0.8756\n",
      "           ...             ⋱             ...          \n",
      "  0.2714  0.2597  0.2480  ...   0.8907  0.8918  0.8926\n",
      "  0.2737  0.2633  0.2528  ...   0.8894  0.8905  0.8917\n",
      "  0.2761  0.2669  0.2577  ...   0.8882  0.8893  0.8909\n",
      "      ⋮  \n",
      "\n",
      "(30 , 0 ,.,.) = \n",
      "  0.4738  0.4827  0.4915  ...   0.4562  0.4320  0.4047\n",
      "  0.4781  0.4861  0.4941  ...   0.4604  0.4386  0.4140\n",
      "  0.4823  0.4895  0.4968  ...   0.4645  0.4452  0.4232\n",
      "           ...             ⋱             ...          \n",
      "  0.0872  0.0834  0.0796  ...   0.0802  0.0780  0.0736\n",
      "  0.0865  0.0824  0.0783  ...   0.0752  0.0740  0.0709\n",
      "  0.0857  0.0813  0.0769  ...   0.0702  0.0700  0.0683\n",
      "\n",
      "(30 , 1 ,.,.) = \n",
      "  0.4738  0.4827  0.4915  ...   0.4562  0.4320  0.4047\n",
      "  0.4781  0.4861  0.4941  ...   0.4604  0.4386  0.4140\n",
      "  0.4823  0.4895  0.4968  ...   0.4645  0.4452  0.4232\n",
      "           ...             ⋱             ...          \n",
      "  0.0872  0.0834  0.0796  ...   0.0802  0.0780  0.0736\n",
      "  0.0865  0.0824  0.0783  ...   0.0752  0.0740  0.0709\n",
      "  0.0857  0.0813  0.0769  ...   0.0702  0.0700  0.0683\n",
      "\n",
      "(30 , 2 ,.,.) = \n",
      "  0.4738  0.4827  0.4915  ...   0.4562  0.4320  0.4047\n",
      "  0.4781  0.4861  0.4941  ...   0.4604  0.4386  0.4140\n",
      "  0.4823  0.4895  0.4968  ...   0.4645  0.4452  0.4232\n",
      "           ...             ⋱             ...          \n",
      "  0.0872  0.0834  0.0796  ...   0.0802  0.0780  0.0736\n",
      "  0.0865  0.0824  0.0783  ...   0.0752  0.0740  0.0709\n",
      "  0.0857  0.0813  0.0769  ...   0.0702  0.0700  0.0683\n",
      "      ⋮  \n",
      "\n",
      "(31 , 0 ,.,.) = \n",
      "  0.7223  0.6319  0.5415  ...   0.1173  0.1211  0.1253\n",
      "  0.7151  0.6239  0.5327  ...   0.1154  0.1185  0.1224\n",
      "  0.7080  0.6160  0.5239  ...   0.1135  0.1159  0.1196\n",
      "           ...             ⋱             ...          \n",
      "  0.5284  0.5828  0.6373  ...   0.5070  0.5204  0.5087\n",
      "  0.5123  0.5667  0.6211  ...   0.6123  0.6334  0.6136\n",
      "  0.4961  0.5505  0.6049  ...   0.7176  0.7465  0.7184\n",
      "\n",
      "(31 , 1 ,.,.) = \n",
      "  0.7223  0.6319  0.5415  ...   0.1173  0.1211  0.1253\n",
      "  0.7151  0.6239  0.5327  ...   0.1154  0.1185  0.1224\n",
      "  0.7080  0.6160  0.5239  ...   0.1135  0.1159  0.1196\n",
      "           ...             ⋱             ...          \n",
      "  0.5284  0.5828  0.6373  ...   0.5070  0.5204  0.5087\n",
      "  0.5123  0.5667  0.6211  ...   0.6123  0.6334  0.6136\n",
      "  0.4961  0.5505  0.6049  ...   0.7176  0.7465  0.7184\n",
      "\n",
      "(31 , 2 ,.,.) = \n",
      "  0.7223  0.6319  0.5415  ...   0.1173  0.1211  0.1253\n",
      "  0.7151  0.6239  0.5327  ...   0.1154  0.1185  0.1224\n",
      "  0.7080  0.6160  0.5239  ...   0.1135  0.1159  0.1196\n",
      "           ...             ⋱             ...          \n",
      "  0.5284  0.5828  0.6373  ...   0.5070  0.5204  0.5087\n",
      "  0.5123  0.5667  0.6211  ...   0.6123  0.6334  0.6136\n",
      "  0.4961  0.5505  0.6049  ...   0.7176  0.7465  0.7184\n",
      "[torch.FloatTensor of size 32x3x224x224]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 0\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      "[torch.LongTensor of size 32]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = tqdm(trainLoader)\n",
    "for (i, (sample)) in enumerate(t):\n",
    "    \n",
    "    inputs = Variable(sample['image'] ).float()\n",
    "    labels = Variable(sample['emotion'])\n",
    "    print(inputs)\n",
    "    print(labels)\n",
    "    if i == 3:\n",
    "        break\n",
    "    #outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c180c3a4-a698-4501-a48d-3b4cb152b2f8"
    }
   },
   "outputs": [],
   "source": [
    "import lab_utils\n",
    "\n",
    "\n",
    "def train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = False):\n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    t_loss, t_acc, v_loss, v_acc = (np.zeros(n_epochs) for i in range(4))    \n",
    "    \n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (sample)) in enumerate(t):\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(sample['image'] ).float()\n",
    "            labels = Variable(sample['emotion'])\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            #for param in network.parameters():\n",
    "            #    print(\"gradient values\", param.grad.data.sum())\n",
    "            #    break\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            a = list(network.parameters())[0].clone()\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "            b = list(network.parameters())[0].clone()\n",
    "            #print(torch.equal(a.data, b.data))\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "            \n",
    "        t_loss[epoch] = (cum_loss/len(t))\n",
    "        t_acc[epoch] = (100*correct/counter)\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (sample)) in enumerate(t):\n",
    "            #print(\"on iter {}\".format(i))\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(sample['image'] ).float()\n",
    "            labels = Variable(sample['emotion'])\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "            \n",
    "        v_loss[epoch] = (cum_loss/len(t))\n",
    "        v_acc[epoch] = (100*correct/counter)\n",
    "        \n",
    "                \n",
    "    #lab_utils.generate_plots(t_loss, v_loss, t_acc, v_acc, n_epochs)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8459ae87-2706-43ee-9348-a63be5996153"
    }
   },
   "source": [
    "### set learning rate, loss, optimizer, all variable stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential (\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU ()\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU ()\n",
      "  (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU ()\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU ()\n",
      "  (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU ()\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU ()\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU ()\n",
      "  (16): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU ()\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU ()\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU ()\n",
      "  (23): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU ()\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU ()\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU ()\n",
      "  (30): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (31): Lambda (\n",
      "  )\n",
      "  (32): Sequential (\n",
      "    (0): Lambda (\n",
      "    )\n",
      "    (1): Linear (25088 -> 4096)\n",
      "  )\n",
      "  (33): ReLU ()\n",
      "  (34): Dropout (p = 0.5)\n",
      "  (35): Sequential (\n",
      "    (0): Lambda (\n",
      "    )\n",
      "    (1): Linear (4096 -> 4096)\n",
      "  )\n",
      "  (36): ReLU ()\n",
      "  (37): Dropout (p = 0.5)\n",
      "  (38): Sequential (\n",
      "    (0): Lambda (\n",
      "    )\n",
      "    (1): Linear (4096 -> 3)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = model\n",
    "#print(pretrained_model)\n",
    "#print(list(pretrained_model.children())[:-2]) #gets rid of the last linear layer and softmax\n",
    "modified_pretrained = nn.Sequential(*list(pretrained_model.children())[:-2]) \n",
    "\n",
    "#print(modified_pretrained)\n",
    "\n",
    "modified_pretrained.add_module('38', nn.Sequential(VGG_FACE.Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(4096,3)))\n",
    "#modified_pretrained.add_module('39', nn.Softmax())\n",
    "\n",
    "print(modified_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "faa6cc19-fa86-49d0-9374-cfc76c652add"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "#\"where we set the learning rate and weight decay to 0.0005, momentum to 0.9, and dropout probability to 0.8 [25]\"\n",
    "learningRate = 5e-4\n",
    "weightDecay = 0.0005\n",
    "moment = 0.9\n",
    "\n",
    "\n",
    "# Definition of our network.\n",
    "#how to change the last fc layer of the model to nn.linear(4096, 7) instead of (4096, 2622)?\n",
    "#model.fc = nn.Linear(512, 2)\n",
    "\n",
    "\n",
    "#Definition of our loss. #maybe need to change this?\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definition of optimization strategy. # maybe need to change this?\n",
    "optimizer = optim.SGD(modified_pretrained.parameters(), lr = learningRate, nesterov = True, weight_decay = weightDecay, momentum= moment)\n",
    "# following this model: https://arxiv.org/pdf/1711.04598.pdf\n",
    "#lambda1 = lambda epoch: epoch // 30\n",
    "lambda2 = lambda epoch: 0.95 ** epoch\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=[lambda2])\n",
    "\n",
    "train_model(modified_pretrained, criterion, optimizer, trainLoader, valLoader, n_epochs = 5, use_gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(modified_pretrained.state_dict(), 'trained_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
